{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\mb}[1]{\\mathbf{ #1 }}$\n",
    "$\\newcommand{\\bs}[1]{\\boldsymbol{ #1 }}$\n",
    "$\\newcommand{\\bb}[1]{\\mathbb{ #1 }}$\n",
    "\n",
    "$\\newcommand{\\R}{\\bb{R}}$\n",
    "\n",
    "$\\newcommand{\\ip}[2]{\\left\\langle #1, #2 \\right\\rangle}$\n",
    "$\\newcommand{\\norm}[1]{\\left\\Vert #1 \\right\\Vert}$\n",
    "\n",
    "$\\newcommand{\\der}[2]{\\frac{\\mathrm{d} #1 }{\\mathrm{d} #2 }}$\n",
    "$\\newcommand{\\derp}[2]{\\frac{\\partial #1 }{\\partial #2 }}$\n",
    "\n",
    "# Finite Dimensional Koopman Bilinear System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a nonlinear dynamical system that allows an exact finite dimensional Koopman canonical transform such that the control-affine dynamics can be transformed to a bilinear system. Consider the dynamical system "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mb{\\dot{x}}=\\mb{f}_0(\\mb x) + \\mb f_1 ( \\mb x) u_1 + \\mb f_2(\\mb x) u_2, \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we for this example choose $\\mb f_0, \\mb f_1$ as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mb f_0(\\mb x) = \\begin{bmatrix} x_3 \\\\ x_4 \\\\ \\lambda x_3 \\\\ \\mu x_4 + (2 \\lambda - \\mu) c x_3^2 \\end{bmatrix}, \\qquad\n",
    "\\mb f_1(\\mb x) = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\qquad\n",
    "\\mb f_2(\\mb x) = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ x_1+1 \\end{bmatrix}, \n",
    "\\end{equation}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and $\\lambda, \\mu, c \\in \\mathbb{R}$ are scalar parameters of the system. Setting $ \\mb x = [q_1 \\, q_2 \\, \\dot{q_1} \\, \\dot{q_2}]^T$, \n",
    "these equations of motion can be expressed as robotic dynamics of the form $\\mb{D}(\\mb{q})\\ddot{\\mb{q}} + \\mb{C}(\\mb{q}, \\dot{\\mb{q}})\\dot{\\mb{q}} + \\mb{G}(\\mb{q}) = \\mb{B}\\mb{u}$, where $\\mb D$ is the inertia matrix, $\\mb C$ is the matrix of Coriolis terms, $\\mb G$ is the matrix of gravitational terms, and $\\mb B$ is the static actuation matrix. Rewriting $\\mb f_0, \\mb f_1, \\mb f_2$ in terms of $\\mb D, \\mb C, \\mb G,$ and $\\mb B$ yield\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mb D(\\mb q) = \\begin{bmatrix} 1 & 0\\\\ 0 &  \\frac{1}{q_1+1} \\end{bmatrix}, \n",
    "\\qquad \\mb C(\\mb q, \\mb{\\dot{q}}) = -\\begin{bmatrix} \\lambda & 0 \\\\ \\frac{1}{q_1 + 1}(2 \\lambda - \\mu) c \\dot{q}_1 & \\frac{1}{q_1 +1} \\mu \\end{bmatrix}, \\qquad \n",
    "\\mb G(\\mb q) = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \n",
    "\\qquad \\mb B = \\begin{bmatrix}1 & 0 \\\\ 0 & 1 \\end{bmatrix},\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of the careful construction of this system, there exists a Koopman canonical transform, $\\mb z = T(\\mb x)$ that exactly transforms the control-affine dynamics into a bilinear system. Consider the transformation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    T(\\mb q, \\mb{\\dot{q}}) = \\begin{bmatrix} \n",
    "    \\phi_1(\\mb q, \\mb{\\dot{q}})\\\\\n",
    "    \\phi_2(\\mb q, \\mb{\\dot{q}})\\\\\n",
    "    \\phi_3(\\mb q, \\mb{\\dot{q}})\\\\\n",
    "    \\phi_4(\\mb q, \\mb{\\dot{q}})\\\\\n",
    "    \\phi_5(\\mb q, \\mb{\\dot{q}})\\\\\n",
    "    \\phi_6(\\mb q, \\mb{\\dot{q}})\\\\\n",
    "    \\end{bmatrix}\n",
    "    = \\begin{bmatrix} \n",
    "    1\\\\\n",
    "    q_1 - \\frac{1}{\\lambda}\\dot{q}_1\\\\\n",
    "    q_2 - \\frac{1}{\\mu} \\dot{q}_2 + \\frac{(2 \\lambda - \\mu)c}{2\\lambda \\mu} \\dot{q}_1^2\\\\\n",
    "    \\dot{q}_1\\\\\n",
    "    \\dot{q}_2 - c \\dot{q}_1^2\\\\\n",
    "    \\dot{q}_1^2\\\\\n",
    "    \\end{bmatrix},\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\phi_1, \\phi_2, \\phi_3, \\phi_4, \\phi_5, \\phi_6$ are eigenfunctions of the Koopman operator associated with the drift \n",
    "vector field $\\mb f_0$. The matrix with the eigenvalue associated with the i-th eigenfunction on the i-th diagonal \n",
    "element is $F=\\text{diag}(0, 0, \\lambda, \\mu, 2 \\lambda, 0)$. Then, to reformulate the dynamics we have: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} \n",
    "L_{\\mb f_1} T(\\mb q, \\mb{\\dot{q}}) = \\begin{bmatrix} 0\\\\ -\\frac{1}{\\lambda}\\\\ \\frac{(2\\lambda - \\mu)c}{\\lambda \\mu}\\dot{q}_1\\\\ 1 \\\\ -2c\\dot{q}_1 \\\\ 2\\dot{q_1} \\end{bmatrix}, \\qquad \n",
    "L_{\\mb f_2} T(\\mb q, \\mb{\\dot{q}}) = \\begin{bmatrix} 0 \\\\ 0\\\\ -\\frac{1}{\\mu}(q_1 + 1)\\\\0 \\\\ q_1 + 1 \\\\ 0 \\end{bmatrix} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the dynamics can be equivalently transformed to a bilinear form $\\mb{\\dot{z}} = F \\mb z + G_1\\mb z u_1 + G_2\\mb z u_2$ with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "F = \\begin{bmatrix} \n",
    "0 &0 & 0 & 0 & 0 & 0\\\\  \n",
    "0 & 0 & 0 & 0 & 0 & 0\\\\\n",
    "0 &0 & 0 & 0 & 0 & 0\\\\\n",
    "0 &0 & 0 & \\lambda & 0 & 0\\\\\n",
    "0 &0 & 0 & 0 & \\mu & 0 \\\\\n",
    "0 &0 & 0 & 0 & 0 & 2 \\lambda\\\\\n",
    "\\end{bmatrix}, \\qquad \n",
    "G_1 = \\begin{bmatrix} \n",
    "0 & 0 & 0 & 0 & 0 & 0\\\\\n",
    "-\\frac{1}{\\lambda}& 0 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 0 & \\frac{(2\\lambda - \\mu)c}{\\lambda \\mu} & 0 & 0\\\\\n",
    "1 & 0 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 0 & -2c & 0 & 0\\\\\n",
    "0 & 0 & 0 & 2 & 0 & 0\\\\  \n",
    "\\end{bmatrix}\n",
    ", \\qquad \n",
    "G_2 = \\begin{bmatrix} \n",
    "0 & 0 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 0 &  0 & 0 & 0 & 0\\\\\n",
    " -\\frac{1}{\\mu} & -\\frac{1}{\\mu} & 0 &  -\\frac{1}{\\lambda \\mu} & 0 & 0\\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0\\\\\n",
    "1 & 1 & 0 & \\frac{1}{\\lambda} & 0 & 0\\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0\\\\  \n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.dynamics import RoboticDynamics, ConfigurationDynamics\n",
    "\n",
    "class KoopPdOutput(ConfigurationDynamics):\n",
    "    def __init__(self, dynamics, xd, n, m):\n",
    "        ConfigurationDynamics.__init__(self, dynamics, 1)\n",
    "        self.xd = xd\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "\n",
    "    def proportional(self, x, t):\n",
    "        q = x[:int(n/2)]\n",
    "        q_d = self.xd[:int(n/2)]\n",
    "\n",
    "        return  q - q_d\n",
    "\n",
    "    def derivative(self, x, t):\n",
    "        q_dot = x[int(n/2):]\n",
    "        q_dot_d = self.xd[int(n/2):]\n",
    "\n",
    "        return q_dot - q_dot_d\n",
    "\n",
    "class FiniteDimKoopSys(RoboticDynamics):\n",
    "    def __init__(self, lambd, mu, c):\n",
    "        RoboticDynamics.__init__(self, 2, 2)\n",
    "        self.params = lambd, mu, c\n",
    "    \n",
    "    def D(self, q):\n",
    "        return np.array([[1, 0],[0, (q[0]+1)**(-1)]])\n",
    "    \n",
    "    def C(self, q, q_dot):\n",
    "        labmd, mu, c = self.params\n",
    "        return -np.array([[lambd, 0], [(q[0]+1)**(-1)*(2*lambd - mu)*c*q_dot[0], (q[0]+1)**(-1)*mu]])\n",
    "    \n",
    "    def G(self, q):\n",
    "        return np.array([0, 0])\n",
    "    \n",
    "    def B(self, q):\n",
    "        return np.array([[1, 0], [0, 1]])\n",
    "\n",
    "n, m = 4, 2\n",
    "lambd, mu, c = .3, .2, -.5\n",
    "sys_name = 'bilinearizable_sys'\n",
    "system = FiniteDimKoopSys(lambd, mu, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koopman_core.dynamics import LinearLiftedDynamics\n",
    "\n",
    "A_lin = np.array([[0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1],\n",
    "                  [0, 0, lambd, 0],\n",
    "                  [0, 0, 0, mu]])\n",
    "B_lin = np.array([[0, 0],\n",
    "                  [0, 0],\n",
    "                  [1, 0],\n",
    "                  [0, 1]])\n",
    "dt = 1e-2\n",
    "linearized_sys = LinearLiftedDynamics(A_lin, B_lin, np.eye(n), lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data for learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "import os\n",
    "\n",
    "q_dc, r_dc = 5e2, 1                                                 # State and actuation penalty values, data collection\n",
    "Q_dc = q_dc * np.identity(n)                                        # State penalty matrix, data collection\n",
    "R_dc = r_dc*np.identity(m)                                          # Actuation penalty matrix, data collection\n",
    "P_dc = sc.linalg.solve_continuous_are(A_lin, B_lin, Q_dc, R_dc)     # Algebraic Ricatti equation solution, data collection\n",
    "K_dc = np.linalg.inv(R_dc)@B_lin.T@P_dc                             # LQR feedback gain matrix, data collection\n",
    "K_dc_p = K_dc[:,:int(n/2)]                                          # Proportional control gains, data collection\n",
    "K_dc_d = K_dc[:,int(n/2):]                                          # Derivative control gains, data collection\n",
    "\n",
    "# Data collection parameters:\n",
    "collect_data = False\n",
    "dt = 1.0e-2                                                         # Time step length\n",
    "traj_length_dc = 2.                                                 # Trajectory length, data collection\n",
    "n_pred_dc = int(traj_length_dc/dt)                                  # Number of time steps, data collection\n",
    "t_eval = dt * np.arange(n_pred_dc + 1)                              # Simulation time points\n",
    "n_traj_train = 100                                                      # Number of trajectories to execute, data collection\n",
    "n_traj_val = int(0.2*n_traj_train)\n",
    "noise_var = 5.                                                      # Exploration noise to perturb controller, data collection\n",
    "\n",
    "xmax = np.array([1., 1., 1., 1.])                                   # State constraints, trajectory generation\n",
    "xmin = -xmax\n",
    "umax = np.array([10., 10.])                                         # Actuation constraint, trajectory generation\n",
    "umin = -umax\n",
    "x0_max = xmax/2                                                     # Initial value limits\n",
    "sub_sample_rate = 1                                                 # Rate to subsample data for training\n",
    "model_fname = 'examples/'                                           # Path to save learned models\n",
    "n_cols = 10                                                         # Number of columns in training data plot\n",
    "directory = os.path.abspath(\"\")                                     # Path to save learned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from koopman_core.util import run_experiment\n",
    "import dill\n",
    "\n",
    "if collect_data:\n",
    "    xs_train, us_train, t_train = run_experiment(system, n, n_traj_train, n_pred_dc, t_eval, x0_max, plot_experiment_data=True,\n",
    "                                      m=m, K_p=K_dc_p, K_d=K_dc_d, noise_var=noise_var)\n",
    "    xs_val, us_val, t_val = run_experiment(system, n, n_traj_val, n_pred_dc, t_eval, x0_max,\n",
    "                                      m=m, K_p=K_dc_p, K_d=K_dc_d, noise_var=noise_var)\n",
    "\n",
    "    data_list = [xs_train, us_train, t_train, n_traj_train, xs_val, us_val, t_val, n_traj_val]\n",
    "    outfile = open(directory + '/data/' + sys_name + '_data.pickle', 'wb')\n",
    "    dill.dump(data_list, outfile)\n",
    "    outfile.close()\n",
    "else:\n",
    "    infile = open(directory + '/data/' + sys_name + '_data.pickle', 'rb')\n",
    "    xs_train, us_train, t_train, n_traj_train, xs_val, us_val, t_val, n_traj_val = dill.load(infile)\n",
    "    infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Koopman-based models of the dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn bilinear EDMD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bilinear EDMD parameters:                                           \n",
    "alpha_bedmd = 2.4e-5  # Regularization strength (LASSO) bEDMD\n",
    "tune_mdl_bedmd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, linear_model\n",
    "from koopman_core.learning import BilinearEdmd\n",
    "from koopman_core.dynamics import BilinearLiftedDynamics\n",
    "\n",
    "bedmd_features = preprocessing.PolynomialFeatures(2)\n",
    "bedmd_features.fit(np.zeros((1,n)))\n",
    "n_lift_bedmd = bedmd_features.transform((np.zeros((1,n)))).shape[1]\n",
    "\n",
    "C_bedmd = np.zeros((n,n_lift_bedmd))\n",
    "C_bedmd[:,1:n+1] = np.eye(n)\n",
    "\n",
    "basis_bedmd = lambda x: bedmd_features.transform(x)\n",
    "optimizer_bedmd = linear_model.MultiTaskLasso(alpha=alpha_bedmd, fit_intercept=False, selection='random')\n",
    "cv_bedmd = linear_model.MultiTaskLassoCV(fit_intercept=False, n_jobs=-1, cv=3, selection='random')\n",
    "#standardizer_bedmd = preprocessing.StandardScaler(with_mean=False)\n",
    "standardizer_bedmd = None\n",
    "\n",
    "model_bedmd = BilinearEdmd(n, m, basis_bedmd, n_lift_bedmd, n_traj_train, optimizer_bedmd, cv=cv_bedmd, \n",
    "                           standardizer=standardizer_bedmd, C=C_bedmd, continuous_mdl=False, dt=dt)\n",
    "X_bedmd, y_bedmd = model_bedmd.process(xs_train, us_train, np.tile(t_train,(n_traj_train,1)), downsample_rate=sub_sample_rate)\n",
    "model_bedmd.fit(X_bedmd, y_bedmd, cv=tune_mdl_bedmd, override_kinematics=True)\n",
    "sys_bedmd = BilinearLiftedDynamics(model_bedmd.n_lift, m, model_bedmd.A, model_bedmd.B, model_bedmd.C, \n",
    "                                   model_bedmd.basis, continuous_mdl=False, dt=dt)\n",
    "if tune_mdl_bedmd:\n",
    "    print('$\\\\alpha$ bilinear EDMD: ', model_bedmd.cv.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn Koopman DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state_dim': 4, 'ctrl_dim': 2, 'encoder_hidden_width': 100, 'encoder_hidden_depth': 1, 'encoder_output_dim': 1, 'optimizer': 'adam', 'activation_type': 'relu', 'lr': 0.01, 'epochs': 500, 'batch_size': 256, 'lin_loss_penalty': 0.1, 'l2_reg': 0, 'l1_reg': 0, 'first_obs_const': True, 'override_kinematics': True, 'dt': 0.01}\n"
     ]
    }
   ],
   "source": [
    "import dill, os, torch\n",
    "\n",
    "load_tuned_params = False\n",
    "\n",
    "if load_tuned_params:\n",
    "    infile = open(os.path.abspath('') + '/data/analytic_koop_sys_best_params.pickle', 'rb')\n",
    "    best_config, val_loss, test_loss, open_loop_mse, open_loop_std = dill.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "else:\n",
    "    net_params = {}\n",
    "    net_params['state_dim'] = n\n",
    "    net_params['ctrl_dim'] = m\n",
    "    net_params['encoder_hidden_width'] = 100\n",
    "    net_params['encoder_hidden_depth'] = 1\n",
    "    net_params['encoder_output_dim'] = 1\n",
    "    net_params['optimizer'] = 'adam'\n",
    "    net_params['activation_type'] = 'relu'\n",
    "    net_params['lr'] = 1e-2\n",
    "    net_params['epochs'] = 500\n",
    "    net_params['batch_size'] = 256\n",
    "    net_params['lin_loss_penalty'] = 1e-1\n",
    "    net_params['l2_reg'] = 0\n",
    "    net_params['l1_reg'] = 0\n",
    "    net_params['first_obs_const'] = True\n",
    "    net_params['override_kinematics'] = True # TODO: Fix override kin... \n",
    "    net_params['dt'] = dt\n",
    "\n",
    "print(net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: train loss: 1056.05395508, validation loss: 1001.26232147\n",
      "Epoch   2: train loss: 984.04943848, validation loss: 945.04153061\n",
      "Epoch   3: train loss: 923.16809082, validation loss: 894.25643921\n",
      "Epoch   4: train loss: 870.64001465, validation loss: 839.70886993\n",
      "Epoch   5: train loss: 820.98797607, validation loss: 792.99705505\n",
      "Epoch   6: train loss: 774.46490479, validation loss: 748.93698883\n",
      "Epoch   7: train loss: 728.45782471, validation loss: 699.77265930\n",
      "Epoch   8: train loss: 687.15802002, validation loss: 663.08065414\n",
      "Epoch   9: train loss: 644.83386230, validation loss: 623.49240494\n",
      "Epoch  10: train loss: 606.18682861, validation loss: 584.33798599\n",
      "Epoch  11: train loss: 570.79571533, validation loss: 550.02181244\n",
      "Epoch  12: train loss: 535.59777832, validation loss: 516.75147438\n",
      "Epoch  13: train loss: 502.72775269, validation loss: 484.71827698\n",
      "Epoch  14: train loss: 472.72482300, validation loss: 455.32818985\n",
      "Epoch  15: train loss: 445.34503174, validation loss: 426.57690620\n",
      "Epoch  16: train loss: 417.99609375, validation loss: 403.33877373\n",
      "Epoch  17: train loss: 391.85775757, validation loss: 377.72175407\n",
      "Epoch  18: train loss: 366.89703369, validation loss: 353.43612099\n",
      "Epoch  19: train loss: 344.63717651, validation loss: 332.55083656\n",
      "Epoch  20: train loss: 322.40573120, validation loss: 310.74348259\n",
      "Epoch  21: train loss: 302.76736450, validation loss: 290.85542107\n",
      "Epoch  22: train loss: 284.81661987, validation loss: 272.17469501\n",
      "Epoch  23: train loss: 265.87802124, validation loss: 254.40279865\n",
      "Epoch  24: train loss: 249.03901672, validation loss: 238.00115108\n",
      "Epoch  25: train loss: 232.91159058, validation loss: 222.42533398\n",
      "Epoch  26: train loss: 216.93016052, validation loss: 208.23180962\n",
      "Epoch  27: train loss: 203.16796875, validation loss: 194.11440182\n",
      "Epoch  28: train loss: 190.42333984, validation loss: 180.37803364\n",
      "Epoch  29: train loss: 177.05908203, validation loss: 168.74125957\n",
      "Epoch  30: train loss: 164.51304626, validation loss: 157.39633369\n",
      "Epoch  31: train loss: 152.90882874, validation loss: 145.36848736\n",
      "Epoch  32: train loss: 142.58268738, validation loss: 135.15347719\n",
      "Epoch  33: train loss: 131.92962646, validation loss: 125.39002943\n",
      "Epoch  34: train loss: 121.98316193, validation loss: 115.61752367\n",
      "Epoch  35: train loss: 113.31142426, validation loss: 106.36842632\n",
      "Epoch  36: train loss: 104.64923096, validation loss: 98.19440842\n",
      "Epoch  37: train loss: 96.39562988, validation loss: 90.24260139\n",
      "Epoch  38: train loss: 88.72462463, validation loss: 83.56383038\n",
      "Epoch  39: train loss: 81.73192596, validation loss: 75.78371239\n",
      "Epoch  40: train loss: 74.58141327, validation loss: 69.66359472\n",
      "Epoch  41: train loss: 68.16342163, validation loss: 63.16013288\n",
      "Epoch  42: train loss: 62.19842911, validation loss: 57.43027449\n",
      "Epoch  43: train loss: 56.68336487, validation loss: 52.45955300\n",
      "Epoch  44: train loss: 51.43046570, validation loss: 47.50090337\n",
      "Epoch  45: train loss: 46.46269608, validation loss: 42.66089344\n",
      "Epoch  46: train loss: 41.76545715, validation loss: 38.37135029\n",
      "Epoch  47: train loss: 37.63172913, validation loss: 34.42861986\n",
      "Epoch  48: train loss: 33.92648697, validation loss: 30.52808774\n",
      "Epoch  49: train loss: 30.14028740, validation loss: 27.16636765\n",
      "Epoch  50: train loss: 26.78096581, validation loss: 24.18175578\n",
      "Epoch  51: train loss: 23.79726982, validation loss: 21.38179195\n",
      "Epoch  52: train loss: 21.18523407, validation loss: 18.76283485\n",
      "Epoch  53: train loss: 18.49600983, validation loss: 16.48083472\n",
      "Epoch  54: train loss: 16.26082420, validation loss: 14.37601209\n",
      "Epoch  55: train loss: 14.21142006, validation loss: 12.44432759\n",
      "Epoch  56: train loss: 12.39782238, validation loss: 10.80758196\n",
      "Epoch  57: train loss: 10.66862869, validation loss: 9.25576955\n",
      "Epoch  58: train loss: 9.21653461, validation loss: 7.95976779\n",
      "Epoch  59: train loss: 7.90028477, validation loss: 6.73238099\n",
      "Epoch  60: train loss: 6.77441502, validation loss: 5.69846341\n",
      "Epoch  61: train loss: 5.73586941, validation loss: 4.80660942\n",
      "Epoch  62: train loss: 4.85591984, validation loss: 4.05366033\n",
      "Epoch  63: train loss: 4.03851604, validation loss: 3.33263485\n",
      "Epoch  64: train loss: 3.39475799, validation loss: 2.72254580\n",
      "Epoch  65: train loss: 2.81421208, validation loss: 2.25506893\n",
      "Epoch  66: train loss: 2.30600643, validation loss: 1.82040832\n",
      "Epoch  67: train loss: 1.88483608, validation loss: 1.46605587\n",
      "Epoch  68: train loss: 1.52227235, validation loss: 1.16135135\n",
      "Epoch  69: train loss: 1.22823763, validation loss: 0.91529597\n",
      "Epoch  70: train loss: 0.98322767, validation loss: 0.73736823\n",
      "Epoch  71: train loss: 0.78463149, validation loss: 0.58766779\n",
      "Epoch  72: train loss: 0.63008541, validation loss: 0.45007519\n",
      "Epoch  73: train loss: 0.48416504, validation loss: 0.33912561\n",
      "Epoch  74: train loss: 0.38379878, validation loss: 0.26029637\n",
      "Epoch  75: train loss: 0.30293313, validation loss: 0.20725976\n",
      "Epoch  76: train loss: 0.22739780, validation loss: 0.17150647\n",
      "Epoch  77: train loss: 0.18053482, validation loss: 0.11889503\n",
      "Epoch  78: train loss: 0.14969318, validation loss: 0.14298620\n",
      "Epoch  79: train loss: 0.12145907, validation loss: 0.07721260\n",
      "Epoch  80: train loss: 0.09824526, validation loss: 0.12753963\n",
      "Epoch  81: train loss: 0.07610200, validation loss: 0.06491931\n",
      "Epoch  82: train loss: 0.05496849, validation loss: 0.05646167\n",
      "Epoch  83: train loss: 0.05569730, validation loss: 0.08553878\n",
      "Epoch  84: train loss: 0.05029391, validation loss: 0.06258395\n",
      "Epoch  85: train loss: 0.04241483, validation loss: 0.05466674\n",
      "Epoch  86: train loss: 0.03455990, validation loss: 0.05893064\n",
      "Epoch  87: train loss: 0.04324985, validation loss: 0.07592035\n",
      "Epoch  88: train loss: 0.02981167, validation loss: 0.05649723\n",
      "Epoch  89: train loss: 0.03411686, validation loss: 0.04594211\n",
      "Epoch  90: train loss: 0.03494356, validation loss: 0.04793797\n",
      "Epoch  91: train loss: 0.03158322, validation loss: 0.07277575\n",
      "Epoch  92: train loss: 0.03136129, validation loss: 0.05086546\n",
      "Epoch  93: train loss: 0.03024262, validation loss: 0.05263409\n",
      "Epoch  94: train loss: 0.03422069, validation loss: 0.03729966\n",
      "Epoch  95: train loss: 0.03215228, validation loss: 0.04946157\n",
      "Epoch  96: train loss: 0.03179696, validation loss: 0.06894867\n",
      "Epoch  97: train loss: 0.02707326, validation loss: 0.04988557\n",
      "Epoch  98: train loss: 0.03338002, validation loss: 0.06635114\n",
      "Epoch  99: train loss: 0.02606133, validation loss: 0.04036525\n",
      "Epoch 100: train loss: 0.02285698, validation loss: 0.03595198\n",
      "Epoch 101: train loss: 0.02521363, validation loss: 0.03481779\n",
      "Epoch 102: train loss: 0.03002730, validation loss: 0.05588062\n",
      "Epoch 103: train loss: 0.02935623, validation loss: 0.03591100\n",
      "Epoch 104: train loss: 0.02632036, validation loss: 0.04266854\n",
      "Epoch 105: train loss: 0.01826355, validation loss: 0.03992576\n",
      "Epoch 106: train loss: 0.01931515, validation loss: 0.03912275\n",
      "Epoch 107: train loss: 0.02128885, validation loss: 0.03107189\n",
      "Epoch 108: train loss: 0.01757341, validation loss: 0.02366383\n",
      "Epoch 109: train loss: 0.01735670, validation loss: 0.02870968\n",
      "Epoch 110: train loss: 0.01825089, validation loss: 0.05496322\n",
      "Epoch 111: train loss: 0.01898815, validation loss: 0.02024869\n",
      "Epoch 112: train loss: 0.01393693, validation loss: 0.02361217\n",
      "Epoch 113: train loss: 0.01722945, validation loss: 0.02439796\n",
      "Epoch 114: train loss: 0.01382344, validation loss: 0.04199025\n",
      "Epoch 115: train loss: 0.01543952, validation loss: 0.03404900\n",
      "Epoch 116: train loss: 0.01422582, validation loss: 0.02030742\n",
      "Epoch 117: train loss: 0.01192559, validation loss: 0.02120778\n",
      "Epoch 118: train loss: 0.01478313, validation loss: 0.03147835\n",
      "Epoch 119: train loss: 0.01788911, validation loss: 0.02001263\n",
      "Epoch 120: train loss: 0.01419533, validation loss: 0.02045416\n",
      "Epoch 121: train loss: 0.01061175, validation loss: 0.01750144\n",
      "Epoch 122: train loss: 0.01346255, validation loss: 0.04168303\n",
      "Epoch 123: train loss: 0.01288794, validation loss: 0.01715593\n",
      "Epoch 124: train loss: 0.01307670, validation loss: 0.01541262\n",
      "Epoch 125: train loss: 0.00883201, validation loss: 0.02146591\n",
      "Epoch 126: train loss: 0.01059486, validation loss: 0.01818256\n",
      "Epoch 127: train loss: 0.00885156, validation loss: 0.01125882\n",
      "Epoch 128: train loss: 0.00931500, validation loss: 0.03265598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129: train loss: 0.01098652, validation loss: 0.01323472\n",
      "Epoch 130: train loss: 0.01047761, validation loss: 0.01421682\n",
      "Epoch 131: train loss: 0.00811994, validation loss: 0.01087226\n",
      "Epoch 132: train loss: 0.00733070, validation loss: 0.01192433\n",
      "Epoch 133: train loss: 0.00615512, validation loss: 0.00946370\n",
      "Epoch 134: train loss: 0.00735780, validation loss: 0.02278075\n",
      "Epoch 135: train loss: 0.00670526, validation loss: 0.01585799\n",
      "Epoch 136: train loss: 0.00887256, validation loss: 0.00871714\n",
      "Epoch 137: train loss: 0.00662381, validation loss: 0.01050425\n",
      "Epoch 138: train loss: 0.00934700, validation loss: 0.01429217\n",
      "Epoch 139: train loss: 0.01026348, validation loss: 0.00867781\n",
      "Epoch 140: train loss: 0.00586091, validation loss: 0.00840832\n",
      "Epoch 141: train loss: 0.00645168, validation loss: 0.01292992\n",
      "Epoch 142: train loss: 0.00660574, validation loss: 0.01348882\n",
      "Epoch 143: train loss: 0.01092445, validation loss: 0.01223763\n",
      "Epoch 144: train loss: 0.00595941, validation loss: 0.00705297\n",
      "Epoch 145: train loss: 0.00621585, validation loss: 0.00872753\n",
      "Epoch 146: train loss: 0.00558845, validation loss: 0.00780691\n",
      "Epoch 147: train loss: 0.00592258, validation loss: 0.01574287\n",
      "Epoch 148: train loss: 0.00544295, validation loss: 0.00873722\n",
      "Epoch 149: train loss: 0.00445351, validation loss: 0.00938968\n",
      "Epoch 150: train loss: 0.00627891, validation loss: 0.00642465\n",
      "Epoch 151: train loss: 0.00440593, validation loss: 0.01480665\n",
      "Epoch 152: train loss: 0.00490397, validation loss: 0.00871834\n",
      "Epoch 153: train loss: 0.00422142, validation loss: 0.00954436\n",
      "Epoch 154: train loss: 0.00548550, validation loss: 0.00855613\n",
      "Epoch 155: train loss: 0.00371264, validation loss: 0.01171239\n",
      "Epoch 156: train loss: 0.00427112, validation loss: 0.00796771\n",
      "Epoch 157: train loss: 0.00326585, validation loss: 0.01102193\n",
      "Epoch 158: train loss: 0.00389653, validation loss: 0.01750152\n",
      "Epoch 159: train loss: 0.00353255, validation loss: 0.00687636\n",
      "Epoch 160: train loss: 0.00376537, validation loss: 0.00796932\n",
      "Epoch 161: train loss: 0.00386118, validation loss: 0.00566646\n",
      "Epoch 162: train loss: 0.00332260, validation loss: 0.00991898\n",
      "Epoch 163: train loss: 0.00409682, validation loss: 0.00998541\n",
      "Epoch 164: train loss: 0.00569977, validation loss: 0.00460560\n",
      "Epoch 165: train loss: 0.00357325, validation loss: 0.00246456\n",
      "Epoch 166: train loss: 0.00383080, validation loss: 0.00420119\n",
      "Epoch 167: train loss: 0.00485996, validation loss: 0.00807967\n",
      "Epoch 168: train loss: 0.00771357, validation loss: 0.00566852\n",
      "Epoch 169: train loss: 0.00599703, validation loss: 0.00528199\n",
      "Epoch 170: train loss: 0.00358924, validation loss: 0.00727520\n",
      "Epoch 171: train loss: 0.00283363, validation loss: 0.00394912\n",
      "Epoch 172: train loss: 0.00359701, validation loss: 0.00738583\n",
      "Epoch 173: train loss: 0.00351858, validation loss: 0.00367956\n",
      "Epoch 174: train loss: 0.00429447, validation loss: 0.00770189\n",
      "Epoch 175: train loss: 0.00499944, validation loss: 0.00604081\n",
      "Epoch 176: train loss: 0.00401428, validation loss: 0.00392882\n",
      "Epoch 177: train loss: 0.00250317, validation loss: 0.00657957\n",
      "Epoch 178: train loss: 0.00254099, validation loss: 0.00274253\n",
      "Epoch 179: train loss: 0.00259447, validation loss: 0.00307862\n",
      "Epoch 180: train loss: 0.00258128, validation loss: 0.00496807\n",
      "Epoch 181: train loss: 0.00253304, validation loss: 0.00352964\n",
      "Epoch 182: train loss: 0.00273874, validation loss: 0.00574780\n",
      "Epoch 183: train loss: 0.00263228, validation loss: 0.01118545\n",
      "Epoch 184: train loss: 0.00307637, validation loss: 0.00226407\n",
      "Epoch 185: train loss: 0.00292042, validation loss: 0.00506386\n",
      "Epoch 186: train loss: 0.00365114, validation loss: 0.00224941\n",
      "Epoch 187: train loss: 0.00220953, validation loss: 0.00343167\n",
      "Epoch 188: train loss: 0.00228789, validation loss: 0.00433498\n",
      "Epoch 189: train loss: 0.00259552, validation loss: 0.00432872\n",
      "Epoch 190: train loss: 0.00236820, validation loss: 0.01011458\n",
      "Epoch 191: train loss: 0.00330454, validation loss: 0.00906908\n",
      "Epoch 192: train loss: 0.00328877, validation loss: 0.00905805\n",
      "Epoch 193: train loss: 0.00291343, validation loss: 0.00313043\n",
      "Epoch 194: train loss: 0.00204800, validation loss: 0.00283839\n",
      "Epoch 195: train loss: 0.00241522, validation loss: 0.00197437\n",
      "Epoch 196: train loss: 0.00225892, validation loss: 0.00241106\n",
      "Epoch 197: train loss: 0.00194833, validation loss: 0.00218954\n",
      "Epoch 198: train loss: 0.00204444, validation loss: 0.00344294\n",
      "Epoch 199: train loss: 0.00212096, validation loss: 0.00352488\n",
      "Epoch 200: train loss: 0.00299224, validation loss: 0.00483468\n",
      "Epoch 201: train loss: 0.00333550, validation loss: 0.00316402\n",
      "Epoch 202: train loss: 0.00289332, validation loss: 0.00220625\n",
      "Epoch 203: train loss: 0.00243954, validation loss: 0.00161623\n",
      "Epoch 204: train loss: 0.00271059, validation loss: 0.00307130\n",
      "Epoch 205: train loss: 0.00181062, validation loss: 0.00375123\n",
      "Epoch 206: train loss: 0.00237069, validation loss: 0.00927865\n",
      "Epoch 207: train loss: 0.00326213, validation loss: 0.00271151\n",
      "Epoch 208: train loss: 0.00325626, validation loss: 0.01625636\n",
      "Epoch 209: train loss: 0.00545732, validation loss: 0.00160404\n",
      "Epoch 210: train loss: 0.00171255, validation loss: 0.00182703\n",
      "Epoch 211: train loss: 0.00191446, validation loss: 0.00182822\n",
      "Epoch 212: train loss: 0.00223035, validation loss: 0.00528112\n",
      "Epoch 213: train loss: 0.00186898, validation loss: 0.00233838\n",
      "Epoch 214: train loss: 0.00189879, validation loss: 0.00272980\n",
      "Epoch 215: train loss: 0.00175903, validation loss: 0.00224898\n",
      "Epoch 216: train loss: 0.00188701, validation loss: 0.00273828\n",
      "Epoch 217: train loss: 0.00253975, validation loss: 0.00359740\n",
      "Epoch 218: train loss: 0.00204613, validation loss: 0.00402338\n",
      "Epoch 219: train loss: 0.00208299, validation loss: 0.00337697\n",
      "Epoch 220: train loss: 0.00199465, validation loss: 0.00324257\n",
      "Epoch 221: train loss: 0.00172856, validation loss: 0.00537165\n",
      "Epoch 222: train loss: 0.00254924, validation loss: 0.00338283\n",
      "Epoch 223: train loss: 0.00289972, validation loss: 0.00132546\n",
      "Epoch 224: train loss: 0.00213407, validation loss: 0.00278026\n",
      "Epoch 225: train loss: 0.00205457, validation loss: 0.00473794\n",
      "Epoch 226: train loss: 0.00234437, validation loss: 0.00323927\n",
      "Epoch 227: train loss: 0.00265402, validation loss: 0.00202596\n",
      "Epoch 228: train loss: 0.00224447, validation loss: 0.00133935\n",
      "Epoch 229: train loss: 0.00167709, validation loss: 0.00185148\n",
      "Epoch 230: train loss: 0.00190670, validation loss: 0.00355043\n",
      "Epoch 231: train loss: 0.00227615, validation loss: 0.00168395\n",
      "Epoch 232: train loss: 0.00179751, validation loss: 0.00126136\n",
      "Epoch 233: train loss: 0.00192755, validation loss: 0.00185814\n",
      "Epoch 234: train loss: 0.00172915, validation loss: 0.00193036\n",
      "Epoch 235: train loss: 0.00171495, validation loss: 0.00148071\n",
      "Epoch 236: train loss: 0.00197251, validation loss: 0.00151796\n",
      "Epoch 237: train loss: 0.00231703, validation loss: 0.00196125\n",
      "Epoch 238: train loss: 0.00179874, validation loss: 0.00137138\n",
      "Epoch 239: train loss: 0.00185704, validation loss: 0.00235216\n",
      "Epoch 240: train loss: 0.00181281, validation loss: 0.00129119\n",
      "Epoch 241: train loss: 0.00192250, validation loss: 0.00137750\n",
      "Epoch 242: train loss: 0.00169071, validation loss: 0.00257963\n",
      "Epoch 243: train loss: 0.00172171, validation loss: 0.00228733\n",
      "Epoch 244: train loss: 0.00198474, validation loss: 0.00109115\n",
      "Epoch 245: train loss: 0.00216471, validation loss: 0.00193221\n",
      "Epoch 246: train loss: 0.00163758, validation loss: 0.00135316\n",
      "Epoch 247: train loss: 0.00143643, validation loss: 0.00185512\n",
      "Epoch 248: train loss: 0.00152108, validation loss: 0.00211544\n",
      "Epoch 249: train loss: 0.00186988, validation loss: 0.00113535\n",
      "Epoch 250: train loss: 0.00170060, validation loss: 0.00228630\n",
      "Epoch 251: train loss: 0.00227440, validation loss: 0.00608258\n",
      "Epoch 252: train loss: 0.00294055, validation loss: 0.00431983\n",
      "Epoch 253: train loss: 0.00211251, validation loss: 0.00144691\n",
      "Epoch 254: train loss: 0.00145767, validation loss: 0.00137408\n",
      "Epoch 255: train loss: 0.00138012, validation loss: 0.00143376\n",
      "Epoch 256: train loss: 0.00155590, validation loss: 0.00131446\n",
      "Epoch 257: train loss: 0.00129143, validation loss: 0.00100517\n",
      "Epoch 258: train loss: 0.00144191, validation loss: 0.00098488\n",
      "Epoch 259: train loss: 0.00143114, validation loss: 0.00221219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260: train loss: 0.00131010, validation loss: 0.00143188\n",
      "Epoch 261: train loss: 0.00151441, validation loss: 0.00268650\n",
      "Epoch 262: train loss: 0.00134272, validation loss: 0.00160613\n",
      "Epoch 263: train loss: 0.00151018, validation loss: 0.00195735\n",
      "Epoch 264: train loss: 0.00127433, validation loss: 0.00150900\n",
      "Epoch 265: train loss: 0.00123119, validation loss: 0.00108152\n",
      "Epoch 266: train loss: 0.00146597, validation loss: 0.00178938\n",
      "Epoch 267: train loss: 0.00138754, validation loss: 0.00151480\n",
      "Epoch 268: train loss: 0.00134431, validation loss: 0.00156968\n",
      "Epoch 269: train loss: 0.00135463, validation loss: 0.00189046\n",
      "Epoch 270: train loss: 0.00149096, validation loss: 0.00151630\n",
      "Epoch 271: train loss: 0.00120947, validation loss: 0.00102501\n",
      "Epoch 272: train loss: 0.00117387, validation loss: 0.00121060\n",
      "Epoch 273: train loss: 0.00121598, validation loss: 0.00201045\n",
      "Epoch 274: train loss: 0.00138811, validation loss: 0.00134017\n",
      "Epoch 275: train loss: 0.00176342, validation loss: 0.00162122\n",
      "Epoch 276: train loss: 0.00149573, validation loss: 0.00102900\n",
      "Epoch 277: train loss: 0.00127533, validation loss: 0.00153180\n",
      "Epoch 278: train loss: 0.00124898, validation loss: 0.00091045\n",
      "Epoch 279: train loss: 0.00105514, validation loss: 0.00127132\n",
      "Epoch 280: train loss: 0.00114679, validation loss: 0.00090681\n",
      "Epoch 281: train loss: 0.00122298, validation loss: 0.00163141\n",
      "Epoch 282: train loss: 0.00145637, validation loss: 0.00098545\n",
      "Epoch 283: train loss: 0.00103261, validation loss: 0.00101264\n",
      "Epoch 284: train loss: 0.00118569, validation loss: 0.00096449\n",
      "Epoch 285: train loss: 0.00109134, validation loss: 0.00080231\n",
      "Epoch 286: train loss: 0.00132205, validation loss: 0.00137572\n",
      "Epoch 287: train loss: 0.00157808, validation loss: 0.00127905\n",
      "Epoch 288: train loss: 0.00124188, validation loss: 0.00101273\n",
      "Epoch 289: train loss: 0.00113905, validation loss: 0.00159831\n",
      "Epoch 290: train loss: 0.00134076, validation loss: 0.00152619\n",
      "Epoch 291: train loss: 0.00141021, validation loss: 0.00089913\n",
      "Epoch 292: train loss: 0.00121497, validation loss: 0.00125371\n",
      "Epoch 293: train loss: 0.00106563, validation loss: 0.00112770\n",
      "Epoch 294: train loss: 0.00098419, validation loss: 0.00097470\n",
      "Epoch 295: train loss: 0.00109800, validation loss: 0.00119549\n",
      "Epoch 296: train loss: 0.00114874, validation loss: 0.00087860\n",
      "Epoch 297: train loss: 0.00093912, validation loss: 0.00082561\n",
      "Epoch 298: train loss: 0.00102651, validation loss: 0.00088652\n",
      "Epoch 299: train loss: 0.00116947, validation loss: 0.00150296\n",
      "Epoch 300: train loss: 0.00103082, validation loss: 0.00111120\n",
      "Epoch 301: train loss: 0.00099340, validation loss: 0.00132971\n",
      "Epoch 302: train loss: 0.00101303, validation loss: 0.00167505\n",
      "Epoch 303: train loss: 0.00109151, validation loss: 0.00085273\n",
      "Epoch 304: train loss: 0.00107088, validation loss: 0.00093442\n",
      "Epoch 305: train loss: 0.00094718, validation loss: 0.00101878\n",
      "Epoch 306: train loss: 0.00089188, validation loss: 0.00097013\n",
      "Epoch 307: train loss: 0.00090927, validation loss: 0.00085571\n",
      "Epoch 308: train loss: 0.00082845, validation loss: 0.00089219\n",
      "Epoch 309: train loss: 0.00095478, validation loss: 0.00137672\n",
      "Epoch 310: train loss: 0.00116858, validation loss: 0.00105310\n",
      "Epoch 311: train loss: 0.00097079, validation loss: 0.00134211\n",
      "Epoch 312: train loss: 0.00104003, validation loss: 0.00098874\n",
      "Epoch 313: train loss: 0.00090770, validation loss: 0.00125896\n",
      "Epoch 314: train loss: 0.00098715, validation loss: 0.00112548\n",
      "Epoch 315: train loss: 0.00085425, validation loss: 0.00078607\n",
      "Epoch 316: train loss: 0.00089772, validation loss: 0.00080209\n",
      "Epoch 317: train loss: 0.00088551, validation loss: 0.00068216\n",
      "Epoch 318: train loss: 0.00088553, validation loss: 0.00102417\n",
      "Epoch 319: train loss: 0.00116896, validation loss: 0.00072901\n",
      "Epoch 320: train loss: 0.00080114, validation loss: 0.00067076\n",
      "Epoch 321: train loss: 0.00083421, validation loss: 0.00079546\n",
      "Epoch 322: train loss: 0.00081086, validation loss: 0.00064532\n",
      "Epoch 323: train loss: 0.00076551, validation loss: 0.00074059\n",
      "Epoch 324: train loss: 0.00080042, validation loss: 0.00068922\n",
      "Epoch 325: train loss: 0.00073728, validation loss: 0.00063232\n",
      "Epoch 326: train loss: 0.00075821, validation loss: 0.00075375\n",
      "Epoch 327: train loss: 0.00079591, validation loss: 0.00077735\n",
      "Epoch 328: train loss: 0.00078979, validation loss: 0.00085779\n",
      "Epoch 329: train loss: 0.00081707, validation loss: 0.00069907\n",
      "Epoch 330: train loss: 0.00079814, validation loss: 0.00080004\n",
      "Epoch 331: train loss: 0.00089541, validation loss: 0.00091057\n",
      "Epoch 332: train loss: 0.00083829, validation loss: 0.00073334\n",
      "Epoch 333: train loss: 0.00074101, validation loss: 0.00090311\n",
      "Epoch 334: train loss: 0.00077062, validation loss: 0.00068488\n",
      "Epoch 335: train loss: 0.00072084, validation loss: 0.00061069\n",
      "Epoch 336: train loss: 0.00075734, validation loss: 0.00073940\n",
      "Epoch 337: train loss: 0.00076137, validation loss: 0.00055047\n",
      "Epoch 338: train loss: 0.00077248, validation loss: 0.00069771\n",
      "Epoch 339: train loss: 0.00073114, validation loss: 0.00068602\n",
      "Epoch 340: train loss: 0.00065991, validation loss: 0.00067014\n",
      "Epoch 341: train loss: 0.00079249, validation loss: 0.00076463\n",
      "Epoch 342: train loss: 0.00076387, validation loss: 0.00081473\n",
      "Epoch 343: train loss: 0.00073977, validation loss: 0.00060389\n",
      "Epoch 344: train loss: 0.00075035, validation loss: 0.00063469\n",
      "Epoch 345: train loss: 0.01114100, validation loss: 0.00169917\n",
      "Epoch 346: train loss: 0.00154590, validation loss: 0.00147234\n",
      "Epoch 347: train loss: 0.00136765, validation loss: 0.00144599\n",
      "Epoch 348: train loss: 0.00132872, validation loss: 0.00121598\n",
      "Epoch 349: train loss: 0.00096583, validation loss: 0.00087805\n",
      "Epoch 350: train loss: 0.00096727, validation loss: 0.00135880\n",
      "Epoch 351: train loss: 0.00108872, validation loss: 0.00095315\n",
      "Epoch 352: train loss: 0.00098993, validation loss: 0.00119606\n",
      "Epoch 353: train loss: 0.00098941, validation loss: 0.00103213\n",
      "Epoch 354: train loss: 0.00099591, validation loss: 0.00069824\n",
      "Epoch 355: train loss: 0.00086452, validation loss: 0.00073562\n",
      "Epoch 356: train loss: 0.00087918, validation loss: 0.00075363\n",
      "Epoch 357: train loss: 0.00089128, validation loss: 0.00084015\n",
      "Epoch 358: train loss: 0.00088231, validation loss: 0.00077630\n",
      "Epoch 359: train loss: 0.00096325, validation loss: 0.00095618\n",
      "Epoch 360: train loss: 0.00081473, validation loss: 0.00059553\n",
      "Epoch 361: train loss: 0.00077895, validation loss: 0.00062697\n",
      "Epoch 362: train loss: 0.00074255, validation loss: 0.00083290\n",
      "Epoch 363: train loss: 0.00077667, validation loss: 0.00061239\n",
      "Epoch 364: train loss: 0.00067545, validation loss: 0.00067834\n",
      "Epoch 365: train loss: 0.00072778, validation loss: 0.00066849\n",
      "Epoch 366: train loss: 0.00078278, validation loss: 0.00088344\n",
      "Epoch 367: train loss: 0.00080209, validation loss: 0.00062826\n",
      "Epoch 368: train loss: 0.00072880, validation loss: 0.00071114\n",
      "Epoch 369: train loss: 0.00079817, validation loss: 0.00069924\n",
      "Epoch 370: train loss: 0.00073096, validation loss: 0.00061590\n",
      "Epoch 371: train loss: 0.00076934, validation loss: 0.00060851\n",
      "Epoch 372: train loss: 0.00070118, validation loss: 0.00051113\n",
      "Epoch 373: train loss: 0.00074141, validation loss: 0.00067506\n",
      "Epoch 374: train loss: 0.00070411, validation loss: 0.00064527\n",
      "Epoch 375: train loss: 0.00074240, validation loss: 0.00055462\n",
      "Epoch 376: train loss: 0.00068818, validation loss: 0.00082724\n",
      "Epoch 377: train loss: 0.00067776, validation loss: 0.00062353\n",
      "Epoch 378: train loss: 0.00075179, validation loss: 0.00084683\n",
      "Epoch 379: train loss: 0.00082934, validation loss: 0.00060925\n",
      "Epoch 380: train loss: 0.00071318, validation loss: 0.00093654\n",
      "Epoch 381: train loss: 0.00070776, validation loss: 0.00060768\n",
      "Epoch 382: train loss: 0.00081502, validation loss: 0.00076027\n",
      "Epoch 383: train loss: 0.00069299, validation loss: 0.00070801\n",
      "Epoch 384: train loss: 0.00074044, validation loss: 0.00085289\n",
      "Epoch 385: train loss: 0.00068130, validation loss: 0.00048747\n",
      "Epoch 386: train loss: 0.00065624, validation loss: 0.00058894\n",
      "Epoch 387: train loss: 0.00067096, validation loss: 0.00071087\n",
      "Epoch 388: train loss: 0.00067237, validation loss: 0.00056325\n",
      "Epoch 389: train loss: 0.00067292, validation loss: 0.00056649\n",
      "Epoch 390: train loss: 0.00071716, validation loss: 0.00102485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391: train loss: 0.00083934, validation loss: 0.00062475\n",
      "Epoch 392: train loss: 0.00071270, validation loss: 0.00064156\n",
      "Epoch 393: train loss: 0.00065033, validation loss: 0.00051405\n",
      "Epoch 394: train loss: 0.00066861, validation loss: 0.00055445\n",
      "Epoch 395: train loss: 0.00067814, validation loss: 0.00053682\n",
      "Epoch 396: train loss: 0.00063032, validation loss: 0.00046313\n",
      "Epoch 397: train loss: 0.00063465, validation loss: 0.00060413\n",
      "Epoch 398: train loss: 0.00064550, validation loss: 0.00064642\n",
      "Epoch 399: train loss: 0.00072120, validation loss: 0.00049763\n",
      "Epoch 400: train loss: 0.00062418, validation loss: 0.00067221\n",
      "Epoch 401: train loss: 0.00066264, validation loss: 0.00057195\n",
      "Epoch 402: train loss: 0.00062489, validation loss: 0.00090653\n",
      "Epoch 403: train loss: 0.01625406, validation loss: 0.00481820\n",
      "Epoch 404: train loss: 0.00250287, validation loss: 0.00163294\n",
      "Epoch 405: train loss: 0.00136703, validation loss: 0.00132000\n",
      "Epoch 406: train loss: 0.00132625, validation loss: 0.00102482\n",
      "Epoch 407: train loss: 0.00109886, validation loss: 0.00090814\n",
      "Epoch 408: train loss: 0.00111914, validation loss: 0.00095407\n",
      "Epoch 409: train loss: 0.00121647, validation loss: 0.00154447\n",
      "Epoch 410: train loss: 0.00118808, validation loss: 0.00101450\n",
      "Epoch 411: train loss: 0.00103402, validation loss: 0.00075969\n",
      "Epoch 412: train loss: 0.00099481, validation loss: 0.00082917\n",
      "Epoch 413: train loss: 0.00101970, validation loss: 0.00109134\n",
      "Epoch 414: train loss: 0.00096009, validation loss: 0.00085094\n",
      "Epoch 415: train loss: 0.00095231, validation loss: 0.00090549\n",
      "Epoch 416: train loss: 0.00098439, validation loss: 0.00083025\n",
      "Epoch 417: train loss: 0.00097407, validation loss: 0.00081013\n",
      "Epoch 418: train loss: 0.00089239, validation loss: 0.00073113\n",
      "Epoch 419: train loss: 0.00098740, validation loss: 0.00092429\n",
      "Epoch 420: train loss: 0.00092615, validation loss: 0.00079653\n",
      "Epoch 421: train loss: 0.00101493, validation loss: 0.00090247\n",
      "Epoch 422: train loss: 0.00086757, validation loss: 0.00091073\n",
      "Epoch 423: train loss: 0.00087378, validation loss: 0.00081359\n",
      "Epoch 424: train loss: 0.00079463, validation loss: 0.00077366\n",
      "Epoch 425: train loss: 0.00084783, validation loss: 0.00073235\n",
      "Epoch 426: train loss: 0.00076961, validation loss: 0.00065084\n",
      "Epoch 427: train loss: 0.00084097, validation loss: 0.00090365\n",
      "Epoch 428: train loss: 0.00085030, validation loss: 0.00149148\n",
      "Epoch 429: train loss: 0.00120945, validation loss: 0.00117597\n",
      "Epoch 430: train loss: 0.00081900, validation loss: 0.00097025\n",
      "Epoch 431: train loss: 0.00077887, validation loss: 0.00075158\n",
      "Epoch 432: train loss: 0.00081025, validation loss: 0.00062084\n",
      "Epoch 433: train loss: 0.00069547, validation loss: 0.00070109\n",
      "Epoch 434: train loss: 0.00070288, validation loss: 0.00067180\n",
      "Epoch 435: train loss: 0.00072362, validation loss: 0.00060778\n",
      "Epoch 436: train loss: 0.00072153, validation loss: 0.00061734\n",
      "Epoch 437: train loss: 0.00072620, validation loss: 0.00099517\n",
      "Epoch 438: train loss: 0.00073073, validation loss: 0.00061634\n",
      "Epoch 439: train loss: 0.00076700, validation loss: 0.00069934\n",
      "Epoch 440: train loss: 0.00079060, validation loss: 0.00077702\n",
      "Epoch 441: train loss: 0.00074786, validation loss: 0.00083007\n",
      "Epoch 442: train loss: 0.00070219, validation loss: 0.00054201\n",
      "Epoch 443: train loss: 0.00067379, validation loss: 0.00068144\n",
      "Epoch 444: train loss: 0.00066183, validation loss: 0.00056517\n",
      "Epoch 445: train loss: 0.00072183, validation loss: 0.00055105\n",
      "Epoch 446: train loss: 0.00068478, validation loss: 0.00086372\n",
      "Epoch 447: train loss: 0.00070564, validation loss: 0.00059106\n",
      "Epoch 448: train loss: 0.00070963, validation loss: 0.00059225\n",
      "Epoch 449: train loss: 0.00069528, validation loss: 0.00064884\n",
      "Epoch 450: train loss: 0.00088303, validation loss: 0.00097156\n",
      "Epoch 451: train loss: 0.00073072, validation loss: 0.00058223\n",
      "Epoch 452: train loss: 0.00067243, validation loss: 0.00081950\n",
      "Epoch 453: train loss: 0.00070835, validation loss: 0.00065808\n",
      "Epoch 454: train loss: 0.00069261, validation loss: 0.00058143\n",
      "Epoch 455: train loss: 0.00066412, validation loss: 0.00087723\n",
      "Epoch 456: train loss: 0.00076502, validation loss: 0.00066853\n",
      "Epoch 457: train loss: 0.00076929, validation loss: 0.00089013\n",
      "Epoch 458: train loss: 0.00085222, validation loss: 0.00061545\n",
      "Epoch 459: train loss: 0.00062719, validation loss: 0.00044119\n",
      "Epoch 460: train loss: 0.00065211, validation loss: 0.00047053\n",
      "Epoch 461: train loss: 0.00065636, validation loss: 0.00051744\n",
      "Epoch 462: train loss: 0.00064507, validation loss: 0.00060618\n",
      "Epoch 463: train loss: 0.00067718, validation loss: 0.00061606\n",
      "Epoch 464: train loss: 0.00066722, validation loss: 0.00054614\n",
      "Epoch 465: train loss: 0.00060954, validation loss: 0.00052511\n",
      "Epoch 466: train loss: 0.00058918, validation loss: 0.00048421\n",
      "Epoch 467: train loss: 0.00061358, validation loss: 0.00048667\n",
      "Epoch 468: train loss: 0.00065206, validation loss: 0.00061322\n",
      "Epoch 469: train loss: 0.00064498, validation loss: 0.00054408\n",
      "Epoch 470: train loss: 0.00062732, validation loss: 0.00053522\n",
      "Epoch 471: train loss: 0.00064630, validation loss: 0.00050992\n",
      "Epoch 472: train loss: 0.00062070, validation loss: 0.00050727\n",
      "Epoch 473: train loss: 0.00064887, validation loss: 0.00068498\n",
      "Epoch 474: train loss: 0.00061001, validation loss: 0.00052691\n",
      "Epoch 475: train loss: 0.00063127, validation loss: 0.00054608\n",
      "Epoch 476: train loss: 0.00065982, validation loss: 0.00050640\n",
      "Epoch 477: train loss: 0.00059150, validation loss: 0.00093296\n",
      "Epoch 478: train loss: 0.01404593, validation loss: 0.00901861\n",
      "Epoch 479: train loss: 0.00416291, validation loss: 0.00116000\n",
      "Epoch 480: train loss: 0.00106329, validation loss: 0.00083863\n",
      "Epoch 481: train loss: 0.00091843, validation loss: 0.00076250\n",
      "Epoch 482: train loss: 0.00081710, validation loss: 0.00069265\n",
      "Epoch 483: train loss: 0.00084364, validation loss: 0.00070171\n",
      "Epoch 484: train loss: 0.00079685, validation loss: 0.00078562\n",
      "Epoch 485: train loss: 0.00075145, validation loss: 0.00072846\n",
      "Epoch 486: train loss: 0.00074972, validation loss: 0.00056961\n",
      "Epoch 487: train loss: 0.00073433, validation loss: 0.00074133\n",
      "Epoch 488: train loss: 0.00068797, validation loss: 0.00059880\n",
      "Epoch 489: train loss: 0.00071374, validation loss: 0.00051927\n",
      "Epoch 490: train loss: 0.00068093, validation loss: 0.00062470\n",
      "Epoch 491: train loss: 0.00073903, validation loss: 0.00066323\n",
      "Epoch 492: train loss: 0.00068392, validation loss: 0.00078602\n",
      "Epoch 493: train loss: 0.00073626, validation loss: 0.00106877\n",
      "Epoch 494: train loss: 0.00074822, validation loss: 0.00052801\n",
      "Epoch 495: train loss: 0.00067984, validation loss: 0.00069720\n",
      "Epoch 496: train loss: 0.00066667, validation loss: 0.00071189\n",
      "Epoch 497: train loss: 0.00073002, validation loss: 0.00070770\n",
      "Epoch 498: train loss: 0.00079833, validation loss: 0.00075191\n",
      "Epoch 499: train loss: 0.00077690, validation loss: 0.00070811\n",
      "Epoch 500: train loss: 0.00072433, validation loss: 0.00073550\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from koopman_core.learning import KoopDnn, KoopmanNetCtrl\n",
    "from koopman_core.util import fit_standardizer\n",
    "\n",
    "standardizer_x_kdnn = fit_standardizer(xs_train, preprocessing.StandardScaler())\n",
    "#standardizer_x_kdnn = None\n",
    "standardizer_u_kdnn = fit_standardizer(us_train, preprocessing.StandardScaler())\n",
    "n_tot = n + net_params['encoder_output_dim'] + int(net_params['first_obs_const'])\n",
    "\n",
    "net = KoopmanNetCtrl(net_params, standardizer_x=standardizer_x_kdnn, standardizer_u=standardizer_u_kdnn)\n",
    "model_koop_dnn = KoopDnn(net)\n",
    "model_koop_dnn.set_datasets(xs_train, t_train, u_train=us_train, x_val=xs_val, u_val=us_val, t_val=t_val)\n",
    "model_koop_dnn.model_pipeline(net_params)\n",
    "model_koop_dnn.construct_koopman_model()\n",
    "sys_koop_dnn = BilinearLiftedDynamics(n_tot, m, model_koop_dnn.A, model_koop_dnn.B, model_koop_dnn.C, \n",
    "                                      model_koop_dnn.basis_encode, continuous_mdl=False, dt=dt, \n",
    "                                      standardizer_x=standardizer_x_kdnn, standardizer_u=standardizer_u_kdnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  1.0000000e+00,  0.0000000e+00,  1.1108225e-02,\n",
       "         0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  1.0000000e+00,  0.0000000e+00,\n",
       "         1.0557983e-02,  0.0000000e+00],\n",
       "       [ 1.1786604e-03, -2.1383153e-06,  7.5332572e-08,  1.0030043e+00,\n",
       "        -1.9111917e-06, -3.2882392e-06],\n",
       "       [ 1.7105874e-04, -9.6479111e-04, -2.9694183e-05,  4.9421778e-05,\n",
       "         1.0020913e+00, -8.8093448e-03],\n",
       "       [-3.4860490e-04, -1.1059882e-03, -8.4219777e-05, -1.4413564e-03,\n",
       "         5.1106745e-06,  9.9100000e-01]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_koop_dnn.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate open-loop prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction performance evaluation parameters:\n",
    "folder_plots = 'figures/'                                          # Path to save plots\n",
    "n_traj_ol = 50                                                     # Number of trajectories to execute, open loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Open loop performance statistics:\n",
      "            Mean squared error    Standard deviation\n",
      "--------  --------------------  --------------------\n",
      "Koop DNN               1e-05                 0.00329\n",
      "bEDMD                  0.00019               0.01362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from koopman_core.util import evaluate_ol_pred\n",
    "from tabulate import tabulate\n",
    "import random as rand\n",
    "\n",
    "xs_ol, us_ol, t_ol = run_experiment(system, n, n_traj_ol, n_pred_dc, t_eval, x0_max,\n",
    "                                      m=m, K_p=K_dc_p, K_d=K_dc_d, noise_var=noise_var)\n",
    "\n",
    "mdl_lst = [sys_koop_dnn, sys_bedmd]\n",
    "mdl_names = ['Koop DNN', 'bEDMD']\n",
    "error, mse, std = [], [], []\n",
    "\n",
    "for sys in mdl_lst:\n",
    "    err_tmp, mse_tmp, std_tmp = evaluate_ol_pred(sys, xs_ol, t_eval, us=us_ol)\n",
    "    error.append(err_tmp)\n",
    "    mse.append(mse_tmp)\n",
    "    std.append(std_tmp)\n",
    "    \n",
    "print('\\nOpen loop performance statistics:')\n",
    "table_data = []\n",
    "for name, mse_mdl, std_mdl in zip(mdl_names, mse, std):\n",
    "    table_data.append([name, \"{:.5f}\".format(mse_mdl), \"{:.5f}\".format(std_mdl)])\n",
    "\n",
    "print(tabulate(table_data, \n",
    "               headers=['Mean squared error', 'Standard deviation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "figwidth = 12\n",
    "lw = 2\n",
    "fs = 14\n",
    "y_lim_gain = 1.2\n",
    "row = 2\n",
    "col = n/row\n",
    "\n",
    "#Plot open loop results:\n",
    "plt.figure(figsize=(figwidth,4))\n",
    "axs = [plt.subplot(row,col,jj+1) for jj in range(n)]\n",
    "\n",
    "for ii, err in enumerate(error):\n",
    "    err_mean = np.mean(err, axis=0)\n",
    "    err_std = np.std(err, axis=0)\n",
    "    \n",
    "    for jj in range(n):\n",
    "        axs[jj].plot(t_eval[1:], err_mean[:,jj], label=mdl_names[ii])\n",
    "        axs[jj].fill_between(t_eval[1:], err_mean[:,jj]-err_std[:,jj], err_mean[:,jj]+err_std[:,jj], alpha=0.1)\n",
    "\n",
    "for jj in range(n):\n",
    "    axs[jj].grid()\n",
    "    axs[jj].set_xlabel('Time (sec)', fontsize=fs)\n",
    "    axs[jj].set_ylabel('$x_'+ str(jj+1) + '$', fontsize=fs)\n",
    "\n",
    "plt.legend(frameon=False, fontsize=fs)\n",
    "stitle=plt.suptitle('Open loop prediction performance of learned models', fontsize=fs+2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.savefig(folder_plots + 'koop_sys_prediction.pdf', format='pdf', dpi=2400, bbox_extra_artists=(stitle,), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0223093  0.00944786]\n",
      "[5.44863724 5.43992453]\n",
      "[ 0.01007821 -0.00539606 -0.01089513  0.00437488]\n",
      "[0.14561805 0.16455691 0.16175582 0.17373891]\n"
     ]
    }
   ],
   "source": [
    "print(standardizer_u_kdnn.mean_)\n",
    "print(standardizer_u_kdnn.scale_)\n",
    "print(standardizer_x_kdnn.mean_)\n",
    "print(standardizer_x_kdnn.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keedmd",
   "language": "python",
   "name": "keedmd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
