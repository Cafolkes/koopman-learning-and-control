{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import os\n",
    "import dill\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import random as rand\n",
    "from sklearn import preprocessing, linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from core.controllers import PDController\n",
    "from core.dynamics import LinearSystemDynamics, ConfigurationDynamics\n",
    "\n",
    "from koopman_core.controllers import OpenLoopController, MPCController,BilinearFBLinController, PerturbedController, LinearLiftedController\n",
    "from koopman_core.dynamics import LinearLiftedDynamics, BilinearLiftedDynamics\n",
    "from koopman_core.learning import Edmd, BilinearEdmd, KoopDnn\n",
    "from koopman_core.basis_functions import PlanarQuadBasis\n",
    "from koopman_core.learning.utils import differentiate_vec\n",
    "from koopman_core.systems import PlanarQuadrotorForceInput\n",
    "\n",
    "class QuadrotorPdOutput(ConfigurationDynamics):\n",
    "    def __init__(self, dynamics, xd, t_d, n, m):\n",
    "        ConfigurationDynamics.__init__(self, dynamics, 1)\n",
    "        self.xd = xd\n",
    "        self.t_d = t_d\n",
    "        self.xd_dot = differentiate_vec(self.xd, self.t_d)\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "\n",
    "    def proportional(self, x, t):\n",
    "        q, q_dot = x[:int(n/2)], x[int(n/2):]\n",
    "        return self.y(q) - self.y_d(t)\n",
    "\n",
    "    def derivative(self, x, t):\n",
    "        q, q_dot = x[:int(n/2)], x[int(n/2):]\n",
    "        return self.dydq(q)@q_dot - self.y_d_dot(t)\n",
    "\n",
    "    def y(self, q):\n",
    "        return q\n",
    "\n",
    "    def dydq(self, q):\n",
    "        return np.eye(int(self.n/2))\n",
    "\n",
    "    def d2ydq2(self, q):\n",
    "        return np.zeros((int(self.n/2), int(self.n/2), int(self.n/2)))\n",
    "\n",
    "    def y_d(self, t):\n",
    "        return self.desired_state_(t)[:int(self.n/2)]\n",
    "\n",
    "    def y_d_dot(self, t):\n",
    "        return self.desired_state_(t)[int(self.n/2):]\n",
    "\n",
    "    def y_d_ddot(self, t):\n",
    "        return self.desired_state_dot_(t)[int(self.n/2):]\n",
    "\n",
    "    def desired_state_(self, t):\n",
    "        return [np.interp(t, self.t_d.flatten(),self.xd[:,ii].flatten()) for ii in range(self.xd.shape[1])]\n",
    "\n",
    "    def desired_state_dot_(self, t):\n",
    "        return [np.interp(t, self.t_d.flatten(),self.xd_dot[:,ii].flatten()) for ii in range(self.xd_dot.shape[1])]\n",
    "\n",
    "class PlanarQuadrotorForceInputDiscrete(PlanarQuadrotorForceInput):\n",
    "    def __init__(self, mass, inertia, prop_arm, g=9.81, dt=1e-2):\n",
    "        PlanarQuadrotorForceInput.__init__(self, mass, inertia, prop_arm, g=g)\n",
    "        self.dt=dt\n",
    "        \n",
    "    def eval_dot(self, x, u, t):\n",
    "        return x + self.dt*self.drift(x, t) + self.dt*np.dot(self.act(x, t),u)\n",
    "\n",
    "    def get_linearization(self, x0, x1, u0, t):\n",
    "        m, J, b, g = self.params\n",
    "        A_lin = np.eye(self.n) + self.dt*np.array([[0, 0, 0, 1, 0, 0],\n",
    "                                                   [0, 0, 0, 0, 1, 0],\n",
    "                                                   [0, 0, 0, 0, 0, 1],\n",
    "                                                   [0, 0, -(1/m)*np.cos(x0[2])*u0[0] -(1/m)*np.cos(x0[2])*u0[1], 0, 0, 0],\n",
    "                                                   [0, 0, -(1/m)*np.sin(x0[2])*u0[0] -(1/m)*np.sin(x0[2])*u0[1], 0, 0, 0],\n",
    "                                                   [0, 0, 0, 0, 0, 0],])\n",
    "\n",
    "        B_lin = self.dt*np.array([[0, 0],\n",
    "                                  [0, 0],\n",
    "                                  [0, 0],\n",
    "                                  [-(1/m)*np.sin(x0[2]), -(1/m)*np.sin(x0[2])],\n",
    "                                  [(1/m)*np.cos(x0[2]), (1/m)*np.cos(x0[2])],\n",
    "                                  [-b/J, b/J]])\n",
    "\n",
    "        if x1 is None:\n",
    "            x1 = A_lin@x0 + B_lin@u0\n",
    "\n",
    "        f_d = self.eval_dot(x0,u0,t)\n",
    "        r_lin = f_d - x1\n",
    "\n",
    "        return A_lin, B_lin, r_lin\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Planar Quadrotor Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a planar quadrotor with states $\\mathbf{x} = [y \\, z \\, \\theta \\, \\dot{y} \\, \\dot{z} \\, \\dot{\\theta}]^T$ and continuous-time dynamics\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{bmatrix} \\ddot{y} \\\\ \\ddot{z} \\\\ \\ddot{\\theta} \\end{bmatrix}\n",
    "    = \\begin{bmatrix}\n",
    "    0\\\\-g\\\\0\n",
    "    \\end{bmatrix} +\n",
    "    \\begin{bmatrix}\n",
    "    -\\frac{1}{m}\\text{sin}\\theta & -\\frac{1}{m}\\text{sin}\\theta\\\\\n",
    "    \\frac{1}{m}\\text{cos}\\theta & \\frac{1}{m}\\text{cos}\\theta\\\\\n",
    "    -\\frac{l_{arm}}{I_{xx}} & \\frac{l_{arm}}{I_{xx}}\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "    T_1 \\\\ T_2\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "where $y,z$ describe the position of the vehicle in a fixed reference frame, $\\theta$ is the orientation of the vehicle,\n",
    "$T_1, T_2$ are the thrust from each of the propellers, $g$ is the gravitational acceleration, $m$ is the vehicle mass,\n",
    "$l_{arm}$ is the distance from the vehicle's center of mass to the center of the propeller, and $I_{xx}$ is the inertia\n",
    "around the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mass = 2.\n",
    "inertia = 1.\n",
    "prop_arm = 0.2\n",
    "gravity = 9.81\n",
    "sys_name = 'planar_quad'\n",
    "system = PlanarQuadrotorForceInput(mass, inertia, prop_arm, g=gravity)\n",
    "\n",
    "# Linearized system specification:\n",
    "n, m = 6, 2                                                         # Number of states, number of control inputs\n",
    "A_nom = np.array([[0., 0., 0., 1., 0., 0.],                         # Linearization of the true system around the origin\n",
    "                  [0., 0., 0., 0., 1., 0.],\n",
    "                  [0., 0., 0., 0., 0., 1.],\n",
    "                  [0., 0., -gravity, 0., 0., 0.],\n",
    "                  [0., 0., 0., 0., 0., 0.],\n",
    "                  [0., 0., 0., 0., 0., 0.]])\n",
    "B_nom = np.array([[0., 0.],                                         # Linearization of the true system around the origin\n",
    "                  [0., 0.],\n",
    "                  [0., 0.],\n",
    "                  [0., 0.],\n",
    "                  [1./mass, 1./mass],\n",
    "                  [-prop_arm/inertia, prop_arm/inertia]])\n",
    "\n",
    "hover_thrust = mass*gravity/m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Collect data for learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To collect data, a nominal controller is designed with LQR on the dynamics's linearization around hover. However, any\n",
    "controller can be used and the method does not require the knowledge of model's linearization. In addition, a\n",
    "exploratory white noise is added to the controller to ensure that the data is sufficiently excited. Note that the system\n",
    "is underactuated and that trajectory optimization is necessary to control the position of the vehicle. We use a\n",
    "simplified trajectory generator based on a model predictive controller for the linearized dynamics. More careful design\n",
    "of the desired trajectory may be necessary for more demanding applications and this is readily compatible with our method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "q_dc, r_dc = 5e2, 1                                                 # State and actuation penalty values, data collection\n",
    "Q_dc = q_dc * np.identity(n)                                        # State penalty matrix, data collection\n",
    "R_dc = r_dc*np.identity(m)                                          # Actuation penalty matrix, data collection\n",
    "P_dc = sc.linalg.solve_continuous_are(A_nom, B_nom, Q_dc, R_dc)     # Algebraic Ricatti equation solution, data collection\n",
    "K_dc = np.linalg.inv(R_dc)@B_nom.T@P_dc                             # LQR feedback gain matrix, data collection\n",
    "K_dc_p = K_dc[:,:int(n/2)]                                          # Proportional control gains, data collection\n",
    "K_dc_d = K_dc[:,int(n/2):]                                          # Derivative control gains, data collection\n",
    "nominal_sys = LinearLiftedDynamics(A_nom, B_nom, np.eye(n), lambda x: x)\n",
    "\n",
    "# Data collection parameters:\n",
    "collect_data = False\n",
    "dt = 1.0e-2                                                         # Time step length\n",
    "traj_length_dc = 2.                                                 # Trajectory length, data collection\n",
    "n_pred_dc = int(traj_length_dc/dt)                                  # Number of time steps, data collection\n",
    "t_train = dt * np.arange(n_pred_dc + 1)                             # Simulation time points\n",
    "n_traj_train = 500                                                  # Number of trajectories to execute, data collection\n",
    "n_traj_val = int(0.25*n_traj_train)\n",
    "noise_var = 2.                                                      # Exploration noise to perturb controller, data collection\n",
    "\n",
    "xmax = np.array([2, 2, np.pi/3, 2.,2.,2.])                          # State constraints, trajectory generation\n",
    "xmin = -xmax\n",
    "umax = np.array([2*hover_thrust, 2*hover_thrust]) - hover_thrust    # Actuation constraint, trajectory generation\n",
    "umin = np.array([0., 0.]) - hover_thrust\n",
    "x0_max = np.array([xmax[0], xmax[1], xmax[2], 1., 1., 1.])          # Initial value limits\n",
    "Q_trajgen = sc.sparse.diags([0,0,0,0,0,0])                          # State penalty matrix, trajectory generation\n",
    "QN_trajgen = sc.sparse.diags([5e1,5e1,5e1,1e1,1e1,1e1])             # Final state penalty matrix, trajectory generation\n",
    "R_trajgen = sc.sparse.eye(m)                                        # Actuation penalty matrix, trajectory generation\n",
    "sub_sample_rate = 1                                                 # Rate to subsample data for training\n",
    "model_fname = 'examples/planar_quad_models'                         # Path to save learned models\n",
    "n_cols = 10                                                         # Number of columns in training data plot\n",
    "save_figures = True\n",
    "directory = os.path.abspath(\"\")                                     # Path to save learned models\n",
    "#dropbox_folder = '/Users/carlaxelfolkestad/Dropbox/Apps/Overleaf/Koopman NMPC (ICRA21)/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if collect_data:\n",
    "    xd = np.empty((n_traj_train + n_traj_val, n_pred_dc + 1, n))\n",
    "    xs = np.empty((n_traj_train + n_traj_val, n_pred_dc + 1, n))\n",
    "    us = np.empty((n_traj_train + n_traj_val, n_pred_dc, m))\n",
    "\n",
    "    plt.figure(figsize=(12, 12 * (n_traj_train + n_traj_val) / (n_cols ** 2)))\n",
    "    for ii in range(n_traj_train+n_traj_val):\n",
    "        x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "        set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "        mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin, umax, xmin, xmax, QN_trajgen, R_trajgen,\n",
    "                                    QN_trajgen, set_pt_dc)\n",
    "        mpc_trajgen.eval(x0, 0)\n",
    "        xd[ii, :, :] = mpc_trajgen.parse_result().T\n",
    "        while abs(x0[0]) + abs(x0[1]) < 1 or np.any(np.isnan(xd[ii, :, :])):\n",
    "            x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "            set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "            mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin, umax, xmin, xmax, QN_trajgen, R_trajgen,\n",
    "                                        QN_trajgen, set_pt_dc)\n",
    "            mpc_trajgen.eval(x0, 0)\n",
    "            xd[ii, :, :] = mpc_trajgen.parse_result().T\n",
    "\n",
    "        output = QuadrotorPdOutput(system, xd[ii, :, :], t_train, n, m)\n",
    "        pd_controller = PDController(output, K_dc_p, K_dc_d)\n",
    "        perturbed_pd_controller = PerturbedController(system, pd_controller, noise_var, const_offset=hover_thrust)\n",
    "        xs[ii, :, :], us[ii, :, :] = system.simulate(x0, perturbed_pd_controller, t_train)\n",
    "\n",
    "        plt.subplot(int(np.ceil((n_traj_train + n_traj_val) / n_cols)), n_cols, ii + 1)\n",
    "        plt.plot(t_train, xs[ii, :, 0], 'b', label='$y$')\n",
    "        plt.plot(t_train, xs[ii, :, 1], 'g', label='$z$')\n",
    "        plt.plot(t_train, xs[ii, :, 2], 'r', label='$\\\\theta$')\n",
    "        plt.plot(t_train, xd[ii, :, 0], '--b', label='$y_d$')\n",
    "        plt.plot(t_train, xd[ii, :, 1], '--g', label='$z_d$')\n",
    "        plt.plot(t_train, xd[ii, :, 2], '--r', label='$\\\\theta_d$')\n",
    "\n",
    "    plt.suptitle(\n",
    "        'Training data \\nx-axis: time (sec), y-axis: state value, $x$ - blue, $xd$ - dotted blue, $\\\\theta$ - red, $\\\\theta_d$ - dotted red',\n",
    "        y=0.94)\n",
    "    plt.show()\n",
    "\n",
    "    xs_train, us_train = xs[:n_traj_train,:,:], us[:n_traj_train, :, :]\n",
    "    xs_val, us_val = xs[n_traj_train:,:,:], us[n_traj_train:, :, :]\n",
    "    \n",
    "    data_list = [xs_train, us_train, t_train, n_traj_train, xs_val, us_val, t_train, n_traj_val]\n",
    "    outfile = open(directory + '/data/' + sys_name + '_data.pickle', 'wb')\n",
    "    dill.dump(data_list, outfile)\n",
    "    outfile.close()\n",
    "else:\n",
    "    infile = open(directory + '/data/' + sys_name + '_data.pickle', 'rb')\n",
    "    xs_train, us_train, t_train, n_traj_train, xs_val, us_val, t_val, n_traj_val = dill.load(infile)\n",
    "    infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Learn a linear model with dynamic mode decomposition (DMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To compare our method with existing techniques, we first learn a linear state space model from data. This is dubbed\n",
    "dynamic mode decomposition. I.e. we use linear regression with LASSO regularization to learn an approximate linear model\n",
    "with model structure\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{\\dot{x}} = A_{dmd}\\mathbf{x} + B_{dmd}\\mathbf{u}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#DMD parameters:\n",
    "alpha_dmd = 9.8e-5                                                  # Regularization strength (LASSO) DMD\n",
    "tune_mdl_dmd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basis = lambda x: x\n",
    "C_dmd = np.eye(n)\n",
    "\n",
    "optimizer_dmd = linear_model.MultiTaskLasso(alpha=alpha_dmd, fit_intercept=False, selection='random')\n",
    "cv_dmd = linear_model.MultiTaskLassoCV(fit_intercept=False, n_jobs=-1, cv=3, selection='random')\n",
    "standardizer_dmd = preprocessing.StandardScaler(with_mean=False)\n",
    "\n",
    "model_dmd = Edmd(n, m, basis, n, n_traj_train, optimizer_dmd, cv=cv_dmd, standardizer=standardizer_dmd, C=C_dmd, \n",
    "                 first_obs_const=False, continuous_mdl=False, dt=dt)\n",
    "xdmd, y_dmd = model_dmd.process(xs_train, us_train-hover_thrust, np.tile(t_train,(n_traj_train,1)), \n",
    "                                downsample_rate=sub_sample_rate)\n",
    "model_dmd.fit(xdmd, y_dmd, cv=tune_mdl_dmd, override_kinematics=True)\n",
    "sys_dmd = LinearLiftedDynamics(model_dmd.A, model_dmd.B, model_dmd.C, model_dmd.basis, continuous_mdl=False, dt=dt)\n",
    "if tune_mdl_dmd:\n",
    "    print('$\\\\alpha$ DMD: ',model_dmd.cv.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Learn a lifted linear model with extended dynamic mode decomposition (EDMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In addition, we compare our method with the current state of the art of Koopman based learning, the extended dynamic mode\n",
    "decomposition. We use a dictionary of nonlinear functions $\\boldsymbol{\\phi(x)}$ to lift the state variables and learn a lifted state space model\n",
    "of the dynamics. I.e. we first lift and then use linear regression with LASSO regularization to learn an approximate\n",
    "lifted linear model with model structure\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{\\dot{z}} = A_{edmd}\\mathbf{z} + B_{edmd}\\mathbf{u}, \\qquad \\mathbf{z} = \\boldsymbol{\\phi(x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#EDMD parameters:\n",
    "alpha_edmd = 2.22e-4                                                 # Regularization strength (LASSO) EDMD\n",
    "tune_mdl_edmd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basis = PlanarQuadBasis(n, poly_deg=3)\n",
    "basis.construct_basis()\n",
    "planar_quad_features = preprocessing.FunctionTransformer(basis.basis)\n",
    "planar_quad_features.fit(np.zeros((1,n)))\n",
    "n_lift_edmd = planar_quad_features.transform((np.zeros((1,n)))).shape[1]\n",
    "C_edmd = np.zeros((n,n_lift_edmd))\n",
    "C_edmd[:,1:n+1] = np.eye(n)\n",
    "\n",
    "optimizer_edmd = linear_model.MultiTaskLasso(alpha=alpha_edmd, fit_intercept=False, selection='random', \n",
    "                                             max_iter=2000)\n",
    "cv_edmd = linear_model.MultiTaskLassoCV(fit_intercept=False, n_jobs=-1, cv=3, selection='random', max_iter=2000)\n",
    "standardizer_edmd = preprocessing.StandardScaler(with_mean=False)\n",
    "\n",
    "model_edmd = Edmd(n, m, basis.basis, n_lift_edmd, n_traj_train, optimizer_edmd, cv=cv_edmd, \n",
    "                  standardizer=standardizer_edmd, C=C_edmd, continuous_mdl=False, dt=dt)\n",
    "X_edmd, y_edmd = model_edmd.process(xs_train, us_train-hover_thrust, np.tile(t_train,(n_traj_train,1)), \n",
    "                                    downsample_rate=sub_sample_rate)\n",
    "model_edmd.fit(X_edmd, y_edmd, cv=tune_mdl_edmd, override_kinematics=True)\n",
    "model_edmd.reduce_mdl()\n",
    "sys_edmd = LinearLiftedDynamics(model_edmd.A, model_edmd.B, model_edmd.C, model_edmd.basis_reduced, \n",
    "                                continuous_mdl=False, dt=dt)\n",
    "if tune_mdl_edmd:\n",
    "    print('$\\\\alpha$ EDMD: ',model_edmd.cv.alpha_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Learn a lifted bilinear model with bilinear extended mode decomposition (bEDMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we use the method developed in the paper to learn a lifted bilinear model of the dynamics, dubbed bilinear\n",
    "extended mode decomposition (bEDMD). I.e. we first lift and then use linear regression with LASSO regularization to learn an approximate\n",
    "lifted linear model with model structure\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{\\dot{z}}=F\\mathbf{z}+\\sum_{i=1}^m G_i\\mathbf{z}\\mathbf{u}_i, \\qquad \\mathbf{z} = \\boldsymbol{\\phi(x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Bilinear EDMD parameters:                                           \n",
    "alpha_bedmd = 6.9e-5  # Regularization strength (LASSO) bEDMD\n",
    "tune_mdl_bedmd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlaxelfolkestad/.conda/envs/keedmd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:1790: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24248935002325567, tolerance: 0.07039349892765395\n",
      "  check_random_state(self.random_state), random)\n"
     ]
    }
   ],
   "source": [
    "n_lift_bedmd = n_lift_edmd\n",
    "C_bedmd = np.zeros((n,n_lift_bedmd))\n",
    "C_bedmd[:,1:n+1] = np.eye(n)\n",
    "\n",
    "basis_bedmd = lambda x: planar_quad_features.transform(x)\n",
    "optimizer_bedmd = linear_model.MultiTaskLasso(alpha=alpha_bedmd, fit_intercept=False, selection='random')\n",
    "cv_bedmd = linear_model.MultiTaskLassoCV(fit_intercept=False, n_jobs=-1, cv=3, selection='random')\n",
    "standardizer_bedmd = preprocessing.StandardScaler(with_mean=False)\n",
    "\n",
    "model_bedmd = BilinearEdmd(n, m, basis_bedmd, n_lift_bedmd, n_traj_train, optimizer_bedmd, cv=cv_bedmd, \n",
    "                           standardizer=standardizer_bedmd, C=C_bedmd, continuous_mdl=False, dt=dt)\n",
    "X_bedmd, y_bedmd = model_bedmd.process(xs_train, us_train-hover_thrust, np.tile(t_train,(n_traj_train,1)), \n",
    "                                       downsample_rate=sub_sample_rate)\n",
    "model_bedmd.fit(X_bedmd, y_bedmd, cv=tune_mdl_bedmd, override_kinematics=True)\n",
    "sys_bedmd = BilinearLiftedDynamics(model_bedmd.n_lift, m, model_bedmd.A, model_bedmd.B, model_bedmd.C, \n",
    "                                   model_bedmd.basis, continuous_mdl=False, dt=dt)\n",
    "if tune_mdl_bedmd:\n",
    "    print('$\\\\alpha$ bilinear EDMD: ', model_bedmd.cv.alpha_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn a lifted bilinear model with Koopman NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state_dim': 6, 'ctrl_dim': 2, 'encoder_hidden_width': 100, 'encoder_hidden_depth': 1, 'encoder_output_dim': 10, 'optimizer': 'adam', 'activation_type': 'tanh', 'lr': 0.001, 'epochs': 200, 'batch_size': 256, 'lin_loss_penalty': 1, 'l2_reg': 0, 'l1_reg': 0, 'first_obs_const': True, 'override_kinematics': True, 'override_C': True, 'dt': 0.01}\n"
     ]
    }
   ],
   "source": [
    "import dill, os, torch\n",
    "\n",
    "load_tuned_params = False\n",
    "\n",
    "if load_tuned_params:\n",
    "    infile = open(os.path.abspath('') + '/data/planar_quad_best_params.pickle', 'rb')\n",
    "    net_params_lst, val_loss, test_loss, open_loop_mse, open_loop_std = dill.load(infile)\n",
    "    infile.close()\n",
    "    net_params = net_params_lst[-3]\n",
    "    \n",
    "    print(open_loop_mse)\n",
    "    plt.figure()\n",
    "    plt.plot(val_loss, label='Validation loss')\n",
    "    plt.plot(test_loss, label='Test loss')\n",
    "    plt.plot(open_loop_mse, label='Open loop mse')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    net_params = {}\n",
    "    net_params['state_dim'] = n\n",
    "    net_params['ctrl_dim'] = m\n",
    "    net_params['encoder_hidden_width'] = 100\n",
    "    net_params['encoder_hidden_depth'] = 1\n",
    "    net_params['encoder_output_dim'] = 10\n",
    "    net_params['optimizer'] = 'adam'\n",
    "    net_params['activation_type'] = 'tanh'\n",
    "    net_params['lr'] = 1e-3\n",
    "    net_params['epochs'] = 200\n",
    "    net_params['batch_size'] = 256 \n",
    "    net_params['lin_loss_penalty'] = 1\n",
    "    net_params['l2_reg'] = 0#1e-6\n",
    "    net_params['l1_reg'] = 0#1e-6\n",
    "    net_params['first_obs_const'] = True\n",
    "    net_params['override_kinematics'] = True\n",
    "    net_params['override_C'] = True\n",
    "    net_params['dt'] = dt\n",
    "\n",
    "print(net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: train loss: 4.20344210, validation loss: 0.44294185\n",
      "Epoch   2: train loss: 0.24370073, validation loss: 0.14547267\n",
      "Epoch   3: train loss: 0.09446752, validation loss: 0.07064260\n",
      "Epoch   4: train loss: 0.04914526, validation loss: 0.04058210\n",
      "Epoch   5: train loss: 0.02958189, validation loss: 0.02581517\n",
      "Epoch   6: train loss: 0.01946732, validation loss: 0.01707399\n",
      "Epoch   7: train loss: 0.01353467, validation loss: 0.01308820\n",
      "Epoch   8: train loss: 0.00986565, validation loss: 0.00920288\n",
      "Epoch   9: train loss: 0.00734180, validation loss: 0.00700937\n",
      "Epoch  10: train loss: 0.00567107, validation loss: 0.00542337\n",
      "Epoch  11: train loss: 0.00437913, validation loss: 0.00398289\n",
      "Epoch  12: train loss: 0.00355034, validation loss: 0.00346214\n",
      "Epoch  13: train loss: 0.00296653, validation loss: 0.00316610\n",
      "Epoch  14: train loss: 0.00258225, validation loss: 0.00297825\n",
      "Epoch  15: train loss: 0.00220987, validation loss: 0.00180924\n",
      "Epoch  16: train loss: 0.00197195, validation loss: 0.00185232\n",
      "Epoch  17: train loss: 0.00174382, validation loss: 0.00164719\n",
      "Epoch  18: train loss: 0.00167728, validation loss: 0.00140700\n",
      "Epoch  19: train loss: 0.00152866, validation loss: 0.00163111\n",
      "Epoch  20: train loss: 0.00189969, validation loss: 0.00148876\n",
      "Epoch  21: train loss: 0.00133052, validation loss: 0.00081346\n",
      "Epoch  22: train loss: 0.00156504, validation loss: 0.00107210\n",
      "Epoch  23: train loss: 0.00109472, validation loss: 0.00169857\n",
      "Epoch  24: train loss: 0.00190652, validation loss: 0.00101774\n",
      "Epoch  25: train loss: 0.00099117, validation loss: 0.00050134\n",
      "Epoch  26: train loss: 0.00124671, validation loss: 0.00065556\n",
      "Epoch  27: train loss: 0.00088965, validation loss: 0.00100047\n",
      "Epoch  28: train loss: 0.00146757, validation loss: 0.00036547\n",
      "Epoch  29: train loss: 0.00077726, validation loss: 0.00091028\n",
      "Epoch  30: train loss: 0.00137749, validation loss: 0.00145307\n",
      "Epoch  31: train loss: 0.00099075, validation loss: 0.00044828\n",
      "Epoch  32: train loss: 0.00081637, validation loss: 0.00027024\n",
      "Epoch  33: train loss: 0.00072119, validation loss: 0.00116972\n",
      "Epoch  34: train loss: 0.00096237, validation loss: 0.00043971\n",
      "Epoch  35: train loss: 0.00072494, validation loss: 0.00196373\n",
      "Epoch  36: train loss: 0.00113553, validation loss: 0.00043418\n",
      "Epoch  37: train loss: 0.00064763, validation loss: 0.00065253\n",
      "Epoch  38: train loss: 0.00094776, validation loss: 0.00067833\n",
      "Epoch  39: train loss: 0.00083372, validation loss: 0.00062546\n",
      "Epoch  40: train loss: 0.00094161, validation loss: 0.00020933\n",
      "Epoch  41: train loss: 0.00095961, validation loss: 0.00083184\n",
      "Epoch  42: train loss: 0.00037937, validation loss: 0.00238147\n",
      "Epoch  43: train loss: 0.00085716, validation loss: 0.00052118\n",
      "Epoch  44: train loss: 0.00081139, validation loss: 0.00051006\n",
      "Epoch  45: train loss: 0.00047319, validation loss: 0.00111531\n",
      "Epoch  46: train loss: 0.00081277, validation loss: 0.00030210\n",
      "Epoch  47: train loss: 0.00046282, validation loss: 0.00069008\n",
      "Epoch  48: train loss: 0.00139116, validation loss: 0.00391197\n",
      "Epoch  49: train loss: 0.00027508, validation loss: 0.00027376\n",
      "Epoch  50: train loss: 0.00081122, validation loss: 0.00057554\n",
      "Epoch  51: train loss: 0.00046415, validation loss: 0.00082277\n",
      "Epoch  52: train loss: 0.00046687, validation loss: 0.00018131\n",
      "Epoch  53: train loss: 0.00096099, validation loss: 0.00029566\n",
      "Epoch  54: train loss: 0.00025008, validation loss: 0.00143664\n",
      "Epoch  55: train loss: 0.00075081, validation loss: 0.00013212\n",
      "Epoch  56: train loss: 0.00046257, validation loss: 0.00018393\n",
      "Epoch  57: train loss: 0.00035613, validation loss: 0.00106712\n",
      "Epoch  58: train loss: 0.00054522, validation loss: 0.00006480\n",
      "Epoch  59: train loss: 0.00077852, validation loss: 0.00012361\n",
      "Epoch  60: train loss: 0.00028107, validation loss: 0.00031050\n",
      "Epoch  61: train loss: 0.00074201, validation loss: 0.00023757\n",
      "Epoch  62: train loss: 0.00068524, validation loss: 0.00063818\n",
      "Epoch  63: train loss: 0.00017451, validation loss: 0.00017311\n",
      "Epoch  64: train loss: 0.00054381, validation loss: 0.00006143\n",
      "Epoch  65: train loss: 0.00039023, validation loss: 0.00111118\n",
      "Epoch  66: train loss: 0.00033625, validation loss: 0.00044208\n",
      "Epoch  67: train loss: 0.00045024, validation loss: 0.00020897\n",
      "Epoch  68: train loss: 0.00049238, validation loss: 0.00141454\n",
      "Epoch  69: train loss: 0.00031020, validation loss: 0.00014905\n"
     ]
    }
   ],
   "source": [
    "from koopman_core.learning import KoopDnn, KoopmanNetCtrl\n",
    "from koopman_core.util import fit_standardizer\n",
    "\n",
    "standardizer_x_kdnn = fit_standardizer(xs_train, preprocessing.StandardScaler())\n",
    "standardizer_u_kdnn = fit_standardizer(us_train-hover_thrust, preprocessing.StandardScaler(with_mean=False))\n",
    "\n",
    "net = KoopmanNetCtrl(net_params, standardizer_x=standardizer_x_kdnn, standardizer_u=standardizer_u_kdnn)\n",
    "model_koop_dnn = KoopDnn(net)\n",
    "model_koop_dnn.set_datasets(xs_train, t_train, u_train=us_train-hover_thrust, x_val=xs_val, u_val=us_val-hover_thrust, t_val=t_train)\n",
    "model_koop_dnn.model_pipeline(net_params)\n",
    "model_koop_dnn.construct_koopman_model()\n",
    "sys_koop_dnn = BilinearLiftedDynamics(model_koop_dnn.net.n_tot, m, model_koop_dnn.A, model_koop_dnn.B, model_koop_dnn.C, model_koop_dnn.basis_encode,\n",
    "                                    continuous_mdl=False, dt=dt, standardizer_x=standardizer_x_kdnn, \n",
    "                                      standardizer_u=standardizer_u_kdnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_koop_dnn.A)\n",
    "print(model_koop_dnn.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = [l[0] for l in model_koop_dnn.train_loss_hist]\n",
    "train_pred_loss = [l[1] for l in model_koop_dnn.train_loss_hist]\n",
    "train_lin_loss = [l[2] for l in model_koop_dnn.train_loss_hist]\n",
    "val_loss = [l[0] for l in model_koop_dnn.val_loss_hist]\n",
    "val_pred_loss = [l[1] for l in model_koop_dnn.val_loss_hist]\n",
    "val_lin_loss = [l[2] for l in model_koop_dnn.val_loss_hist]\n",
    "epochs = np.arange(0, net_params['epochs'])\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(epochs, train_loss, color='tab:orange', label='Training loss')\n",
    "plt.plot(epochs, train_pred_loss, '--', color='tab:orange', label='Training prediction loss')\n",
    "plt.plot(epochs, train_lin_loss, ':', color='tab:orange', label='Training linear loss')\n",
    "plt.plot(epochs, val_loss, color='tab:blue', label='Validation loss')\n",
    "plt.plot(epochs, val_pred_loss, '--', color='tab:blue', label='Validation prediction loss')\n",
    "plt.plot(epochs, val_lin_loss, ':', color='tab:blue', label='Validation linear loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate open loop prediction performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We first evaluate the open loop prediction performance of the proposed method.\n",
    "This is done by generating a new data set in the same way as the training set, predicting the evolution of the system\n",
    "with the control sequence of each trajectory executed in the data set with each of the models, and finally comparing\n",
    "the mean and standard deviation of the error between the true and predicted evolution over the trajectories. The\n",
    "experimental results support what is to be expected from the theory as the error in the $y$ and $z$ terms are\n",
    "significantly lower for the bEDMD method than both DMD and EDMD. The reason for this\n",
    "improvement is that the bEDMD method can capture the nonlinearities present in the actuation matrix of the\n",
    "$(y,z)$-dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction performance evaluation parameters:\n",
    "folder_plots = 'figures/'                                  # Path to save plots\n",
    "n_traj_ol = 50                                                     # Number of trajectories to execute, open loop\n",
    "t_eval = t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from koopman_core.util import evaluate_ol_pred\n",
    "from tabulate import tabulate\n",
    "\n",
    "xs_test = np.empty((n_traj_ol, t_eval.shape[0], n))\n",
    "us_test = np.empty((n_traj_ol, t_eval.shape[0]-1, m))\n",
    "\n",
    "for ii in range(n_traj_ol):\n",
    "    x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "    set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "    mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin, umax, xmin, xmax, QN_trajgen, R_trajgen,\n",
    "                                QN_trajgen, set_pt_dc)\n",
    "    mpc_trajgen.eval(x0, 0)\n",
    "    xd = mpc_trajgen.parse_result().T\n",
    "\n",
    "    while xd[0,0] is None:\n",
    "        x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "        set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "        mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin, umax, xmin, xmax, QN_trajgen, R_trajgen,\n",
    "                                    QN_trajgen, set_pt_dc)\n",
    "        mpc_trajgen.eval(x0, 0)\n",
    "        xd = mpc_trajgen.parse_result().T\n",
    "\n",
    "    output = QuadrotorPdOutput(system, xd, t_eval, n, m)\n",
    "    pd_controller = PDController(output, K_dc_p, K_dc_d)\n",
    "    perturbed_pd_controller = PerturbedController(system, pd_controller, noise_var, const_offset=hover_thrust)\n",
    "    \n",
    "    xs_test[ii,:,:], us_test[ii,:,:] = system.simulate(x0, perturbed_pd_controller, t_eval)\n",
    "    \n",
    "#    mdl_lst = [sys_dmd, sys_edmd, sys_bedmd, sys_koop_dnn]\n",
    "mdl_lst = [sys_bedmd, sys_koop_dnn]\n",
    "#mdl_names = ['DMD', 'EDMD', 'bEDMD', 'Koop DNN']\n",
    "mdl_names = ['bEDMD', 'Koop DNN']\n",
    "error, mse, std = [], [], []\n",
    "\n",
    "for sys in mdl_lst:\n",
    "    err_tmp, mse_tmp, std_tmp = evaluate_ol_pred(sys, xs_test, t_eval, us=us_test-hover_thrust)\n",
    "    error.append(err_tmp)\n",
    "    mse.append(mse_tmp)\n",
    "    std.append(std_tmp)\n",
    "\n",
    "print('\\nOpen loop performance statistics:')\n",
    "table_data = []\n",
    "for name, mse_mdl, std_mdl in zip(mdl_names, mse, std):\n",
    "    table_data.append([name, \"{:.5f}\".format(mse_mdl), \"{:.5f}\".format(std_mdl)])\n",
    "\n",
    "print(tabulate(table_data, \n",
    "               headers=['Mean squared error', 'Standard deviation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "figwidth = 16\n",
    "lw = 2\n",
    "fs = 14\n",
    "y_lim_gain = 1.2\n",
    "row = 2\n",
    "col = n/row\n",
    "\n",
    "#Plot open loop results:\n",
    "plt.figure(figsize=(figwidth,4))\n",
    "axs = [plt.subplot(row,col,jj+1) for jj in range(n)]\n",
    "\n",
    "for ii, err in enumerate(error):\n",
    "    err_mean = np.mean(err, axis=0)\n",
    "    err_std = np.std(err, axis=0)\n",
    "    \n",
    "    for jj in range(n):\n",
    "        axs[jj].plot(t_eval[1:], err_mean[:,jj], label=mdl_names[ii])\n",
    "        axs[jj].fill_between(t_eval[1:], err_mean[:,jj]-err_std[:,jj], err_mean[:,jj]+err_std[:,jj], alpha=0.1)\n",
    "\n",
    "for jj in range(n):\n",
    "    axs[jj].set_xlabel('Time (sec)', fontsize=fs)\n",
    "    axs[jj].set_ylabel('$x_'+ str(jj+1) + '$', fontsize=fs)\n",
    "\n",
    "plt.legend(frameon=False, fontsize=fs)\n",
    "stitle=plt.suptitle('Open loop prediction performance of learned models', fontsize=fs+2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.savefig(folder_plots + 'koop_sys_prediction.pdf', format='pdf', dpi=2400, bbox_extra_artists=(stitle,), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 5\n",
    "x0 = xs_test[ii, 0, :].reshape(1,-1)\n",
    "ctrl = OpenLoopController(sys, standardizer_u_kdnn.transform(us_test[ii, :, :]-hover_thrust), t_train[:-1])\n",
    "z0 = sys.basis(np.atleast_2d(x0)).squeeze()\n",
    "zs_tmp, _ = sys.simulate(z0, ctrl, t_train)\n",
    "xs_pred = standardizer_x_kdnn.inverse_transform(np.dot(sys.C, zs_tmp.T).T)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "for ss in range(3):\n",
    "    plt.subplot(1,3,ss+1)\n",
    "    plt.plot(t_train, xs_test[ii, :, ss], '--', color='tab:orange', label='True')\n",
    "    plt.plot(t_train, xs_pred[:, ss], '--', color='tab:blue', label='Learned')\n",
    "    plt.plot(t_train, xs_test[ii, :, ss+3], color='tab:orange', label='True')\n",
    "    plt.plot(t_train, xs_pred[:, ss+3], color='tab:blue', label='Learned')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### We now study the closed loop performance of the control design. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Closed loop performance evaluation parameters:\n",
    "traj_length=250\n",
    "t_eval = dt * np.arange(traj_length+1)                       # Simulation time points, closed loop\n",
    "Q_mpc = sc.sparse.diags([0,0,0,0,0,0])                       # State penalty matrix, trajectory generation\n",
    "#QN_mpc = sc.sparse.diags([1e5,1e5,1e5,1e5,1e5,1e5])         # Final state penalty matrix, trajectory generation\n",
    "QN_mpc = Q_mpc\n",
    "R_mpc = sc.sparse.eye(m)                                     # Actuation penalty matrix, trajectory generation\n",
    "\n",
    "ctrl_offset = np.array([hover_thrust, hover_thrust])\n",
    "\n",
    "# Design trajectory:\n",
    "x0_cl = np.array([0., 0., 0., 0., 0., 0.])                   # Initial value, closed loop trajectory\n",
    "set_pt_cl = np.array([1.5, 0.5, 0., 0., 0., 0.])              # Desired final value, closed loop trajectory\n",
    "xmax = np.array([2, 2, np.pi/3, 1.,1.,1.])                          # State constraints, trajectory generation\n",
    "xmin = -xmax\n",
    "term_constraint=True\n",
    "\n",
    "# Define initial solution for SQP algorithm:\n",
    "x_init = np.linspace(x0_cl, set_pt_cl, int(traj_length)+1)\n",
    "u_init = hover_thrust*np.ones((m,traj_length)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design controllers for learned DMD, EDMD, and bEDMD models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koopman_core.controllers import MPCController, NonlinearMPCController, BilinearMPCController\n",
    "\n",
    "# Define DMD-based controller:\n",
    "controller_dmd = MPCController(sys_dmd, traj_length, dt, umin, umax, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, terminal_constraint=term_constraint, const_offset=ctrl_offset)\n",
    "\n",
    "# Define EDMD-based controller:\n",
    "controller_edmd = MPCController(sys_edmd, traj_length, dt, umin, umax, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, terminal_constraint=term_constraint, const_offset=ctrl_offset)\n",
    "\n",
    "# Define bEDMD-based controller:\n",
    "controller_bedmd = BilinearMPCController(sys_bedmd, traj_length, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, terminal_constraint=term_constraint)\n",
    "z0_cl = sys_bedmd.basis(x0_cl.reshape((1,-1))).squeeze()\n",
    "z_init = sys_bedmd.basis(x_init)\n",
    "controller_bedmd.construct_controller(z_init, u_init)\n",
    "\n",
    "# Define KDNN-based controller:\n",
    "controller_kdnn = BilinearMPCController(sys_koop_dnn, traj_length, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, \n",
    "                                        terminal_constraint=term_constraint, standardizer_x=standardizer_x_kdnn, standardizer_u=standardizer_u_kdnn)\n",
    "z0_cl_kdnn = sys_koop_dnn.basis(x0_cl.reshape((1,-1))).squeeze()\n",
    "z_init_kdnn = sys_koop_dnn.basis(x_init)\n",
    "u_init_kdnn = standardizer_u_kdnn.transform(u_init)\n",
    "controller_kdnn.construct_controller(z_init_kdnn, u_init_kdnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design controller using full knowledge of nonlinear controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_d = PlanarQuadrotorForceInputDiscrete(mass, inertia, prop_arm, g=gravity, dt=dt)\n",
    "controller_nmpc = NonlinearMPCController(system_d, traj_length, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, terminal_constraint=term_constraint)\n",
    "controller_nmpc.construct_controller(x_init, u_init+hover_thrust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design trajectories with the contructed MPCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 50\n",
    "\n",
    "controller_dmd.eval(x0_cl, 0)\n",
    "xr_dmd = controller_dmd.parse_result()\n",
    "ur_dmd = controller_dmd.get_control_prediction() + hover_thrust\n",
    "\n",
    "controller_edmd.eval(x0_cl, 0)\n",
    "xr_edmd = sys_edmd.C@controller_edmd.parse_result()\n",
    "ur_edmd = controller_edmd.get_control_prediction() + hover_thrust\n",
    "\n",
    "controller_bedmd.solve_to_convergence(z0_cl, 0., z_init, u_init, max_iter=max_iter)\n",
    "xr_bedmd = sys_bedmd.C@controller_bedmd.get_state_prediction().T\n",
    "ur_bedmd = controller_bedmd.get_control_prediction().T\n",
    "\n",
    "controller_kdnn.solve_to_convergence(z0_cl_kdnn, 0., z_init_kdnn, u_init_kdnn, max_iter=max_iter)\n",
    "xr_kdnn = standardizer_x_kdnn.inverse_transform((sys_koop_dnn.C@controller_kdnn.get_state_prediction().T).T).T\n",
    "ur_kdnn = controller_kdnn.get_control_prediction().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_nmpc.solve_to_convergence(x0_cl, 0., x_init, u_init + ctrl_offset.reshape(1,-1), max_iter=max_iter)\n",
    "xr_nmpc = controller_nmpc.get_state_prediction().T\n",
    "ur_nmpc = controller_nmpc.get_control_prediction().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate designed trajectories open loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_controller_dmd = OpenLoopController(system, ur_dmd.T, t_eval[:-1])\n",
    "xs_dmd, us_dmd = system.simulate(x0_cl, ol_controller_dmd, t_eval)\n",
    "xs_dmd, us_dmd = xs_dmd.T, us_dmd.T\n",
    "\n",
    "ol_controller_edmd = OpenLoopController(system, ur_edmd.T, t_eval[:-1])\n",
    "xs_edmd, us_edmd = system.simulate(x0_cl, ol_controller_edmd, t_eval)\n",
    "xs_edmd, us_edmd = xs_edmd.T, us_edmd.T\n",
    "\n",
    "ol_controller_bedmd = OpenLoopController(system, ur_bedmd.T, t_eval[:-1])\n",
    "xs_bedmd, us_bedmd = system.simulate(x0_cl, ol_controller_bedmd, t_eval)\n",
    "xs_bedmd, us_bedmd = xs_bedmd.T, us_bedmd.T\n",
    "\n",
    "ol_controller_kdnn = OpenLoopController(system, ur_kdnn.T, t_eval[:-1])\n",
    "xs_kdnn, us_kdnn = system.simulate(x0_cl, ol_controller_kdnn, t_eval)\n",
    "xs_kdnn, us_kdnn = xs_kdnn.T, us_kdnn.T\n",
    "\n",
    "ol_controller_nmpc = OpenLoopController(system, ur_nmpc.T, t_eval[:-1])\n",
    "xs_nmpc, us_nmpc = system.simulate(x0_cl, ol_controller_nmpc, t_eval)\n",
    "xs_nmpc, us_nmpc = xs_nmpc.T, us_nmpc.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "plot_inds = [0, 1, 2, 3, 4, 5, 0, 1]\n",
    "subplot_inds = [1, 2, 3, 5, 6, 7, 4, 8]\n",
    "labels = ['$y$ (m)', '$z$ (m)', '$\\\\theta$ (rad)', '$\\\\dot{y}$ (m/s)','$\\\\dot{z}$ (m/s)', '$\\\\dot{\\\\theta}$', '$T_1$ (N)','$T_2$ (N)']\n",
    "titles = ['y-coordinates', 'z-coordinates', '$\\\\theta$-coordinates', 'Control inputs']\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:brown', 'tab:green', 'tab:cyan']\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "#plt.suptitle('Trajectory designed with model predictive controllers\\nsolid lines - designed trajectory | dashed lines - open loop simulated trajectory | black dotted lines - state/actuation bounds')\n",
    "for ii in range(8):\n",
    "    ind = plot_inds[ii]\n",
    "    if ii < 6:\n",
    "        ax = plt.subplot(2,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval, xr_dmd[ind,:], colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval, xr_edmd[ind, :], colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval, xr_bedmd[ind, :], colors[2], label='K-MPC')\n",
    "        plt.plot(t_eval, xr_kdnn[ind, :], colors[3], label='KDNN-MPC')\n",
    "        plt.plot(t_eval, xr_nmpc[ind,:], colors[4], label='NMPC')\n",
    "\n",
    "        plt.plot(t_eval, xs_dmd[ind,:], '--', color=colors[0], linewidth=1)\n",
    "        plt.plot(t_eval, xs_edmd[ind, :], '--', color=colors[1], linewidth=1)\n",
    "        plt.plot(t_eval, xs_bedmd[ind, :], '--', color=colors[2], linewidth=1)\n",
    "        plt.plot(t_eval, xs_kdnn[ind, :], '--',  colors[3], linewidth=1)\n",
    "        plt.plot(t_eval, xs_nmpc[ind,:], '--', color=colors[4], linewidth=1)\n",
    "\n",
    "        plt.scatter(t_eval[0], x0_cl[ind], color='g')\n",
    "        plt.scatter(t_eval[-1], set_pt_cl[ind], color='r')\n",
    "        plt.ylabel(labels[ind])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        if ii >= 3:\n",
    "            plt.plot([0, t_eval[-1]], [xmax[ind], xmax[ind]], ':k')\n",
    "            plt.plot([0, t_eval[-1]], [xmin[ind], xmin[ind]], ':k')\n",
    "            #plt.ylim(xmin[ind]-0.1,xmax[ind]+0.1)\n",
    "        if subplot_inds[ii]==1:\n",
    "            plt.legend(loc='upper left', frameon=False)\n",
    "    elif ii < 8:\n",
    "        ax = plt.subplot(2,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval[:-1],ur_dmd[ind,:], color=colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval[:-1], ur_edmd[ind, :], color=colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval[:-1], ur_bedmd[ind, :], color=colors[2], label='K-NMPC')\n",
    "        plt.plot(t_eval[:-1], ur_kdnn[ind, :], color=colors[3], label='KDNN-NMPC')\n",
    "        plt.plot(t_eval[:-1],ur_nmpc[ind,:], color=colors[4], label='NMPC')\n",
    "        plt.plot([0, t_eval[-1]], [umax[ind]+hover_thrust, umax[ind]+hover_thrust], ':k')\n",
    "        plt.plot([0, t_eval[-1]], [umin[ind]+hover_thrust, umin[ind]+hover_thrust], ':k')\n",
    "        plt.ylabel(labels[ii])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        \n",
    "    if subplot_inds[ii] > 4:\n",
    "        plt.xlabel('Time (sec)')\n",
    "    else:\n",
    "        plt.title(titles[subplot_inds[ii]-1])\n",
    "\n",
    "if save_figures:\n",
    "    matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "    matplotlib.rcParams['ps.fonttype'] = 42\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(dropbox_folder + 'planar_quad_trajectory.pdf', format='pdf', dpi=2400)\n",
    "plt.show()\n",
    "\n",
    "cost_ref_dmd = (xr_dmd[:,-1]-set_pt_cl).T@QN_mpc@(xr_dmd[:,-1]-set_pt_cl) + np.sum(np.diag(ur_dmd.T@R_mpc@ur_dmd))\n",
    "cost_ref_edmd = (xr_edmd[:,-1]-set_pt_cl).T@QN_mpc@(xr_edmd[:,-1]-set_pt_cl) + np.sum(np.diag(ur_edmd.T@R_mpc@ur_edmd))\n",
    "cost_ref_bedmd = (xr_bedmd[:,-1]-set_pt_cl).T@QN_mpc@(xr_bedmd[:,-1]-set_pt_cl) + np.sum(np.diag(ur_bedmd.T@R_mpc@ur_bedmd))\n",
    "cost_ref_kdnn = (xr_kdnn[:,-1]-set_pt_cl).T@QN_mpc@(xr_kdnn[:,-1]-set_pt_cl) + np.sum(np.diag(ur_kdnn.T@R_mpc@ur_kdnn))\n",
    "cost_ref_nmpc = (xr_nmpc[:,-1]-set_pt_cl).T@QN_mpc@(xr_nmpc[:,-1]-set_pt_cl) + np.sum(np.diag(ur_nmpc.T@R_mpc@ur_nmpc))\n",
    "\n",
    "dist_ol_dmd = np.linalg.norm(xs_dmd[:,-1] - set_pt_cl)\n",
    "dist_ol_edmd = np.linalg.norm(xs_edmd[:,-1] - set_pt_cl)\n",
    "dist_ol_bedmd = np.linalg.norm(xs_bedmd[:,-1] - set_pt_cl)\n",
    "dist_ol_kdnn = np.linalg.norm(xs_kdnn[:,-1] - set_pt_cl)\n",
    "dist_ol_nmpc = np.linalg.norm(xs_nmpc[:,-1] - set_pt_cl)\n",
    "\n",
    "print('Solution statistics:\\n')\n",
    "print(tabulate([['DMD MPC', \"{:.4f}\".format(cost_ref_dmd/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_dmd), '-','-',sum(controller_dmd.comp_time)], \n",
    "                ['EDMD MPC', \"{:.4f}\".format(cost_ref_edmd/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_edmd),'-','-',sum(controller_edmd.comp_time)], \n",
    "                ['bEDMD MPC', \"{:.4f}\".format(cost_ref_bedmd/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_bedmd), len(controller_bedmd.x_iter), \"{:.4f}\".format(np.mean(controller_bedmd.comp_time)), sum(controller_bedmd.comp_time)],\n",
    "                ['KDNN MPC', \"{:.4f}\".format(cost_ref_kdnn/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_kdnn), len(controller_kdnn.x_iter), \"{:.4f}\".format(np.mean(controller_kdnn.comp_time)), sum(controller_kdnn.comp_time)],\n",
    "                ['NMPC (benchmark)', 1, \"{:.4f}\".format(dist_ol_nmpc), len(controller_nmpc.x_iter), \"{:.4f}\".format(np.mean(controller_nmpc.comp_time)), sum(controller_nmpc.comp_time)]], \n",
    "               headers=['Normalized cost,\\ndesigned trajectory', 'Realized terminal,\\nerror', '# of SQP\\niterations','Mean comp. time\\nper iteration (secs)', 'Total comp.\\ntime (secs)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study evolution of the solution after each iteration of the SQP-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = min(len(controller_nmpc.x_iter),len(controller_bedmd.x_iter))\n",
    "\n",
    "# Calculate cost after each iteration:\n",
    "iter_cost_bedmd, iter_cost_nmpc = [], []\n",
    "\n",
    "ol_controller_init = OpenLoopController(system, u_init, t_eval[:-1])\n",
    "xs_init, _ = system.simulate(x0_cl, ol_controller_init, t_eval)\n",
    "xs_init, us_init = xs_init.T, u_init.T\n",
    "init_cost = (xs_init[:,-1]-set_pt_cl).T@QN_mpc@(xs_init[:,-1]-set_pt_cl) + np.sum(np.diag(us_init.T@R_mpc@us_init))\n",
    "iter_cost_bedmd = [init_cost]\n",
    "iter_cost_kdnn = [init_cost]\n",
    "iter_cost_nmpc = [init_cost]\n",
    "iter_norm_dist_bedmd = [np.linalg.norm(xs_init[:,-1]-set_pt_cl)]\n",
    "iter_norm_dist_kdnn = [np.linalg.norm(xs_init[:,-1]-set_pt_cl)]\n",
    "iter_norm_dist_nmpc = [np.linalg.norm(xs_init[:,-1]-set_pt_cl)]\n",
    "\n",
    "for ii in range(len(controller_bedmd.x_iter)):\n",
    "    ur_bedmd_iter = controller_bedmd.u_iter[ii].T\n",
    "    ol_controller_bedmd_iter = OpenLoopController(system, ur_bedmd_iter, t_eval[:-1])\n",
    "    xs_bedmd_iter, _ = system.simulate(x0_cl, ol_controller_bedmd_iter, t_eval)\n",
    "    xs_bedmd_iter, us_bedmd_iter = xs_bedmd_iter.T, ur_bedmd_iter.T\n",
    "    iter_cost_bedmd.append((xs_bedmd_iter[:,-1]-set_pt_cl).T@QN_mpc@(xs_bedmd_iter[:,-1]-set_pt_cl) + np.sum(np.diag(us_bedmd_iter.T@R_mpc@us_bedmd_iter)))\n",
    "    iter_norm_dist_bedmd.append(np.linalg.norm(xs_bedmd_iter[:,-1]-set_pt_cl))\n",
    "    \n",
    "for ii in range(len(controller_kdnn.x_iter)):\n",
    "    ur_kdnn_iter = standardizer_u_kdnn.inverse_transform(controller_kdnn.u_iter[ii].T)\n",
    "    ol_controller_kdnn_iter = OpenLoopController(system, ur_kdnn_iter, t_eval[:-1])\n",
    "    xs_kdnn_iter, _ = system.simulate(x0_cl, ol_controller_kdnn_iter, t_eval)\n",
    "    xs_kdnn_iter, us_kdnn_iter = xs_kdnn_iter.T, ur_kdnn_iter.T\n",
    "    iter_cost_kdnn.append((xs_kdnn_iter[:,-1]-set_pt_cl).T@QN_mpc@(xs_kdnn_iter[:,-1]-set_pt_cl) + np.sum(np.diag(us_kdnn_iter.T@R_mpc@us_kdnn_iter)))\n",
    "    iter_norm_dist_kdnn.append(np.linalg.norm(xs_kdnn_iter[:,-1]-set_pt_cl))\n",
    "    \n",
    "for ii in range(len(controller_nmpc.x_iter)):\n",
    "    ur_nmpc_iter = controller_nmpc.u_iter[ii].T\n",
    "    ol_controller_nmpc_iter = OpenLoopController(system, ur_nmpc_iter, t_eval[:-1])\n",
    "    xs_nmpc_iter, _ = system.simulate(x0_cl, ol_controller_nmpc_iter, t_eval)\n",
    "    xs_nmpc_iter, us_nmpc_iter = xs_nmpc_iter.T, ur_nmpc_iter.T\n",
    "    iter_cost_nmpc.append((xs_nmpc_iter[:,-1]-set_pt_cl).T@QN_mpc@(xs_nmpc_iter[:,-1]-set_pt_cl) + np.sum(np.diag(us_nmpc_iter.T@R_mpc@us_nmpc_iter)))\n",
    "    iter_norm_dist_nmpc.append(np.linalg.norm(xs_nmpc_iter[:,-1]-set_pt_cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "#plt.suptitle('Control solution after each iteration of the SQP-algorithm for NMPC and K-NMPC')\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(np.arange(n_iter), iter_cost_bedmd[:n_iter]/iter_cost_nmpc[-1], color=colors[2], label='K-NMPC')\n",
    "plt.plot(np.arange(n_iter), iter_cost_kdnn[:n_iter]/iter_cost_nmpc[-1], color=colors[3], label='KDNN-NMPC')\n",
    "plt.plot(np.arange(n_iter), iter_cost_nmpc[:n_iter]/iter_cost_nmpc[-1], color=colors[4], label='NMPC')\n",
    "plt.title('Control effort')\n",
    "plt.ylabel('$||u||$')\n",
    "plt.legend(loc='upper right', frameon=False)\n",
    "plt.xlabel('SQP iteration')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.arange(n_iter), iter_norm_dist_bedmd[:n_iter], color=colors[2], label=labels[2])\n",
    "plt.plot(np.arange(n_iter), iter_norm_dist_kdnn[:n_iter], color=colors[3], label=labels[3])\n",
    "plt.plot(np.arange(n_iter), iter_norm_dist_nmpc[:n_iter], color=colors[4], label=labels[4])\n",
    "plt.ylim(0,5)\n",
    "plt.title('Realized terminal distance from setpoint')\n",
    "plt.ylabel('$||x_N - x_d||$')\n",
    "plt.xlabel('SQP iteration')\n",
    "\n",
    "if save_figures:\n",
    "    matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "    matplotlib.rcParams['ps.fonttype'] = 42\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(dropbox_folder + 'planar_quad_sqp_iterations.pdf', format='pdf', dpi=2400)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Solution statistics\\n')\n",
    "print(tabulate([['Nonlinear MPC', len(controller_nmpc.x_iter), np.mean(controller_nmpc.comp_time), np.std(controller_nmpc.comp_time), sum(controller_nmpc.comp_time)],\n",
    "                ['Koopman bilinear MPC', len(controller_bedmd.x_iter), np.mean(controller_bedmd.comp_time), np.std(controller_bedmd.comp_time), sum(controller_bedmd.comp_time)],\n",
    "                ['Koopman DNN bilinear MPC', len(controller_kdnn.x_iter), np.mean(controller_kdnn.comp_time), np.std(controller_kdnn.comp_time), sum(controller_kdnn.comp_time)]], \n",
    "               headers=['Number of SQP\\niterations','Mean comp. time per\\niteration (secs)', 'Std comp. time per\\niteration (secs)', 'Total comp.\\ntime (secs)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate performance of controllers for closed-loop control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design finite horizon controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koopman_core.controllers import PerturbedController\n",
    "\n",
    "Q_mpc_cl = 5e2*np.diag([1, 1, 1, 2e-1, 2e-1, 2e-1])\n",
    "QN_mpc_cl = Q_mpc_cl\n",
    "R_mpc_cl = np.eye(m)\n",
    "traj_duration = 1.\n",
    "N_cl = int(traj_duration/dt)\n",
    "t_eval_cl=np.arange(300)*dt\n",
    "\n",
    "# Solver settings closed loop:\n",
    "polish_osqp = False\n",
    "max_iter_osqp = 10\n",
    "linsys_solver_osqp = 'qdldl'\n",
    "warm_start_osqp = True\n",
    "\n",
    "controller_dmd_cl = MPCController(sys_dmd, N_cl, dt, umin, umax, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, add_slack=True)\n",
    "controller_dmd_cl = PerturbedController(sys_dmd,controller_dmd_cl,0.,const_offset=hover_thrust, umin=umin, umax=umax)\n",
    "\n",
    "controller_edmd_cl = MPCController(sys_edmd, N_cl, dt, umin, umax, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, add_slack=True)\n",
    "controller_edmd_cl = PerturbedController(sys_edmd,controller_edmd_cl,0.,const_offset=hover_thrust, umin=umin, umax=umax)\n",
    "\n",
    "controller_bedmd_cl = BilinearMPCController(sys_bedmd, N_cl, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, add_slack=True)\n",
    "controller_bedmd_cl.construct_controller(controller_bedmd.cur_z[:N_cl+1,:], controller_bedmd.cur_u[:N_cl,:])\n",
    "controller_bedmd_cl.solve_to_convergence(z0_cl, 0., controller_bedmd.cur_z[:N_cl+1,:], controller_bedmd.cur_u[:N_cl,:], max_iter=max_iter)\n",
    "#controller_bedmd_cl = PerturbedController(sys_bedmd,controller_bedmd_cl,0.,const_offset=hover_thrust, umin=umin, umax=umax)\n",
    "controller_bedmd_cl.update_solver_settings(polish=polish_osqp, max_iter=max_iter_osqp, linsys_solver=linsys_solver_osqp, warm_start=warm_start_osqp)\n",
    "\n",
    "controller_kdnn_cl = BilinearMPCController(sys_koop_dnn, N_cl, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, \n",
    "                                        add_slack=True, standardizer_x=standardizer_x_kdnn, standardizer_u=standardizer_u_kdnn)\n",
    "controller_kdnn_cl.construct_controller(controller_kdnn.cur_z[:N_cl+1,:], controller_kdnn.cur_u[:N_cl,:])\n",
    "controller_kdnn_cl.solve_to_convergence(z0_cl_kdnn, 0., controller_kdnn.cur_z[:N_cl+1,:], controller_kdnn.cur_u[:N_cl,:], max_iter=max_iter)\n",
    "controller_kdnn_cl.update_solver_settings(polish=polish_osqp, max_iter=max_iter_osqp, linsys_solver=linsys_solver_osqp, warm_start=warm_start_osqp)\n",
    "\n",
    "controller_nmpc_cl = NonlinearMPCController(system_d, N_cl, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, add_slack=True)\n",
    "controller_nmpc_cl.construct_controller(controller_nmpc.cur_z[:N_cl+1,:], controller_nmpc.cur_u[:N_cl,:])\n",
    "controller_nmpc_cl.solve_to_convergence(x0_cl, 0., controller_nmpc.cur_z[:N_cl+1,:], controller_nmpc.cur_u[:N_cl,:], max_iter=max_iter)\n",
    "controller_nmpc_cl.update_solver_settings(polish=polish_osqp, max_iter=max_iter_osqp, linsys_solver=linsys_solver_osqp, warm_start=warm_start_osqp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate designed trajectories closed-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_dmd_cl, us_dmd_cl = system.simulate(x0_cl, controller_dmd_cl, t_eval_cl)\n",
    "xs_dmd_cl, us_dmd_cl = xs_dmd_cl.T, us_dmd_cl.T\n",
    "\n",
    "xs_edmd_cl, us_edmd_cl = system.simulate(x0_cl, controller_edmd_cl, t_eval_cl)\n",
    "xs_edmd_cl, us_edmd_cl = xs_edmd_cl.T, us_edmd_cl.T\n",
    "\n",
    "controller_bedmd_cl.comp_time = []\n",
    "xs_bedmd_cl, us_bedmd_cl = system.simulate(x0_cl, controller_bedmd_cl, t_eval_cl)\n",
    "xs_bedmd_cl, us_bedmd_cl = xs_bedmd_cl.T, us_bedmd_cl.T\n",
    "\n",
    "controller_kdnn_cl.comp_time = []\n",
    "xs_kdnn_cl, us_kdnn_cl = system.simulate(x0_cl, controller_kdnn_cl, t_eval_cl)\n",
    "xs_kdnn_cl, us_kdnn_cl = xs_kdnn_cl.T, us_kdnn_cl.T\n",
    "\n",
    "controller_nmpc_cl.comp_time = []\n",
    "xs_nmpc_cl, us_nmpc_cl = system.simulate(x0_cl, controller_nmpc_cl, t_eval_cl)\n",
    "xs_nmpc_cl, us_nmpc_cl = xs_nmpc_cl.T, us_nmpc_cl.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot/analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inds = [0, 1, 2, 0, 1]\n",
    "subplot_inds = [1, 2, 3, 4, 8]\n",
    "\n",
    "plt.figure(figsize=(12,2.5))\n",
    "for ii in range(5):\n",
    "    ind = plot_inds[ii]\n",
    "    if ii < 3:\n",
    "        ax = plt.subplot(1,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval_cl, xs_dmd_cl[ind,:], colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval_cl, xs_edmd_cl[ind, :], colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval_cl, xs_bedmd_cl[ind, :], colors[2], label='K-NMPC')\n",
    "        plt.plot(t_eval_cl, xs_kdnn_cl[ind, :], colors[3], label='KDNN-NMPC')\n",
    "        plt.plot(t_eval_cl, xs_nmpc_cl[ind,:], colors[4], label='NMPC')\n",
    "\n",
    "        plt.scatter(t_eval_cl[0], x0_cl[ind], color='g')\n",
    "        plt.scatter(t_eval_cl[-1], set_pt_cl[ind], color='r')\n",
    "        plt.ylabel(labels[ind])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.title(titles[subplot_inds[ii]-1])\n",
    "        plt.xlabel('Time (sec)')\n",
    "        if subplot_inds[ii]==1:\n",
    "            plt.legend(loc='upper left', frameon=False)\n",
    "            plt.ylim(-0.15,2)\n",
    "    else:\n",
    "        bx = plt.subplot(2,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval_cl[:-1],us_dmd_cl[ind,:], color=colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval_cl[:-1], us_edmd_cl[ind, :], color=colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval_cl[:-1], us_bedmd_cl[ind, :], color=colors[2], label='K-NMPC')\n",
    "        plt.plot(t_eval_cl[:-1], us_kdnn_cl[ind, :], color=colors[3], label='KDNN-NMPC')\n",
    "        plt.plot(t_eval_cl[:-1],us_nmpc_cl[ind,:], color=colors[4], label='NMPC')\n",
    "        plt.plot([0, t_eval_cl[-1]], [umax[ind]+hover_thrust, umax[ind]+hover_thrust], ':k')\n",
    "        plt.plot([0, t_eval_cl[-1]], [umin[ind]+hover_thrust, umin[ind]+hover_thrust], ':k')\n",
    "        plt.ylabel(labels[ii+3])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        if subplot_inds[ii] == 4:\n",
    "            plt.title('Control inputs')\n",
    "        else:\n",
    "            plt.xlabel('Time (sec)')\n",
    "if save_figures:\n",
    "    matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "    matplotlib.rcParams['ps.fonttype'] = 42\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(dropbox_folder + 'planar_quad_closed_loop.pdf', format='pdf', dpi=2400)\n",
    "plt.show()\n",
    "    \n",
    "cost_cl_dmd = np.sum(np.diag((xs_dmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_dmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_dmd_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_dmd_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_dmd_cl.T@R_mpc_cl@us_dmd_cl))\n",
    "cost_cl_edmd = np.sum(np.diag((xs_edmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_edmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_edmd_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_edmd_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_edmd_cl.T@R_mpc_cl@us_edmd_cl))\n",
    "cost_cl_bedmd = np.sum(np.diag((xs_bedmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_bedmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_bedmd_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_bedmd_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_bedmd_cl.T@R_mpc_cl@us_bedmd_cl))\n",
    "cost_cl_kdnn = np.sum(np.diag((xs_kdnn_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_kdnn_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_kdnn_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_kdnn_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_kdnn_cl.T@R_mpc_cl@us_kdnn_cl))\n",
    "cost_cl_nmpc = np.sum(np.diag((xs_nmpc_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_nmpc_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_nmpc_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_nmpc_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_nmpc_cl.T@R_mpc_cl@us_nmpc_cl))\n",
    "\n",
    "print('Solution statistics:\\n')\n",
    "print(tabulate([['DMD MPC', \"{:.4f}\".format(cost_cl_dmd/cost_cl_nmpc), np.mean(controller_dmd_cl.nom_controller.comp_time), np.std(controller_dmd_cl.nom_controller.comp_time)], \n",
    "                ['EDMD MPC', \"{:.4f}\".format(cost_cl_edmd/cost_cl_nmpc),np.mean(controller_edmd_cl.nom_controller.comp_time), np.std(controller_edmd_cl.nom_controller.comp_time)], \n",
    "                ['bEDMD MPC', \"{:.4f}\".format(cost_cl_bedmd/cost_cl_nmpc), np.mean(controller_bedmd_cl.comp_time), np.std(controller_bedmd_cl.comp_time)],\n",
    "                ['DNN bEDMD MPC', \"{:.4f}\".format(cost_cl_kdnn/cost_cl_nmpc), np.mean(controller_kdnn_cl.comp_time), np.std(controller_kdnn_cl.comp_time)],\n",
    "                ['NMPC (benchmark, known model)',1, np.mean(controller_nmpc_cl.comp_time), np.std(controller_nmpc_cl.comp_time)]], \n",
    "               headers=['Normalized cost,\\nrealized trajectory', 'Mean comp. time (secs)', 'std comp. time (secs)']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keedmd",
   "language": "python",
   "name": "keedmd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
