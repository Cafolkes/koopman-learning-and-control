{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import os\n",
    "import dill\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import random as rand\n",
    "from sklearn import preprocessing, linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from core.controllers import PDController\n",
    "from core.dynamics import LinearSystemDynamics, ConfigurationDynamics\n",
    "\n",
    "from koopman_core.controllers import OpenLoopController, MPCController,BilinearFBLinController, PerturbedController, LinearLiftedController\n",
    "from koopman_core.dynamics import LinearLiftedDynamics, BilinearLiftedDynamics\n",
    "from koopman_core.learning import Edmd, BilinearEdmd, KoopDnn\n",
    "from koopman_core.basis_functions import PlanarQuadBasis\n",
    "from koopman_core.learning.utils import differentiate_vec\n",
    "from koopman_core.systems import PlanarQuadrotorForceInput\n",
    "\n",
    "class QuadrotorPdOutput(ConfigurationDynamics):\n",
    "    def __init__(self, dynamics, xd, t_d, n, m):\n",
    "        ConfigurationDynamics.__init__(self, dynamics, 1)\n",
    "        self.xd = xd\n",
    "        self.t_d = t_d\n",
    "        self.xd_dot = differentiate_vec(self.xd, self.t_d)\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "\n",
    "    def proportional(self, x, t):\n",
    "        q, q_dot = x[:int(n/2)], x[int(n/2):]\n",
    "        return self.y(q) - self.y_d(t)\n",
    "\n",
    "    def derivative(self, x, t):\n",
    "        q, q_dot = x[:int(n/2)], x[int(n/2):]\n",
    "        return self.dydq(q)@q_dot - self.y_d_dot(t)\n",
    "\n",
    "    def y(self, q):\n",
    "        return q\n",
    "\n",
    "    def dydq(self, q):\n",
    "        return np.eye(int(self.n/2))\n",
    "\n",
    "    def d2ydq2(self, q):\n",
    "        return np.zeros((int(self.n/2), int(self.n/2), int(self.n/2)))\n",
    "\n",
    "    def y_d(self, t):\n",
    "        return self.desired_state_(t)[:int(self.n/2)]\n",
    "\n",
    "    def y_d_dot(self, t):\n",
    "        return self.desired_state_(t)[int(self.n/2):]\n",
    "\n",
    "    def y_d_ddot(self, t):\n",
    "        return self.desired_state_dot_(t)[int(self.n/2):]\n",
    "\n",
    "    def desired_state_(self, t):\n",
    "        return [np.interp(t, self.t_d.flatten(),self.xd[:,ii].flatten()) for ii in range(self.xd.shape[1])]\n",
    "\n",
    "    def desired_state_dot_(self, t):\n",
    "        return [np.interp(t, self.t_d.flatten(),self.xd_dot[:,ii].flatten()) for ii in range(self.xd_dot.shape[1])]\n",
    "\n",
    "class PlanarQuadrotorForceInputDiscrete(PlanarQuadrotorForceInput):\n",
    "    def __init__(self, mass, inertia, prop_arm, g=9.81, dt=1e-2):\n",
    "        PlanarQuadrotorForceInput.__init__(self, mass, inertia, prop_arm, g=g)\n",
    "        self.dt=dt\n",
    "        \n",
    "    def eval_dot(self, x, u, t):\n",
    "        return x + self.dt*self.drift(x, t) + self.dt*np.dot(self.act(x, t),u)\n",
    "\n",
    "    def get_linearization(self, x0, x1, u0, t):\n",
    "        m, J, b, g = self.params\n",
    "        A_lin = np.eye(self.n) + self.dt*np.array([[0, 0, 0, 1, 0, 0],\n",
    "                                                   [0, 0, 0, 0, 1, 0],\n",
    "                                                   [0, 0, 0, 0, 0, 1],\n",
    "                                                   [0, 0, -(1/m)*np.cos(x0[2])*u0[0] -(1/m)*np.cos(x0[2])*u0[1], 0, 0, 0],\n",
    "                                                   [0, 0, -(1/m)*np.sin(x0[2])*u0[0] -(1/m)*np.sin(x0[2])*u0[1], 0, 0, 0],\n",
    "                                                   [0, 0, 0, 0, 0, 0],])\n",
    "\n",
    "        B_lin = self.dt*np.array([[0, 0],\n",
    "                                  [0, 0],\n",
    "                                  [0, 0],\n",
    "                                  [-(1/m)*np.sin(x0[2]), -(1/m)*np.sin(x0[2])],\n",
    "                                  [(1/m)*np.cos(x0[2]), (1/m)*np.cos(x0[2])],\n",
    "                                  [-b/J, b/J]])\n",
    "\n",
    "        if x1 is None:\n",
    "            x1 = A_lin@x0 + B_lin@u0\n",
    "\n",
    "        f_d = self.eval_dot(x0,u0,t)\n",
    "        r_lin = f_d - x1\n",
    "\n",
    "        return A_lin, B_lin, r_lin\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Planar Quadrotor Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a planar quadrotor with states $\\mathbf{x} = [y \\, z \\, \\theta \\, \\dot{y} \\, \\dot{z} \\, \\dot{\\theta}]^T$ and continuous-time dynamics\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{bmatrix} \\ddot{y} \\\\ \\ddot{z} \\\\ \\ddot{\\theta} \\end{bmatrix}\n",
    "    = \\begin{bmatrix}\n",
    "    0\\\\-g\\\\0\n",
    "    \\end{bmatrix} +\n",
    "    \\begin{bmatrix}\n",
    "    -\\frac{1}{m}\\text{sin}\\theta & -\\frac{1}{m}\\text{sin}\\theta\\\\\n",
    "    \\frac{1}{m}\\text{cos}\\theta & \\frac{1}{m}\\text{cos}\\theta\\\\\n",
    "    -\\frac{l_{arm}}{I_{xx}} & \\frac{l_{arm}}{I_{xx}}\n",
    "    \\end{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "    T_1 \\\\ T_2\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "where $y,z$ describe the position of the vehicle in a fixed reference frame, $\\theta$ is the orientation of the vehicle,\n",
    "$T_1, T_2$ are the thrust from each of the propellers, $g$ is the gravitational acceleration, $m$ is the vehicle mass,\n",
    "$l_{arm}$ is the distance from the vehicle's center of mass to the center of the propeller, and $I_{xx}$ is the inertia\n",
    "around the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mass = 2.\n",
    "inertia = 1.\n",
    "prop_arm = 0.2\n",
    "gravity = 9.81\n",
    "sys_name = 'planar_quad'\n",
    "system = PlanarQuadrotorForceInput(mass, inertia, prop_arm, g=gravity)\n",
    "\n",
    "# Linearized system specification:\n",
    "n, m = 6, 2                                                         # Number of states, number of control inputs\n",
    "A_nom = np.array([[0., 0., 0., 1., 0., 0.],                         # Linearization of the true system around the origin\n",
    "                  [0., 0., 0., 0., 1., 0.],\n",
    "                  [0., 0., 0., 0., 0., 1.],\n",
    "                  [0., 0., -gravity, 0., 0., 0.],\n",
    "                  [0., 0., 0., 0., 0., 0.],\n",
    "                  [0., 0., 0., 0., 0., 0.]])\n",
    "B_nom = np.array([[0., 0.],                                         # Linearization of the true system around the origin\n",
    "                  [0., 0.],\n",
    "                  [0., 0.],\n",
    "                  [0., 0.],\n",
    "                  [1./mass, 1./mass],\n",
    "                  [-prop_arm/inertia, prop_arm/inertia]])\n",
    "\n",
    "hover_thrust = mass*gravity/m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Collect data for learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To collect data, a nominal controller is designed with LQR on the dynamics's linearization around hover. However, any\n",
    "controller can be used and the method does not require the knowledge of model's linearization. In addition, a\n",
    "exploratory white noise is added to the controller to ensure that the data is sufficiently excited. Note that the system\n",
    "is underactuated and that trajectory optimization is necessary to control the position of the vehicle. We use a\n",
    "simplified trajectory generator based on a model predictive controller for the linearized dynamics. More careful design\n",
    "of the desired trajectory may be necessary for more demanding applications and this is readily compatible with our method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "q_dc, r_dc = 5e2, 1                                                 # State and actuation penalty values, data collection\n",
    "Q_dc = q_dc * np.identity(n)                                        # State penalty matrix, data collection\n",
    "R_dc = r_dc*np.identity(m)                                          # Actuation penalty matrix, data collection\n",
    "P_dc = sc.linalg.solve_continuous_are(A_nom, B_nom, Q_dc, R_dc)     # Algebraic Ricatti equation solution, data collection\n",
    "K_dc = np.linalg.inv(R_dc)@B_nom.T@P_dc                             # LQR feedback gain matrix, data collection\n",
    "K_dc_p = K_dc[:,:int(n/2)]                                          # Proportional control gains, data collection\n",
    "K_dc_d = K_dc[:,int(n/2):]                                          # Derivative control gains, data collection\n",
    "nominal_sys = LinearLiftedDynamics(A_nom, B_nom, np.eye(n), lambda x: x)\n",
    "\n",
    "# Data collection parameters:\n",
    "collect_data = False\n",
    "dt = 1.0e-2                                                         # Time step length\n",
    "traj_length_dc = 2.                                                 # Trajectory length, data collection\n",
    "n_pred_dc = int(traj_length_dc/dt)                                  # Number of time steps, data collection\n",
    "t_train = dt * np.arange(n_pred_dc + 1)                             # Simulation time points\n",
    "n_traj_train = 200                                                  # Number of trajectories to execute, data collection\n",
    "n_traj_val = int(0.2*n_traj_train)\n",
    "noise_var = 5.                                                      # Exploration noise to perturb controller, data collection\n",
    "\n",
    "xmax = np.array([2, 2, np.pi/3, 2.,2.,2.])                          # State constraints, trajectory generation\n",
    "xmin = -xmax\n",
    "umax = np.array([2*hover_thrust, 2*hover_thrust]) - hover_thrust    # Actuation constraint, trajectory generation\n",
    "umin = np.array([0., 0.]) - hover_thrust\n",
    "x0_max = np.array([xmax[0], xmax[1], xmax[2], 1., 1., 1.])          # Initial value limits\n",
    "Q_trajgen = sc.sparse.diags([0,0,0,0,0,0])                          # State penalty matrix, trajectory generation\n",
    "QN_trajgen = sc.sparse.diags([5e1,5e1,5e1,1e1,1e1,1e1])             # Final state penalty matrix, trajectory generation\n",
    "R_trajgen = sc.sparse.eye(m)                                        # Actuation penalty matrix, trajectory generation\n",
    "sub_sample_rate = 1                                                 # Rate to subsample data for training\n",
    "model_fname = 'examples/planar_quad_models'                         # Path to save learned models\n",
    "n_cols = 10                                                         # Number of columns in training data plot\n",
    "save_figures = True\n",
    "directory = os.path.abspath(\"\")                                     # Path to save learned models\n",
    "#dropbox_folder = '/Users/carlaxelfolkestad/Dropbox/Apps/Overleaf/Koopman NMPC (ICRA21)/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if collect_data:\n",
    "    xd = np.empty((n_traj_train + n_traj_val, n_pred_dc + 1, n))\n",
    "    xs = np.empty((n_traj_train + n_traj_val, n_pred_dc + 1, n))\n",
    "    us = np.empty((n_traj_train + n_traj_val, n_pred_dc, m))\n",
    "\n",
    "    plt.figure(figsize=(12, 12 * (n_traj_train + n_traj_val) / (n_cols ** 2)))\n",
    "    for ii in range(n_traj_train+n_traj_val):\n",
    "        x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "        set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "        mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin, umax, xmin, xmax, QN_trajgen, R_trajgen,\n",
    "                                    QN_trajgen, set_pt_dc)\n",
    "        mpc_trajgen.eval(x0, 0)\n",
    "        xd[ii, :, :] = mpc_trajgen.parse_result().T\n",
    "        while abs(x0[0]) + abs(x0[1]) < 1 or np.any(np.isnan(xd[ii, :, :])):\n",
    "            x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "            set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "            mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin, umax, xmin, xmax, QN_trajgen, R_trajgen,\n",
    "                                        QN_trajgen, set_pt_dc)\n",
    "            mpc_trajgen.eval(x0, 0)\n",
    "            xd[ii, :, :] = mpc_trajgen.parse_result().T\n",
    "\n",
    "        output = QuadrotorPdOutput(system, xd[ii, :, :], t_train, n, m)\n",
    "        pd_controller = PDController(output, K_dc_p, K_dc_d)\n",
    "        perturbed_pd_controller = PerturbedController(system, pd_controller, noise_var, const_offset=hover_thrust)\n",
    "        xs[ii, :, :], us[ii, :, :] = system.simulate(x0, perturbed_pd_controller, t_train)\n",
    "\n",
    "        plt.subplot(int(np.ceil((n_traj_train + n_traj_val) / n_cols)), n_cols, ii + 1)\n",
    "        plt.plot(t_train, xs[ii, :, 0], 'b', label='$y$')\n",
    "        plt.plot(t_train, xs[ii, :, 1], 'g', label='$z$')\n",
    "        plt.plot(t_train, xs[ii, :, 2], 'r', label='$\\\\theta$')\n",
    "        plt.plot(t_train, xd[ii, :, 0], '--b', label='$y_d$')\n",
    "        plt.plot(t_train, xd[ii, :, 1], '--g', label='$z_d$')\n",
    "        plt.plot(t_train, xd[ii, :, 2], '--r', label='$\\\\theta_d$')\n",
    "\n",
    "    plt.suptitle(\n",
    "        'Training data \\nx-axis: time (sec), y-axis: state value, $x$ - blue, $xd$ - dotted blue, $\\\\theta$ - red, $\\\\theta_d$ - dotted red',\n",
    "        y=0.94)\n",
    "    plt.show()\n",
    "\n",
    "    xs_train, us_train = xs[:n_traj_train,:,:], us[:n_traj_train, :, :]\n",
    "    xs_val, us_val = xs[n_traj_train:,:,:], us[n_traj_train:, :, :]\n",
    "    \n",
    "    data_list = [xs_train, us_train, t_train, n_traj_train, xs_val, us_val, t_train, n_traj_val]\n",
    "    outfile = open(directory + '/data/' + sys_name + '_data.pickle', 'wb')\n",
    "    dill.dump(data_list, outfile)\n",
    "    outfile.close()\n",
    "else:\n",
    "    infile = open(directory + '/data/' + sys_name + '_data.pickle', 'rb')\n",
    "    xs_train, us_train, t_train, n_traj_train, xs_val, us_val, t_val, n_traj_val = dill.load(infile)\n",
    "    infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Learn a linear model with dynamic mode decomposition (DMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To compare our method with existing techniques, we first learn a linear state space model from data. This is dubbed\n",
    "dynamic mode decomposition. I.e. we use linear regression with LASSO regularization to learn an approximate linear model\n",
    "with model structure\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{\\dot{x}} = A_{dmd}\\mathbf{x} + B_{dmd}\\mathbf{u}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#DMD parameters:\n",
    "alpha_dmd = 9.8e-5                                                  # Regularization strength (LASSO) DMD\n",
    "tune_mdl_dmd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basis = lambda x: x\n",
    "C_dmd = np.eye(n)\n",
    "\n",
    "optimizer_dmd = linear_model.MultiTaskLasso(alpha=alpha_dmd, fit_intercept=False, selection='random')\n",
    "cv_dmd = linear_model.MultiTaskLassoCV(fit_intercept=False, n_jobs=-1, cv=3, selection='random')\n",
    "standardizer_dmd = preprocessing.StandardScaler(with_mean=False)\n",
    "\n",
    "model_dmd = Edmd(n, m, basis, n, n_traj_train, optimizer_dmd, cv=cv_dmd, standardizer=standardizer_dmd, C=C_dmd, \n",
    "                 first_obs_const=False, continuous_mdl=False, dt=dt)\n",
    "xdmd, y_dmd = model_dmd.process(xs_train, us_train-hover_thrust, np.tile(t_train,(n_traj_train,1)), \n",
    "                                downsample_rate=sub_sample_rate)\n",
    "model_dmd.fit(xdmd, y_dmd, cv=tune_mdl_dmd, override_kinematics=True)\n",
    "sys_dmd = LinearLiftedDynamics(model_dmd.A, model_dmd.B, model_dmd.C, model_dmd.basis, continuous_mdl=False, dt=dt)\n",
    "if tune_mdl_dmd:\n",
    "    print('$\\\\alpha$ DMD: ',model_dmd.cv.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Learn a lifted linear model with extended dynamic mode decomposition (EDMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In addition, we compare our method with the current state of the art of Koopman based learning, the extended dynamic mode\n",
    "decomposition. We use a dictionary of nonlinear functions $\\boldsymbol{\\phi(x)}$ to lift the state variables and learn a lifted state space model\n",
    "of the dynamics. I.e. we first lift and then use linear regression with LASSO regularization to learn an approximate\n",
    "lifted linear model with model structure\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{\\dot{z}} = A_{edmd}\\mathbf{z} + B_{edmd}\\mathbf{u}, \\qquad \\mathbf{z} = \\boldsymbol{\\phi(x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#EDMD parameters:\n",
    "alpha_edmd = 2.22e-4                                                 # Regularization strength (LASSO) EDMD\n",
    "tune_mdl_edmd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "basis = PlanarQuadBasis(n, poly_deg=3)\n",
    "basis.construct_basis()\n",
    "planar_quad_features = preprocessing.FunctionTransformer(basis.basis)\n",
    "planar_quad_features.fit(np.zeros((1,n)))\n",
    "n_lift_edmd = planar_quad_features.transform((np.zeros((1,n)))).shape[1]\n",
    "C_edmd = np.zeros((n,n_lift_edmd))\n",
    "C_edmd[:,1:n+1] = np.eye(n)\n",
    "\n",
    "optimizer_edmd = linear_model.MultiTaskLasso(alpha=alpha_edmd, fit_intercept=False, selection='random', \n",
    "                                             max_iter=2000)\n",
    "cv_edmd = linear_model.MultiTaskLassoCV(fit_intercept=False, n_jobs=-1, cv=3, selection='random', max_iter=2000)\n",
    "standardizer_edmd = preprocessing.StandardScaler(with_mean=False)\n",
    "\n",
    "model_edmd = Edmd(n, m, basis.basis, n_lift_edmd, n_traj_train, optimizer_edmd, cv=cv_edmd, \n",
    "                  standardizer=standardizer_edmd, C=C_edmd, continuous_mdl=False, dt=dt)\n",
    "X_edmd, y_edmd = model_edmd.process(xs_train, us_train-hover_thrust, np.tile(t_train,(n_traj_train,1)), \n",
    "                                    downsample_rate=sub_sample_rate)\n",
    "model_edmd.fit(X_edmd, y_edmd, cv=tune_mdl_edmd, override_kinematics=True)\n",
    "model_edmd.reduce_mdl()\n",
    "sys_edmd = LinearLiftedDynamics(model_edmd.A, model_edmd.B, model_edmd.C, model_edmd.basis_reduced, \n",
    "                                continuous_mdl=False, dt=dt)\n",
    "if tune_mdl_edmd:\n",
    "    print('$\\\\alpha$ EDMD: ',model_edmd.cv.alpha_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Learn a lifted bilinear model with bilinear extended mode decomposition (bEDMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we use the method developed in the paper to learn a lifted bilinear model of the dynamics, dubbed bilinear\n",
    "extended mode decomposition (bEDMD). I.e. we first lift and then use linear regression with LASSO regularization to learn an approximate\n",
    "lifted linear model with model structure\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf{\\dot{z}}=F\\mathbf{z}+\\sum_{i=1}^m G_i\\mathbf{z}\\mathbf{u}_i, \\qquad \\mathbf{z} = \\boldsymbol{\\phi(x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Bilinear EDMD parameters:                                           \n",
    "alpha_bedmd = 6.9e-5  # Regularization strength (LASSO) bEDMD\n",
    "tune_mdl_bedmd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlaxelfolkestad/.conda/envs/keedmd/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:1790: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2962602995612684, tolerance: 0.04539497581718174\n",
      "  check_random_state(self.random_state), random)\n"
     ]
    }
   ],
   "source": [
    "n_lift_bedmd = n_lift_edmd\n",
    "C_bedmd = np.zeros((n,n_lift_bedmd))\n",
    "C_bedmd[:,1:n+1] = np.eye(n)\n",
    "\n",
    "basis_bedmd = lambda x: planar_quad_features.transform(x)\n",
    "optimizer_bedmd = linear_model.MultiTaskLasso(alpha=alpha_bedmd, fit_intercept=False, selection='random')\n",
    "cv_bedmd = linear_model.MultiTaskLassoCV(fit_intercept=False, n_jobs=-1, cv=3, selection='random')\n",
    "standardizer_bedmd = preprocessing.StandardScaler(with_mean=False)\n",
    "\n",
    "model_bedmd = BilinearEdmd(n, m, basis_bedmd, n_lift_bedmd, n_traj_train, optimizer_bedmd, cv=cv_bedmd, \n",
    "                           standardizer=standardizer_bedmd, C=C_bedmd, continuous_mdl=False, dt=dt)\n",
    "X_bedmd, y_bedmd = model_bedmd.process(xs_train, us_train, np.tile(t_train,(n_traj_train,1)), \n",
    "                                       downsample_rate=sub_sample_rate)\n",
    "model_bedmd.fit(X_bedmd, y_bedmd, cv=tune_mdl_bedmd, override_kinematics=True)\n",
    "sys_bedmd = BilinearLiftedDynamics(model_bedmd.n_lift, m, model_bedmd.A, model_bedmd.B, model_bedmd.C, \n",
    "                                   model_bedmd.basis, continuous_mdl=False, dt=dt)\n",
    "if tune_mdl_bedmd:\n",
    "    print('$\\\\alpha$ bilinear EDMD: ', model_bedmd.cv.alpha_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn a lifted bilinear model with Koopman NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state_dim': 6, 'ctrl_dim': 2, 'encoder_hidden_width': 100, 'encoder_hidden_depth': 1, 'encoder_output_dim': 10, 'optimizer': 'adam', 'activation_type': 'tanh', 'lr': 0.002, 'epochs': 500, 'batch_size': 64, 'lin_loss_penalty': 0.9, 'l2_reg': 1e-05, 'l1_reg': 1e-05, 'first_obs_const': True, 'override_kinematics': True, 'dt': 0.01}\n"
     ]
    }
   ],
   "source": [
    "import dill, os, torch\n",
    "\n",
    "load_tuned_params = False\n",
    "\n",
    "if load_tuned_params:\n",
    "    infile = open(os.path.abspath('') + '/data/planar_quad_best_params.pickle', 'rb')\n",
    "    net_params_lst, val_loss, test_loss, open_loop_mse, open_loop_std = dill.load(infile)\n",
    "    infile.close()\n",
    "    net_params = net_params_lst[-2]\n",
    "    \n",
    "    print(open_loop_mse)\n",
    "    plt.figure()\n",
    "    plt.plot(val_loss, label='Validation loss')\n",
    "    plt.plot(test_loss, label='Test loss')\n",
    "    plt.plot(open_loop_mse, label='Open loop mse')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    net_params = {}\n",
    "    net_params['state_dim'] = n\n",
    "    net_params['ctrl_dim'] = m\n",
    "    net_params['encoder_hidden_width'] = 100\n",
    "    net_params['encoder_hidden_depth'] = 1\n",
    "    net_params['encoder_output_dim'] = 10\n",
    "    net_params['optimizer'] = 'adam'\n",
    "    net_params['activation_type'] = 'tanh'\n",
    "    net_params['lr'] = 2e-3\n",
    "    net_params['epochs'] = 500\n",
    "    net_params['batch_size'] = 64\n",
    "    net_params['lin_loss_penalty'] = 0.9\n",
    "    net_params['l2_reg'] = 1e-5\n",
    "    net_params['l1_reg'] = 1e-5\n",
    "    net_params['first_obs_const'] = True\n",
    "    net_params['override_kinematics'] = True \n",
    "    net_params['dt'] = dt\n",
    "\n",
    "print(net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: train loss: 0.83987385, validation loss: 0.05237851\n",
      "Epoch   2: train loss: 0.03493781, validation loss: 0.02700283\n",
      "Epoch   3: train loss: 0.01957339, validation loss: 0.01717537\n",
      "Epoch   4: train loss: 0.01313558, validation loss: 0.01181021\n",
      "Epoch   5: train loss: 0.01011370, validation loss: 0.00920760\n",
      "Epoch   6: train loss: 0.00803489, validation loss: 0.00766484\n",
      "Epoch   7: train loss: 0.00682834, validation loss: 0.00628969\n",
      "Epoch   8: train loss: 0.00582382, validation loss: 0.00618856\n",
      "Epoch   9: train loss: 0.00505004, validation loss: 0.00505526\n",
      "Epoch  10: train loss: 0.00457169, validation loss: 0.00424122\n",
      "Epoch  11: train loss: 0.00389136, validation loss: 0.00345917\n",
      "Epoch  12: train loss: 0.00346139, validation loss: 0.00310732\n",
      "Epoch  13: train loss: 0.00336620, validation loss: 0.00290759\n",
      "Epoch  14: train loss: 0.00283627, validation loss: 0.00296010\n",
      "Epoch  15: train loss: 0.00274254, validation loss: 0.00291216\n",
      "Epoch  16: train loss: 0.00255745, validation loss: 0.00236395\n",
      "Epoch  17: train loss: 0.00237495, validation loss: 0.00270686\n",
      "Epoch  18: train loss: 0.00245489, validation loss: 0.00277634\n",
      "Epoch  19: train loss: 0.00210602, validation loss: 0.00208352\n",
      "Epoch  20: train loss: 0.00219976, validation loss: 0.00195366\n",
      "Epoch  21: train loss: 0.00199953, validation loss: 0.00192631\n",
      "Epoch  22: train loss: 0.00204750, validation loss: 0.00173640\n",
      "Epoch  23: train loss: 0.00188270, validation loss: 0.00185583\n",
      "Epoch  24: train loss: 0.00188003, validation loss: 0.00155221\n",
      "Epoch  25: train loss: 0.00173288, validation loss: 0.00158705\n",
      "Epoch  26: train loss: 0.00157185, validation loss: 0.00146233\n",
      "Epoch  27: train loss: 0.00152548, validation loss: 0.00154716\n",
      "Epoch  28: train loss: 0.00155629, validation loss: 0.00130435\n",
      "Epoch  29: train loss: 0.00142742, validation loss: 0.00151349\n",
      "Epoch  30: train loss: 0.00148176, validation loss: 0.00123387\n",
      "Epoch  31: train loss: 0.00132604, validation loss: 0.00137011\n",
      "Epoch  32: train loss: 0.00143850, validation loss: 0.00130808\n",
      "Epoch  33: train loss: 0.00124614, validation loss: 0.00128847\n",
      "Epoch  34: train loss: 0.00139404, validation loss: 0.00113551\n",
      "Epoch  35: train loss: 0.00128447, validation loss: 0.00121933\n",
      "Epoch  36: train loss: 0.00127699, validation loss: 0.00199773\n",
      "Epoch  37: train loss: 0.00128231, validation loss: 0.00117102\n",
      "Epoch  38: train loss: 0.00129146, validation loss: 0.00121639\n",
      "Epoch  39: train loss: 0.00124834, validation loss: 0.00117312\n",
      "Epoch  40: train loss: 0.00116690, validation loss: 0.00123262\n",
      "Epoch  41: train loss: 0.00136537, validation loss: 0.00112271\n",
      "Epoch  42: train loss: 0.00111182, validation loss: 0.00116538\n",
      "Epoch  43: train loss: 0.00141689, validation loss: 0.00108573\n",
      "Epoch  44: train loss: 0.00109733, validation loss: 0.00108041\n",
      "Epoch  45: train loss: 0.00116461, validation loss: 0.00151147\n",
      "Epoch  46: train loss: 0.00117290, validation loss: 0.00158912\n",
      "Epoch  47: train loss: 0.00122001, validation loss: 0.00112423\n",
      "Epoch  48: train loss: 0.00114950, validation loss: 0.00116154\n",
      "Epoch  49: train loss: 0.00113782, validation loss: 0.00237369\n",
      "Epoch  50: train loss: 0.00113596, validation loss: 0.00104838\n",
      "Epoch  51: train loss: 0.00110707, validation loss: 0.00103108\n",
      "Epoch  52: train loss: 0.00110778, validation loss: 0.00101059\n",
      "Epoch  53: train loss: 0.00110946, validation loss: 0.00103278\n",
      "Epoch  54: train loss: 0.00112185, validation loss: 0.00104925\n",
      "Epoch  55: train loss: 0.00107419, validation loss: 0.00112262\n",
      "Epoch  56: train loss: 0.00102828, validation loss: 0.00115613\n",
      "Epoch  57: train loss: 0.00107707, validation loss: 0.00094456\n",
      "Epoch  58: train loss: 0.00106689, validation loss: 0.00096566\n",
      "Epoch  59: train loss: 0.00107670, validation loss: 0.00096695\n",
      "Epoch  60: train loss: 0.00109940, validation loss: 0.00123379\n",
      "Epoch  61: train loss: 0.00101799, validation loss: 0.00116202\n",
      "Epoch  62: train loss: 0.00109757, validation loss: 0.00111467\n",
      "Epoch  63: train loss: 0.00104752, validation loss: 0.00108470\n",
      "Epoch  64: train loss: 0.00107661, validation loss: 0.00130849\n",
      "Epoch  65: train loss: 0.00108866, validation loss: 0.00095026\n",
      "Epoch  66: train loss: 0.00095126, validation loss: 0.00090643\n",
      "Epoch  67: train loss: 0.00106022, validation loss: 0.00091502\n",
      "Epoch  68: train loss: 0.00104568, validation loss: 0.00116917\n",
      "Epoch  69: train loss: 0.00106251, validation loss: 0.00091529\n",
      "Epoch  70: train loss: 0.00096358, validation loss: 0.00095330\n",
      "Epoch  71: train loss: 0.00114956, validation loss: 0.00086128\n",
      "Epoch  72: train loss: 0.00094765, validation loss: 0.00096880\n",
      "Epoch  73: train loss: 0.00107727, validation loss: 0.00091796\n",
      "Epoch  74: train loss: 0.00096455, validation loss: 0.00107408\n",
      "Epoch  75: train loss: 0.00103601, validation loss: 0.00089874\n",
      "Epoch  76: train loss: 0.00095787, validation loss: 0.00094691\n",
      "Epoch  77: train loss: 0.00098629, validation loss: 0.00088602\n",
      "Epoch  78: train loss: 0.00098947, validation loss: 0.00084410\n",
      "Epoch  79: train loss: 0.00113719, validation loss: 0.00109191\n",
      "Epoch  80: train loss: 0.00096194, validation loss: 0.00090945\n",
      "Epoch  81: train loss: 0.00096306, validation loss: 0.00104691\n",
      "Epoch  82: train loss: 0.00101633, validation loss: 0.00091201\n",
      "Epoch  83: train loss: 0.00095878, validation loss: 0.00136275\n",
      "Epoch  84: train loss: 0.00098025, validation loss: 0.00115743\n",
      "Epoch  85: train loss: 0.00116454, validation loss: 0.00104729\n",
      "Epoch  86: train loss: 0.00089481, validation loss: 0.00080956\n",
      "Epoch  87: train loss: 0.00092819, validation loss: 0.00084171\n",
      "Epoch  88: train loss: 0.00092160, validation loss: 0.00096528\n",
      "Epoch  89: train loss: 0.00109475, validation loss: 0.00092402\n",
      "Epoch  90: train loss: 0.00093489, validation loss: 0.00088652\n",
      "Epoch  91: train loss: 0.00093791, validation loss: 0.00083569\n",
      "Epoch  92: train loss: 0.00102192, validation loss: 0.00094489\n",
      "Epoch  93: train loss: 0.00090513, validation loss: 0.00086479\n",
      "Epoch  94: train loss: 0.00095147, validation loss: 0.00119809\n",
      "Epoch  95: train loss: 0.00092695, validation loss: 0.00080364\n",
      "Epoch  96: train loss: 0.00099638, validation loss: 0.00093162\n",
      "Epoch  97: train loss: 0.00087913, validation loss: 0.00083438\n",
      "Epoch  98: train loss: 0.00091090, validation loss: 0.00098316\n",
      "Epoch  99: train loss: 0.00094779, validation loss: 0.00081578\n",
      "Epoch 100: train loss: 0.00089258, validation loss: 0.00090392\n",
      "Epoch 101: train loss: 0.00089861, validation loss: 0.00088606\n",
      "Epoch 102: train loss: 0.00092759, validation loss: 0.00102856\n",
      "Epoch 103: train loss: 0.00085734, validation loss: 0.00088885\n",
      "Epoch 104: train loss: 0.00083256, validation loss: 0.00099404\n",
      "Epoch 105: train loss: 0.00087939, validation loss: 0.00090487\n",
      "Epoch 106: train loss: 0.00103542, validation loss: 0.00078455\n",
      "Epoch 107: train loss: 0.00085079, validation loss: 0.00078781\n",
      "Epoch 108: train loss: 0.00079085, validation loss: 0.00080771\n",
      "Epoch 109: train loss: 0.00081416, validation loss: 0.00138487\n",
      "Epoch 110: train loss: 0.00088014, validation loss: 0.00071498\n",
      "Epoch 111: train loss: 0.00083749, validation loss: 0.00075980\n",
      "Epoch 112: train loss: 0.00081805, validation loss: 0.00072322\n",
      "Epoch 113: train loss: 0.00078840, validation loss: 0.00080157\n",
      "Epoch 114: train loss: 0.00079238, validation loss: 0.00074998\n",
      "Epoch 115: train loss: 0.00082375, validation loss: 0.00069753\n",
      "Epoch 116: train loss: 0.00079088, validation loss: 0.00067731\n",
      "Epoch 117: train loss: 0.00080219, validation loss: 0.00069348\n",
      "Epoch 118: train loss: 0.00076790, validation loss: 0.00072851\n",
      "Epoch 119: train loss: 0.00084163, validation loss: 0.00075365\n",
      "Epoch 120: train loss: 0.00076278, validation loss: 0.00074028\n",
      "Epoch 121: train loss: 0.00076554, validation loss: 0.00123281\n",
      "Epoch 122: train loss: 0.00082448, validation loss: 0.00076346\n",
      "Epoch 123: train loss: 0.00079981, validation loss: 0.00089439\n",
      "Epoch 124: train loss: 0.00075215, validation loss: 0.00088420\n",
      "Epoch 125: train loss: 0.00091834, validation loss: 0.00066111\n",
      "Epoch 126: train loss: 0.00072300, validation loss: 0.00072066\n",
      "Epoch 127: train loss: 0.00074774, validation loss: 0.00069025\n",
      "Epoch 128: train loss: 0.00075874, validation loss: 0.00068342\n",
      "Epoch 129: train loss: 0.00078233, validation loss: 0.00077148\n",
      "Epoch 130: train loss: 0.00078795, validation loss: 0.00067845\n",
      "Epoch 131: train loss: 0.00072567, validation loss: 0.00065169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132: train loss: 0.00074105, validation loss: 0.00068765\n",
      "Epoch 133: train loss: 0.00072827, validation loss: 0.00071050\n",
      "Epoch 134: train loss: 0.00080914, validation loss: 0.00074492\n",
      "Epoch 135: train loss: 0.00073753, validation loss: 0.00065495\n",
      "Epoch 136: train loss: 0.00071666, validation loss: 0.00072283\n",
      "Epoch 137: train loss: 0.00086162, validation loss: 0.00105892\n",
      "Epoch 138: train loss: 0.00072112, validation loss: 0.00076745\n",
      "Epoch 139: train loss: 0.00069798, validation loss: 0.00066760\n",
      "Epoch 140: train loss: 0.00081377, validation loss: 0.00066351\n",
      "Epoch 141: train loss: 0.00071815, validation loss: 0.00069988\n",
      "Epoch 142: train loss: 0.00068770, validation loss: 0.00074303\n",
      "Epoch 143: train loss: 0.00075515, validation loss: 0.00068697\n",
      "Epoch 144: train loss: 0.00073746, validation loss: 0.00067380\n",
      "Epoch 145: train loss: 0.00071747, validation loss: 0.00063187\n",
      "Epoch 146: train loss: 0.00069285, validation loss: 0.00076271\n",
      "Epoch 147: train loss: 0.00074845, validation loss: 0.00064087\n",
      "Epoch 148: train loss: 0.00075492, validation loss: 0.00068502\n",
      "Epoch 149: train loss: 0.00069971, validation loss: 0.00066092\n",
      "Epoch 150: train loss: 0.00080391, validation loss: 0.00065308\n",
      "Epoch 151: train loss: 0.00067091, validation loss: 0.00063532\n",
      "Epoch 152: train loss: 0.00080485, validation loss: 0.00066760\n",
      "Epoch 153: train loss: 0.00068299, validation loss: 0.00067073\n",
      "Epoch 154: train loss: 0.00069565, validation loss: 0.00080711\n",
      "Epoch 155: train loss: 0.00080618, validation loss: 0.00061447\n",
      "Epoch 156: train loss: 0.00065331, validation loss: 0.00065921\n",
      "Epoch 157: train loss: 0.00074395, validation loss: 0.00071257\n",
      "Epoch 158: train loss: 0.00077603, validation loss: 0.00064362\n",
      "Epoch 159: train loss: 0.00070648, validation loss: 0.00074929\n",
      "Epoch 160: train loss: 0.00067049, validation loss: 0.00066190\n",
      "Epoch 161: train loss: 0.00070343, validation loss: 0.00075841\n",
      "Epoch 162: train loss: 0.00071477, validation loss: 0.00064946\n",
      "Epoch 163: train loss: 0.00066413, validation loss: 0.00062971\n",
      "Epoch 164: train loss: 0.00072934, validation loss: 0.00079814\n",
      "Epoch 165: train loss: 0.00076714, validation loss: 0.00065702\n",
      "Epoch 166: train loss: 0.00067381, validation loss: 0.00123533\n",
      "Epoch 167: train loss: 0.00074291, validation loss: 0.00064357\n",
      "Epoch 168: train loss: 0.00065969, validation loss: 0.00063357\n",
      "Epoch 169: train loss: 0.00066989, validation loss: 0.00063087\n",
      "Epoch 170: train loss: 0.00072124, validation loss: 0.00064066\n",
      "Epoch 171: train loss: 0.00067397, validation loss: 0.00089244\n",
      "Epoch 172: train loss: 0.00069273, validation loss: 0.00070382\n",
      "Epoch 173: train loss: 0.00072514, validation loss: 0.00060441\n",
      "Epoch 174: train loss: 0.00069201, validation loss: 0.00099550\n",
      "Epoch 175: train loss: 0.00068414, validation loss: 0.00066300\n",
      "Epoch 176: train loss: 0.00066457, validation loss: 0.00072202\n",
      "Epoch 177: train loss: 0.00066354, validation loss: 0.00064373\n",
      "Epoch 178: train loss: 0.00067749, validation loss: 0.00060444\n",
      "Epoch 179: train loss: 0.00072166, validation loss: 0.00064162\n",
      "Epoch 180: train loss: 0.00066650, validation loss: 0.00075101\n",
      "Epoch 181: train loss: 0.00068173, validation loss: 0.00082248\n",
      "Epoch 182: train loss: 0.00068569, validation loss: 0.00079034\n",
      "Epoch 183: train loss: 0.00061333, validation loss: 0.00064441\n",
      "Epoch 184: train loss: 0.00074185, validation loss: 0.00056235\n",
      "Epoch 185: train loss: 0.00062936, validation loss: 0.00065753\n",
      "Epoch 186: train loss: 0.00066455, validation loss: 0.00070476\n",
      "Epoch 187: train loss: 0.00066329, validation loss: 0.00064671\n",
      "Epoch 188: train loss: 0.00061780, validation loss: 0.00057221\n",
      "Epoch 189: train loss: 0.00066681, validation loss: 0.00069537\n",
      "Epoch 190: train loss: 0.00065841, validation loss: 0.00087228\n",
      "Epoch 191: train loss: 0.00064420, validation loss: 0.00064667\n",
      "Epoch 192: train loss: 0.00076372, validation loss: 0.00066391\n",
      "Epoch 193: train loss: 0.00060624, validation loss: 0.00072282\n",
      "Epoch 194: train loss: 0.00060654, validation loss: 0.00058829\n",
      "Epoch 195: train loss: 0.00072797, validation loss: 0.00056992\n",
      "Epoch 196: train loss: 0.00059772, validation loss: 0.00065466\n",
      "Epoch 197: train loss: 0.00065196, validation loss: 0.00061424\n",
      "Epoch 198: train loss: 0.00064787, validation loss: 0.00057338\n",
      "Epoch 199: train loss: 0.00061637, validation loss: 0.00085219\n",
      "Epoch 200: train loss: 0.00064139, validation loss: 0.00059904\n",
      "Epoch 201: train loss: 0.00063236, validation loss: 0.00063305\n",
      "Epoch 202: train loss: 0.00062426, validation loss: 0.00055802\n",
      "Epoch 203: train loss: 0.00061684, validation loss: 0.00058405\n",
      "Epoch 204: train loss: 0.00062885, validation loss: 0.00062024\n",
      "Epoch 205: train loss: 0.00060038, validation loss: 0.00057961\n",
      "Epoch 206: train loss: 0.00065680, validation loss: 0.00055193\n",
      "Epoch 207: train loss: 0.00058178, validation loss: 0.00060832\n",
      "Epoch 208: train loss: 0.00065253, validation loss: 0.00054092\n"
     ]
    }
   ],
   "source": [
    "from koopman_core.learning import KoopDnn, KoopmanNetCtrl\n",
    "from koopman_core.util import fit_standardizer\n",
    "\n",
    "standardizer_x_kdnn = fit_standardizer(xs_train, preprocessing.StandardScaler())\n",
    "standardizer_u_kdnn = fit_standardizer(us_train, preprocessing.StandardScaler())\n",
    "n_tot = n + net_params['encoder_output_dim'] + int(net_params['first_obs_const'])\n",
    "\n",
    "net = KoopmanNetCtrl(net_params, standardizer_x=standardizer_x_kdnn, standardizer_u=standardizer_u_kdnn)\n",
    "model_koop_dnn = KoopDnn(net)\n",
    "model_koop_dnn.set_datasets(xs_train, t_train, u_train=us_train, x_val=xs_val, u_val=us_val, t_val=t_train)\n",
    "model_koop_dnn.model_pipeline(net_params)\n",
    "model_koop_dnn.construct_koopman_model()\n",
    "sys_koop_dnn = BilinearLiftedDynamics(n_tot, m, model_koop_dnn.A, model_koop_dnn.B, model_koop_dnn.C, model_koop_dnn.basis_encode,\n",
    "                                    continuous_mdl=False, dt=dt, standardizer_x=standardizer_x_kdnn, \n",
    "                                      standardizer_u=standardizer_u_kdnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate open loop prediction performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We first evaluate the open loop prediction performance of the proposed method.\n",
    "This is done by generating a new data set in the same way as the training set, predicting the evolution of the system\n",
    "with the control sequence of each trajectory executed in the data set with each of the models, and finally comparing\n",
    "the mean and standard deviation of the error between the true and predicted evolution over the trajectories. The\n",
    "experimental results support what is to be expected from the theory as the error in the $y$ and $z$ terms are\n",
    "significantly lower for the bEDMD method than both DMD and EDMD. The reason for this\n",
    "improvement is that the bEDMD method can capture the nonlinearities present in the actuation matrix of the\n",
    "$(y,z)$-dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction performance evaluation parameters:\n",
    "folder_plots = 'figures/'                                  # Path to save plots\n",
    "n_traj_ol = 50                                                     # Number of trajectories to execute, open loop\n",
    "t_eval = t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from koopman_core.util import evaluate_ol_pred\n",
    "from tabulate import tabulate\n",
    "\n",
    "xs_test = np.empty((n_traj_ol, t_eval.shape[0], n))\n",
    "us_test = np.empty((n_traj_ol, t_eval.shape[0]-1, m))\n",
    "\n",
    "for ii in range(n_traj_ol):\n",
    "    x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "    set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "    mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin, umax, xmin, xmax, QN_trajgen, R_trajgen,\n",
    "                                QN_trajgen, set_pt_dc)\n",
    "    mpc_trajgen.eval(x0, 0)\n",
    "    xd = mpc_trajgen.parse_result().T\n",
    "\n",
    "    while xd[0,0] is None:\n",
    "        x0 = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "        set_pt_dc = np.asarray([rand.uniform(l, u) for l, u in zip(-x0_max, x0_max)])\n",
    "        mpc_trajgen = MPCController(nominal_sys, n_pred_dc, dt, umin, umax, xmin, xmax, QN_trajgen, R_trajgen,\n",
    "                                    QN_trajgen, set_pt_dc)\n",
    "        mpc_trajgen.eval(x0, 0)\n",
    "        xd = mpc_trajgen.parse_result().T\n",
    "\n",
    "    output = QuadrotorPdOutput(system, xd, t_eval, n, m)\n",
    "    pd_controller = PDController(output, K_dc_p, K_dc_d)\n",
    "    perturbed_pd_controller = PerturbedController(system, pd_controller, noise_var, const_offset=hover_thrust)\n",
    "    \n",
    "    xs_test[ii,:,:], us_test[ii,:,:] = system.simulate(x0, perturbed_pd_controller, t_eval)\n",
    "    \n",
    "    mdl_lst = [sys_dmd, sys_edmd, sys_bedmd, sys_koop_dnn]\n",
    "    u_data_lst = [us_test-hover_thrust, us_test-hover_thrust, us_test, us_test]\n",
    "    mdl_names = ['DMD', 'EDMD', 'bEDMD', 'Koop DNN']\n",
    "    error, mse, std = [], [], []\n",
    "    \n",
    "    for sys, u_data in zip(mdl_lst, u_data_lst):\n",
    "        err_tmp, mse_tmp, std_tmp = evaluate_ol_pred(sys, xs_test, t_eval, us=u_data)\n",
    "        error.append(err_tmp)\n",
    "        mse.append(mse_tmp)\n",
    "        std.append(std_tmp)\n",
    "\n",
    "print('\\nOpen loop performance statistics:')\n",
    "table_data = []\n",
    "for name, mse_mdl, std_mdl in zip(mdl_names, mse, std):\n",
    "    table_data.append([name, \"{:.5f}\".format(mse_mdl), \"{:.5f}\".format(std_mdl)])\n",
    "\n",
    "print(tabulate(table_data, \n",
    "               headers=['Mean squared error', 'Standard deviation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "figwidth = 16\n",
    "lw = 2\n",
    "fs = 14\n",
    "y_lim_gain = 1.2\n",
    "row = 2\n",
    "col = n/row\n",
    "\n",
    "#Plot open loop results:\n",
    "plt.figure(figsize=(figwidth,4))\n",
    "axs = [plt.subplot(row,col,jj+1) for jj in range(n)]\n",
    "\n",
    "for ii, err in enumerate(error):\n",
    "    err_mean = np.mean(err, axis=0)\n",
    "    err_std = np.std(err, axis=0)\n",
    "    \n",
    "    for jj in range(n):\n",
    "        axs[jj].plot(t_eval[1:], err_mean[:,jj], label=mdl_names[ii])\n",
    "        axs[jj].fill_between(t_eval[1:], err_mean[:,jj]-err_std[:,jj], err_mean[:,jj]+err_std[:,jj], alpha=0.1)\n",
    "\n",
    "for jj in range(n):\n",
    "    axs[jj].set_xlabel('Time (sec)', fontsize=fs)\n",
    "    axs[jj].set_ylabel('$x_'+ str(jj+1) + '$', fontsize=fs)\n",
    "\n",
    "plt.legend(frameon=False, fontsize=fs)\n",
    "stitle=plt.suptitle('Open loop prediction performance of learned models', fontsize=fs+2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.savefig(folder_plots + 'koop_sys_prediction.pdf', format='pdf', dpi=2400, bbox_extra_artists=(stitle,), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design trajectories based on learned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now study the closed loop performance of the control design. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Closed loop performance evaluation parameters:\n",
    "traj_length=250\n",
    "t_eval = dt * np.arange(traj_length+1)                       # Simulation time points, closed loop\n",
    "Q_mpc = sc.sparse.diags([0,0,0,0,0,0])                       # State penalty matrix, trajectory generation\n",
    "#QN_mpc = sc.sparse.diags([1e5,1e5,1e5,1e5,1e5,1e5])         # Final state penalty matrix, trajectory generation\n",
    "QN_mpc = Q_mpc\n",
    "R_mpc = sc.sparse.eye(m)                                     # Actuation penalty matrix, trajectory generation\n",
    "\n",
    "ctrl_offset = np.array([hover_thrust, hover_thrust])\n",
    "\n",
    "# Design trajectory:\n",
    "x0_cl = np.array([0., 0., 0., 0., 0., 0.])                   # Initial value, closed loop trajectory\n",
    "set_pt_cl = np.array([1.5, 0.5, 0., 0., 0., 0.])              # Desired final value, closed loop trajectory\n",
    "xmax = np.array([2, 2, np.pi/3, 1.,1.,1.])                          # State constraints, trajectory generation\n",
    "xmin = -xmax\n",
    "term_constraint=True\n",
    "\n",
    "# Define initial solution for SQP algorithm:\n",
    "x_init = np.linspace(x0_cl, set_pt_cl, int(traj_length)+1)\n",
    "u_init = hover_thrust*np.ones((m,traj_length)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design controllers for learned DMD, EDMD, and bEDMD models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koopman_core.controllers import MPCController, NonlinearMPCController, BilinearMPCController\n",
    "\n",
    "# Define DMD-based controller:\n",
    "controller_dmd = MPCController(sys_dmd, traj_length, dt, umin, umax, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, terminal_constraint=term_constraint, const_offset=ctrl_offset)\n",
    "\n",
    "# Define EDMD-based controller:\n",
    "controller_edmd = MPCController(sys_edmd, traj_length, dt, umin, umax, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, terminal_constraint=term_constraint, const_offset=ctrl_offset)\n",
    "\n",
    "# Define bEDMD-based controller:\n",
    "controller_bedmd = BilinearMPCController(sys_bedmd, traj_length, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, terminal_constraint=term_constraint)\n",
    "z0_cl = sys_bedmd.basis(x0_cl.reshape((1,-1))).squeeze()\n",
    "z_init = sys_bedmd.basis(x_init)\n",
    "controller_bedmd.construct_controller(z_init, u_init)\n",
    "\n",
    "# Define KDNN-based controller:\n",
    "controller_kdnn = BilinearMPCController(sys_koop_dnn, traj_length, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, \n",
    "                                        terminal_constraint=term_constraint, standardizer_x=standardizer_x_kdnn, standardizer_u=standardizer_u_kdnn)\n",
    "z0_cl_kdnn = sys_koop_dnn.basis(x0_cl.reshape((1,-1))).squeeze()\n",
    "z_init_kdnn = sys_koop_dnn.basis(x_init)\n",
    "u_init_kdnn = standardizer_u_kdnn.transform(u_init)\n",
    "controller_kdnn.construct_controller(z_init_kdnn, u_init_kdnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design controller using full knowledge of nonlinear controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_d = PlanarQuadrotorForceInputDiscrete(mass, inertia, prop_arm, g=gravity, dt=dt)\n",
    "controller_nmpc = NonlinearMPCController(system_d, traj_length, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc, R_mpc, QN_mpc, set_pt_cl, terminal_constraint=term_constraint)\n",
    "controller_nmpc.construct_controller(x_init, u_init+hover_thrust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design trajectories with the contructed MPCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 50\n",
    "\n",
    "controller_dmd.eval(x0_cl, 0)\n",
    "xr_dmd = controller_dmd.parse_result()\n",
    "ur_dmd = controller_dmd.get_control_prediction() + hover_thrust\n",
    "\n",
    "controller_edmd.eval(x0_cl, 0)\n",
    "xr_edmd = sys_edmd.C@controller_edmd.parse_result()\n",
    "ur_edmd = controller_edmd.get_control_prediction() + hover_thrust\n",
    "\n",
    "controller_bedmd.solve_to_convergence(z0_cl, 0., z_init, u_init, max_iter=max_iter)\n",
    "xr_bedmd = sys_bedmd.C@controller_bedmd.get_state_prediction().T\n",
    "ur_bedmd = controller_bedmd.get_control_prediction().T\n",
    "\n",
    "controller_kdnn.solve_to_convergence(z0_cl_kdnn, 0., z_init_kdnn, u_init_kdnn, max_iter=max_iter)\n",
    "xr_kdnn = standardizer_x_kdnn.inverse_transform((sys_koop_dnn.C@controller_kdnn.get_state_prediction().T).T).T\n",
    "ur_kdnn = controller_kdnn.get_control_prediction().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_nmpc.solve_to_convergence(x0_cl, 0., x_init, u_init + ctrl_offset.reshape(1,-1), max_iter=max_iter)\n",
    "xr_nmpc = controller_nmpc.get_state_prediction().T\n",
    "ur_nmpc = controller_nmpc.get_control_prediction().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate designed trajectories open loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol_controller_dmd = OpenLoopController(system, ur_dmd.T, t_eval[:-1])\n",
    "xs_dmd, us_dmd = system.simulate(x0_cl, ol_controller_dmd, t_eval)\n",
    "xs_dmd, us_dmd = xs_dmd.T, us_dmd.T\n",
    "\n",
    "ol_controller_edmd = OpenLoopController(system, ur_edmd.T, t_eval[:-1])\n",
    "xs_edmd, us_edmd = system.simulate(x0_cl, ol_controller_edmd, t_eval)\n",
    "xs_edmd, us_edmd = xs_edmd.T, us_edmd.T\n",
    "\n",
    "ol_controller_bedmd = OpenLoopController(system, ur_bedmd.T, t_eval[:-1])\n",
    "xs_bedmd, us_bedmd = system.simulate(x0_cl, ol_controller_bedmd, t_eval)\n",
    "xs_bedmd, us_bedmd = xs_bedmd.T, us_bedmd.T\n",
    "\n",
    "ol_controller_kdnn = OpenLoopController(system, ur_kdnn.T, t_eval[:-1])\n",
    "xs_kdnn, us_kdnn = system.simulate(x0_cl, ol_controller_kdnn, t_eval)\n",
    "xs_kdnn, us_kdnn = xs_kdnn.T, us_kdnn.T\n",
    "\n",
    "ol_controller_nmpc = OpenLoopController(system, ur_nmpc.T, t_eval[:-1])\n",
    "xs_nmpc, us_nmpc = system.simulate(x0_cl, ol_controller_nmpc, t_eval)\n",
    "xs_nmpc, us_nmpc = xs_nmpc.T, us_nmpc.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "plot_inds = [0, 1, 2, 3, 4, 5, 0, 1]\n",
    "subplot_inds = [1, 2, 3, 5, 6, 7, 4, 8]\n",
    "labels = ['$y$ (m)', '$z$ (m)', '$\\\\theta$ (rad)', '$\\\\dot{y}$ (m/s)','$\\\\dot{z}$ (m/s)', '$\\\\dot{\\\\theta}$', '$T_1$ (N)','$T_2$ (N)']\n",
    "titles = ['y-coordinates', 'z-coordinates', '$\\\\theta$-coordinates', 'Control inputs']\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:brown', 'tab:green', 'tab:cyan']\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "#plt.suptitle('Trajectory designed with model predictive controllers\\nsolid lines - designed trajectory | dashed lines - open loop simulated trajectory | black dotted lines - state/actuation bounds')\n",
    "for ii in range(8):\n",
    "    ind = plot_inds[ii]\n",
    "    if ii < 6:\n",
    "        ax = plt.subplot(2,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval, xr_dmd[ind,:], colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval, xr_edmd[ind, :], colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval, xr_bedmd[ind, :], colors[2], label='K-MPC')\n",
    "        plt.plot(t_eval, xr_kdnn[ind, :], colors[3], label='KDNN-MPC')\n",
    "        plt.plot(t_eval, xr_nmpc[ind,:], colors[4], label='NMPC')\n",
    "\n",
    "        plt.plot(t_eval, xs_dmd[ind,:], '--', color=colors[0], linewidth=1)\n",
    "        plt.plot(t_eval, xs_edmd[ind, :], '--', color=colors[1], linewidth=1)\n",
    "        plt.plot(t_eval, xs_bedmd[ind, :], '--', color=colors[2], linewidth=1)\n",
    "        plt.plot(t_eval, xs_kdnn[ind, :], '--',  colors[3], linewidth=1)\n",
    "        plt.plot(t_eval, xs_nmpc[ind,:], '--', color=colors[4], linewidth=1)\n",
    "\n",
    "        plt.scatter(t_eval[0], x0_cl[ind], color='g')\n",
    "        plt.scatter(t_eval[-1], set_pt_cl[ind], color='r')\n",
    "        plt.ylabel(labels[ind])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        if ii >= 3:\n",
    "            plt.plot([0, t_eval[-1]], [xmax[ind], xmax[ind]], ':k')\n",
    "            plt.plot([0, t_eval[-1]], [xmin[ind], xmin[ind]], ':k')\n",
    "            #plt.ylim(xmin[ind]-0.1,xmax[ind]+0.1)\n",
    "        if subplot_inds[ii]==1:\n",
    "            plt.legend(loc='upper left', frameon=False)\n",
    "    elif ii < 8:\n",
    "        ax = plt.subplot(2,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval[:-1],ur_dmd[ind,:], color=colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval[:-1], ur_edmd[ind, :], color=colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval[:-1], ur_bedmd[ind, :], color=colors[2], label='K-NMPC')\n",
    "        plt.plot(t_eval[:-1], ur_kdnn[ind, :], color=colors[3], label='KDNN-NMPC')\n",
    "        plt.plot(t_eval[:-1],ur_nmpc[ind,:], color=colors[4], label='NMPC')\n",
    "        plt.plot([0, t_eval[-1]], [umax[ind]+hover_thrust, umax[ind]+hover_thrust], ':k')\n",
    "        plt.plot([0, t_eval[-1]], [umin[ind]+hover_thrust, umin[ind]+hover_thrust], ':k')\n",
    "        plt.ylabel(labels[ii])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        \n",
    "    if subplot_inds[ii] > 4:\n",
    "        plt.xlabel('Time (sec)')\n",
    "    else:\n",
    "        plt.title(titles[subplot_inds[ii]-1])\n",
    "\n",
    "if save_figures:\n",
    "    matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "    matplotlib.rcParams['ps.fonttype'] = 42\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(dropbox_folder + 'planar_quad_trajectory.pdf', format='pdf', dpi=2400)\n",
    "plt.show()\n",
    "\n",
    "cost_ref_dmd = (xr_dmd[:,-1]-set_pt_cl).T@QN_mpc@(xr_dmd[:,-1]-set_pt_cl) + np.sum(np.diag(ur_dmd.T@R_mpc@ur_dmd))\n",
    "cost_ref_edmd = (xr_edmd[:,-1]-set_pt_cl).T@QN_mpc@(xr_edmd[:,-1]-set_pt_cl) + np.sum(np.diag(ur_edmd.T@R_mpc@ur_edmd))\n",
    "cost_ref_bedmd = (xr_bedmd[:,-1]-set_pt_cl).T@QN_mpc@(xr_bedmd[:,-1]-set_pt_cl) + np.sum(np.diag(ur_bedmd.T@R_mpc@ur_bedmd))\n",
    "cost_ref_kdnn = (xr_kdnn[:,-1]-set_pt_cl).T@QN_mpc@(xr_kdnn[:,-1]-set_pt_cl) + np.sum(np.diag(ur_kdnn.T@R_mpc@ur_kdnn))\n",
    "cost_ref_nmpc = (xr_nmpc[:,-1]-set_pt_cl).T@QN_mpc@(xr_nmpc[:,-1]-set_pt_cl) + np.sum(np.diag(ur_nmpc.T@R_mpc@ur_nmpc))\n",
    "\n",
    "dist_ol_dmd = np.linalg.norm(xs_dmd[:,-1] - set_pt_cl)\n",
    "dist_ol_edmd = np.linalg.norm(xs_edmd[:,-1] - set_pt_cl)\n",
    "dist_ol_bedmd = np.linalg.norm(xs_bedmd[:,-1] - set_pt_cl)\n",
    "dist_ol_kdnn = np.linalg.norm(xs_kdnn[:,-1] - set_pt_cl)\n",
    "dist_ol_nmpc = np.linalg.norm(xs_nmpc[:,-1] - set_pt_cl)\n",
    "\n",
    "print('Solution statistics:\\n')\n",
    "print(tabulate([['DMD MPC', \"{:.4f}\".format(cost_ref_dmd/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_dmd), '-','-',sum(controller_dmd.comp_time)], \n",
    "                ['EDMD MPC', \"{:.4f}\".format(cost_ref_edmd/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_edmd),'-','-',sum(controller_edmd.comp_time)], \n",
    "                ['bEDMD MPC', \"{:.4f}\".format(cost_ref_bedmd/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_bedmd), len(controller_bedmd.x_iter), \"{:.4f}\".format(np.mean(controller_bedmd.comp_time)), sum(controller_bedmd.comp_time)],\n",
    "                ['KDNN MPC', \"{:.4f}\".format(cost_ref_kdnn/cost_ref_nmpc), \"{:.4f}\".format(dist_ol_kdnn), len(controller_kdnn.x_iter), \"{:.4f}\".format(np.mean(controller_kdnn.comp_time)), sum(controller_kdnn.comp_time)],\n",
    "                ['NMPC (benchmark)', 1, \"{:.4f}\".format(dist_ol_nmpc), len(controller_nmpc.x_iter), \"{:.4f}\".format(np.mean(controller_nmpc.comp_time)), sum(controller_nmpc.comp_time)]], \n",
    "               headers=['Normalized cost,\\ndesigned trajectory', 'Realized terminal,\\nerror', '# of SQP\\niterations','Mean comp. time\\nper iteration (secs)', 'Total comp.\\ntime (secs)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study evolution of the solution after each iteration of the SQP-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = min(len(controller_nmpc.x_iter),len(controller_bedmd.x_iter))\n",
    "\n",
    "# Calculate cost after each iteration:\n",
    "iter_cost_bedmd, iter_cost_nmpc = [], []\n",
    "\n",
    "ol_controller_init = OpenLoopController(system, u_init, t_eval[:-1])\n",
    "xs_init, _ = system.simulate(x0_cl, ol_controller_init, t_eval)\n",
    "xs_init, us_init = xs_init.T, u_init.T\n",
    "init_cost = (xs_init[:,-1]-set_pt_cl).T@QN_mpc@(xs_init[:,-1]-set_pt_cl) + np.sum(np.diag(us_init.T@R_mpc@us_init))\n",
    "iter_cost_bedmd = [init_cost]\n",
    "iter_cost_kdnn = [init_cost]\n",
    "iter_cost_nmpc = [init_cost]\n",
    "iter_norm_dist_bedmd = [np.linalg.norm(xs_init[:,-1]-set_pt_cl)]\n",
    "iter_norm_dist_kdnn = [np.linalg.norm(xs_init[:,-1]-set_pt_cl)]\n",
    "iter_norm_dist_nmpc = [np.linalg.norm(xs_init[:,-1]-set_pt_cl)]\n",
    "\n",
    "for ii in range(len(controller_bedmd.x_iter)):\n",
    "    ur_bedmd_iter = controller_bedmd.u_iter[ii].T\n",
    "    ol_controller_bedmd_iter = OpenLoopController(system, ur_bedmd_iter, t_eval[:-1])\n",
    "    xs_bedmd_iter, _ = system.simulate(x0_cl, ol_controller_bedmd_iter, t_eval)\n",
    "    xs_bedmd_iter, us_bedmd_iter = xs_bedmd_iter.T, ur_bedmd_iter.T\n",
    "    iter_cost_bedmd.append((xs_bedmd_iter[:,-1]-set_pt_cl).T@QN_mpc@(xs_bedmd_iter[:,-1]-set_pt_cl) + np.sum(np.diag(us_bedmd_iter.T@R_mpc@us_bedmd_iter)))\n",
    "    iter_norm_dist_bedmd.append(np.linalg.norm(xs_bedmd_iter[:,-1]-set_pt_cl))\n",
    "    \n",
    "for ii in range(len(controller_kdnn.x_iter)):\n",
    "    ur_kdnn_iter = standardizer_u_kdnn.inverse_transform(controller_kdnn.u_iter[ii].T)\n",
    "    ol_controller_kdnn_iter = OpenLoopController(system, ur_kdnn_iter, t_eval[:-1])\n",
    "    xs_kdnn_iter, _ = system.simulate(x0_cl, ol_controller_kdnn_iter, t_eval)\n",
    "    xs_kdnn_iter, us_kdnn_iter = xs_kdnn_iter.T, ur_kdnn_iter.T\n",
    "    iter_cost_kdnn.append((xs_kdnn_iter[:,-1]-set_pt_cl).T@QN_mpc@(xs_kdnn_iter[:,-1]-set_pt_cl) + np.sum(np.diag(us_kdnn_iter.T@R_mpc@us_kdnn_iter)))\n",
    "    iter_norm_dist_kdnn.append(np.linalg.norm(xs_kdnn_iter[:,-1]-set_pt_cl))\n",
    "    \n",
    "for ii in range(len(controller_nmpc.x_iter)):\n",
    "    ur_nmpc_iter = controller_nmpc.u_iter[ii].T\n",
    "    ol_controller_nmpc_iter = OpenLoopController(system, ur_nmpc_iter, t_eval[:-1])\n",
    "    xs_nmpc_iter, _ = system.simulate(x0_cl, ol_controller_nmpc_iter, t_eval)\n",
    "    xs_nmpc_iter, us_nmpc_iter = xs_nmpc_iter.T, ur_nmpc_iter.T\n",
    "    iter_cost_nmpc.append((xs_nmpc_iter[:,-1]-set_pt_cl).T@QN_mpc@(xs_nmpc_iter[:,-1]-set_pt_cl) + np.sum(np.diag(us_nmpc_iter.T@R_mpc@us_nmpc_iter)))\n",
    "    iter_norm_dist_nmpc.append(np.linalg.norm(xs_nmpc_iter[:,-1]-set_pt_cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "#plt.suptitle('Control solution after each iteration of the SQP-algorithm for NMPC and K-NMPC')\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(np.arange(n_iter), iter_cost_bedmd[:n_iter]/iter_cost_nmpc[-1], color=colors[2], label='K-NMPC')\n",
    "plt.plot(np.arange(n_iter), iter_cost_kdnn[:n_iter]/iter_cost_nmpc[-1], color=colors[3], label='KDNN-NMPC')\n",
    "plt.plot(np.arange(n_iter), iter_cost_nmpc[:n_iter]/iter_cost_nmpc[-1], color=colors[4], label='NMPC')\n",
    "plt.title('Control effort')\n",
    "plt.ylabel('$||u||$')\n",
    "plt.legend(loc='upper right', frameon=False)\n",
    "plt.xlabel('SQP iteration')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(np.arange(n_iter), iter_norm_dist_bedmd[:n_iter], color=colors[2], label=labels[2])\n",
    "plt.plot(np.arange(n_iter), iter_norm_dist_kdnn[:n_iter], color=colors[3], label=labels[3])\n",
    "plt.plot(np.arange(n_iter), iter_norm_dist_nmpc[:n_iter], color=colors[4], label=labels[4])\n",
    "plt.ylim(0,5)\n",
    "plt.title('Realized terminal distance from setpoint')\n",
    "plt.ylabel('$||x_N - x_d||$')\n",
    "plt.xlabel('SQP iteration')\n",
    "\n",
    "if save_figures:\n",
    "    matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "    matplotlib.rcParams['ps.fonttype'] = 42\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(dropbox_folder + 'planar_quad_sqp_iterations.pdf', format='pdf', dpi=2400)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Solution statistics\\n')\n",
    "print(tabulate([['Nonlinear MPC', len(controller_nmpc.x_iter), np.mean(controller_nmpc.comp_time), np.std(controller_nmpc.comp_time), sum(controller_nmpc.comp_time)],\n",
    "                ['Koopman bilinear MPC', len(controller_bedmd.x_iter), np.mean(controller_bedmd.comp_time), np.std(controller_bedmd.comp_time), sum(controller_bedmd.comp_time)],\n",
    "                ['Koopman DNN bilinear MPC', len(controller_kdnn.x_iter), np.mean(controller_kdnn.comp_time), np.std(controller_kdnn.comp_time), sum(controller_kdnn.comp_time)]], \n",
    "               headers=['Number of SQP\\niterations','Mean comp. time per\\niteration (secs)', 'Std comp. time per\\niteration (secs)', 'Total comp.\\ntime (secs)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate performance of controllers for closed-loop control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design finite horizon controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from koopman_core.controllers import PerturbedController\n",
    "\n",
    "Q_mpc_cl = 5e2*np.diag([1, 1, 1, 2e-1, 2e-1, 2e-1])\n",
    "QN_mpc_cl = Q_mpc_cl\n",
    "R_mpc_cl = np.eye(m)\n",
    "traj_duration = 1.\n",
    "N_cl = int(traj_duration/dt)\n",
    "t_eval_cl=np.arange(300)*dt\n",
    "\n",
    "# Solver settings closed loop:\n",
    "polish_osqp = False\n",
    "max_iter_osqp = 10\n",
    "linsys_solver_osqp = 'qdldl'\n",
    "warm_start_osqp = True\n",
    "\n",
    "controller_dmd_cl = MPCController(sys_dmd, N_cl, dt, umin, umax, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, add_slack=True)\n",
    "controller_dmd_cl = PerturbedController(sys_dmd,controller_dmd_cl,0.,const_offset=hover_thrust, umin=umin, umax=umax)\n",
    "\n",
    "controller_edmd_cl = MPCController(sys_edmd, N_cl, dt, umin, umax, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, add_slack=True)\n",
    "controller_edmd_cl = PerturbedController(sys_edmd,controller_edmd_cl,0.,const_offset=hover_thrust, umin=umin, umax=umax)\n",
    "\n",
    "controller_bedmd_cl = BilinearMPCController(sys_bedmd, N_cl, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, add_slack=True)\n",
    "controller_bedmd_cl.construct_controller(controller_bedmd.cur_z[:N_cl+1,:], controller_bedmd.cur_u[:N_cl,:])\n",
    "controller_bedmd_cl.solve_to_convergence(z0_cl, 0., controller_bedmd.cur_z[:N_cl+1,:], controller_bedmd.cur_u[:N_cl,:], max_iter=max_iter)\n",
    "#controller_bedmd_cl = PerturbedController(sys_bedmd,controller_bedmd_cl,0.,const_offset=hover_thrust, umin=umin, umax=umax)\n",
    "controller_bedmd_cl.update_solver_settings(polish=polish_osqp, max_iter=max_iter_osqp, linsys_solver=linsys_solver_osqp, warm_start=warm_start_osqp)\n",
    "\n",
    "controller_kdnn_cl = BilinearMPCController(sys_koop_dnn, N_cl, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, \n",
    "                                        add_slack=True, standardizer_x=standardizer_x_kdnn, standardizer_u=standardizer_u_kdnn)\n",
    "controller_kdnn_cl.construct_controller(controller_kdnn.cur_z[:N_cl+1,:], controller_kdnn.cur_u[:N_cl,:])\n",
    "controller_kdnn_cl.solve_to_convergence(z0_cl_kdnn, 0., controller_kdnn.cur_z[:N_cl+1,:], controller_kdnn.cur_u[:N_cl,:], max_iter=max_iter)\n",
    "controller_kdnn_cl.update_solver_settings(polish=polish_osqp, max_iter=max_iter_osqp, linsys_solver=linsys_solver_osqp, warm_start=warm_start_osqp)\n",
    "\n",
    "controller_nmpc_cl = NonlinearMPCController(system_d, N_cl, dt, umin+hover_thrust, umax+hover_thrust, xmin, xmax, Q_mpc_cl, R_mpc_cl, QN_mpc_cl, set_pt_cl, add_slack=True)\n",
    "controller_nmpc_cl.construct_controller(controller_nmpc.cur_z[:N_cl+1,:], controller_nmpc.cur_u[:N_cl,:])\n",
    "controller_nmpc_cl.solve_to_convergence(x0_cl, 0., controller_nmpc.cur_z[:N_cl+1,:], controller_nmpc.cur_u[:N_cl,:], max_iter=max_iter)\n",
    "controller_nmpc_cl.update_solver_settings(polish=polish_osqp, max_iter=max_iter_osqp, linsys_solver=linsys_solver_osqp, warm_start=warm_start_osqp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate designed trajectories closed-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_dmd_cl, us_dmd_cl = system.simulate(x0_cl, controller_dmd_cl, t_eval_cl)\n",
    "xs_dmd_cl, us_dmd_cl = xs_dmd_cl.T, us_dmd_cl.T\n",
    "\n",
    "xs_edmd_cl, us_edmd_cl = system.simulate(x0_cl, controller_edmd_cl, t_eval_cl)\n",
    "xs_edmd_cl, us_edmd_cl = xs_edmd_cl.T, us_edmd_cl.T\n",
    "\n",
    "controller_bedmd_cl.comp_time = []\n",
    "xs_bedmd_cl, us_bedmd_cl = system.simulate(x0_cl, controller_bedmd_cl, t_eval_cl)\n",
    "xs_bedmd_cl, us_bedmd_cl = xs_bedmd_cl.T, us_bedmd_cl.T\n",
    "\n",
    "controller_kdnn_cl.comp_time = []\n",
    "xs_kdnn_cl, us_kdnn_cl = system.simulate(x0_cl, controller_kdnn_cl, t_eval_cl)\n",
    "xs_kdnn_cl, us_kdnn_cl = xs_kdnn_cl.T, us_kdnn_cl.T\n",
    "\n",
    "controller_nmpc_cl.comp_time = []\n",
    "xs_nmpc_cl, us_nmpc_cl = system.simulate(x0_cl, controller_nmpc_cl, t_eval_cl)\n",
    "xs_nmpc_cl, us_nmpc_cl = xs_nmpc_cl.T, us_nmpc_cl.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot/analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inds = [0, 1, 2, 0, 1]\n",
    "subplot_inds = [1, 2, 3, 4, 8]\n",
    "\n",
    "plt.figure(figsize=(12,2.5))\n",
    "for ii in range(5):\n",
    "    ind = plot_inds[ii]\n",
    "    if ii < 3:\n",
    "        ax = plt.subplot(1,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval_cl, xs_dmd_cl[ind,:], colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval_cl, xs_edmd_cl[ind, :], colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval_cl, xs_bedmd_cl[ind, :], colors[2], label='K-NMPC')\n",
    "        plt.plot(t_eval_cl, xs_kdnn_cl[ind, :], colors[3], label='KDNN-NMPC')\n",
    "        plt.plot(t_eval_cl, xs_nmpc_cl[ind,:], colors[4], label='NMPC')\n",
    "\n",
    "        plt.scatter(t_eval_cl[0], x0_cl[ind], color='g')\n",
    "        plt.scatter(t_eval_cl[-1], set_pt_cl[ind], color='r')\n",
    "        plt.ylabel(labels[ind])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.title(titles[subplot_inds[ii]-1])\n",
    "        plt.xlabel('Time (sec)')\n",
    "        if subplot_inds[ii]==1:\n",
    "            plt.legend(loc='upper left', frameon=False)\n",
    "            plt.ylim(-0.15,2)\n",
    "    else:\n",
    "        bx = plt.subplot(2,4,subplot_inds[ii])\n",
    "        plt.plot(t_eval_cl[:-1],us_dmd_cl[ind,:], color=colors[0], label='DMD MPC')\n",
    "        plt.plot(t_eval_cl[:-1], us_edmd_cl[ind, :], color=colors[1], label='EDMD MPC')\n",
    "        plt.plot(t_eval_cl[:-1], us_bedmd_cl[ind, :], color=colors[2], label='K-NMPC')\n",
    "        plt.plot(t_eval_cl[:-1], us_kdnn_cl[ind, :], color=colors[3], label='KDNN-NMPC')\n",
    "        plt.plot(t_eval_cl[:-1],us_nmpc_cl[ind,:], color=colors[4], label='NMPC')\n",
    "        plt.plot([0, t_eval_cl[-1]], [umax[ind]+hover_thrust, umax[ind]+hover_thrust], ':k')\n",
    "        plt.plot([0, t_eval_cl[-1]], [umin[ind]+hover_thrust, umin[ind]+hover_thrust], ':k')\n",
    "        plt.ylabel(labels[ii+3])\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        if subplot_inds[ii] == 4:\n",
    "            plt.title('Control inputs')\n",
    "        else:\n",
    "            plt.xlabel('Time (sec)')\n",
    "if save_figures:\n",
    "    matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "    matplotlib.rcParams['ps.fonttype'] = 42\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(dropbox_folder + 'planar_quad_closed_loop.pdf', format='pdf', dpi=2400)\n",
    "plt.show()\n",
    "    \n",
    "cost_cl_dmd = np.sum(np.diag((xs_dmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_dmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_dmd_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_dmd_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_dmd_cl.T@R_mpc_cl@us_dmd_cl))\n",
    "cost_cl_edmd = np.sum(np.diag((xs_edmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_edmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_edmd_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_edmd_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_edmd_cl.T@R_mpc_cl@us_edmd_cl))\n",
    "cost_cl_bedmd = np.sum(np.diag((xs_bedmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_bedmd_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_bedmd_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_bedmd_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_bedmd_cl.T@R_mpc_cl@us_bedmd_cl))\n",
    "cost_cl_kdnn = np.sum(np.diag((xs_kdnn_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_kdnn_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_kdnn_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_kdnn_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_kdnn_cl.T@R_mpc_cl@us_kdnn_cl))\n",
    "cost_cl_nmpc = np.sum(np.diag((xs_nmpc_cl[:,:-1]-set_pt_cl.reshape(-1,1)).T@Q_mpc_cl@(xs_nmpc_cl[:,:-1]-set_pt_cl.reshape(-1,1)))) + (xs_nmpc_cl[:,-1]-set_pt_cl).T@QN_mpc_cl@(xs_nmpc_cl[:,-1]-set_pt_cl) + np.sum(np.diag(us_nmpc_cl.T@R_mpc_cl@us_nmpc_cl))\n",
    "\n",
    "print('Solution statistics:\\n')\n",
    "print(tabulate([['DMD MPC', \"{:.4f}\".format(cost_cl_dmd/cost_cl_nmpc), np.mean(controller_dmd_cl.nom_controller.comp_time), np.std(controller_dmd_cl.nom_controller.comp_time)], \n",
    "                ['EDMD MPC', \"{:.4f}\".format(cost_cl_edmd/cost_cl_nmpc),np.mean(controller_edmd_cl.nom_controller.comp_time), np.std(controller_edmd_cl.nom_controller.comp_time)], \n",
    "                ['bEDMD MPC', \"{:.4f}\".format(cost_cl_bedmd/cost_cl_nmpc), np.mean(controller_bedmd_cl.comp_time), np.std(controller_bedmd_cl.comp_time)],\n",
    "                ['DNN bEDMD MPC', \"{:.4f}\".format(cost_cl_kdnn/cost_cl_nmpc), np.mean(controller_kdnn_cl.comp_time), np.std(controller_kdnn_cl.comp_time)],\n",
    "                ['NMPC (benchmark, known model)',1, np.mean(controller_nmpc_cl.comp_time), np.std(controller_nmpc_cl.comp_time)]], \n",
    "               headers=['Normalized cost,\\nrealized trajectory', 'Mean comp. time (secs)', 'std comp. time (secs)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keedmd",
   "language": "python",
   "name": "keedmd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
